{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72d0a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 31276 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 00:41:15.066356 1199042 site-packages/torch/distributed/run.py:792] \n",
      "W0308 00:41:15.066356 1199042 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 00:41:15.066356 1199042 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 00:41:15.066356 1199042 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W308 00:41:21.544153658 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W308 00:41:21.743065903 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "1298/1298 07:08<00:00 , loss=0.0422, lr=0.0003, step=1298\n",
      "433/433 01:53<00:00 \n",
      "EPOCH 1 | DICE 0.9007179995048279\n",
      "[0.90814558 0.90554593 0.89890237 0.90063547 0.89861352 0.89688042\n",
      " 0.89630272]\n",
      "SAVING BEST!\n",
      "61/1298 00:21<06:39 , loss=0.0279, lr=0.0003, step=1359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function PtyProcess.__del__ at 0x758d40fae040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ptyprocess/ptyprocess.py\", line 370, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b86820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "222ae4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 33506 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 01:29:15.402783 1204915 site-packages/torch/distributed/run.py:792] \n",
      "W0308 01:29:15.402783 1204915 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 01:29:15.402783 1204915 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 01:29:15.402783 1204915 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W308 01:29:22.454328972 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W308 01:29:22.521235726 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "1298/1298 07:08<00:00 , loss=0.188, lr=0.0003, step=1298\n",
      "433/433 02:24<00:00 \n",
      "EPOCH 1 | DICE 0.9081455805892548\n",
      "[0.90814558]\n",
      "SAVING BEST!\n",
      "76/1298 00:32<07:40 , loss=0.157, lr=0.0003, step=1374 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"2\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c866b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b928d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 34588 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 01:50:36.262629 1208109 site-packages/torch/distributed/run.py:792] \n",
      "W0308 01:50:36.262629 1208109 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 01:50:36.262629 1208109 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 01:50:36.262629 1208109 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W308 01:50:42.879330603 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W308 01:50:43.087311915 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "1298/1298 07:08<00:00 , loss=0.0727, lr=0.0003, step=1298\n",
      "433/433 02:27<00:00 \n",
      "EPOCH 1 | DICE 0.6897347612388626\n",
      "[0.68921707 0.69897649 0.69814052 0.69494936 0.68984171 0.68275253\n",
      " 0.68035593 0.68801306 0.68957039 0.69079342 0.69072064 0.68915293\n",
      " 0.68953037 0.68427223]\n",
      "SAVING BEST!\n",
      "1298/1298 07:43<00:00 , loss=0.0581, lr=0.000299, step=2596\n",
      "433/433 01:56<00:00 \n",
      "EPOCH 2 | DICE 0.6946163513643414\n",
      "[0.70298328 0.71037637 0.70358958 0.69924702 0.69045121 0.68786819\n",
      " 0.68535318 0.69076182 0.69200585 0.69320639 0.69368077 0.69265395\n",
      " 0.69482242 0.68762888]\n",
      "SAVING BEST!\n",
      "1298/1298 07:11<00:00 , loss=0.0563, lr=0.000297, step=3894\n",
      "433/433 01:53<00:00 \n",
      "EPOCH 3 | DICE 0.6850442898652959\n",
      "[0.69036372 0.69810222 0.69321002 0.68987415 0.68205417 0.67731323\n",
      " 0.67601153 0.68233296 0.68320802 0.68332001 0.68563448 0.68685408\n",
      " 0.68348678 0.67885467]\n",
      "1298/1298 07:08<00:00 , loss=0.0542, lr=0.000294, step=5192\n",
      "433/433 01:52<00:00 \n",
      "EPOCH 4 | DICE 0.7042933211544291\n",
      "[0.71210579 0.71601264 0.71415843 0.70827446 0.7026375  0.69743706\n",
      " 0.69739072 0.7008058  0.70146163 0.70610817 0.70266901 0.70364339\n",
      " 0.70196018 0.69544172]\n",
      "SAVING BEST!\n",
      "1298/1298 08:04<00:00 , loss=0.052, lr=0.000291, step=6490 \n",
      "433/433 01:52<00:00 \n",
      "EPOCH 5 | DICE 0.6987230700967147\n",
      "[0.70349807 0.71115233 0.7081776  0.70305085 0.69829218 0.69192571\n",
      " 0.69280728 0.69800151 0.69475773 0.7015802  0.6982533  0.69825142\n",
      " 0.69552003 0.68685479]\n",
      "1298/1298 07:09<00:00 , loss=0.0499, lr=0.000287, step=7788\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 6 | DICE 0.6912194455762649\n",
      "[0.69864847 0.70542687 0.69833287 0.69459337 0.68850791 0.68276967\n",
      " 0.68047504 0.68760566 0.68662214 0.69291852 0.69412303 0.69093942\n",
      " 0.69200791 0.68410137]\n",
      "1298/1298 07:32<00:00 , loss=0.0483, lr=0.000282, step=9086\n",
      "433/433 02:37<00:00 \n",
      "EPOCH 7 | DICE 0.6945630272394743\n",
      "[0.70410289 0.70654929 0.70416939 0.69950213 0.69364369 0.68515695\n",
      " 0.68699684 0.69108395 0.69311692 0.69749854 0.69582244 0.6936633\n",
      " 0.68846534 0.68411072]\n",
      "1298/1298 08:08<00:00 , loss=0.0463, lr=0.000277, step=10384\n",
      "433/433 01:49<00:00 \n",
      "EPOCH 8 | DICE 0.6854922691694638\n",
      "[0.69305642 0.69471485 0.69132714 0.68940742 0.68239399 0.67929775\n",
      " 0.67588088 0.68549339 0.6841451  0.68603985 0.68614867 0.68907041\n",
      " 0.68480809 0.67510781]\n",
      "1298/1298 07:10<00:00 , loss=0.0454, lr=0.000271, step=11682\n",
      "433/433 01:53<00:00 \n",
      "EPOCH 9 | DICE 0.6997057691536082\n",
      "[0.7058063  0.7108136  0.70722594 0.70265379 0.698215   0.69007518\n",
      " 0.69096892 0.69968628 0.69693452 0.70335557 0.6996341  0.70112653\n",
      " 0.6977864  0.69159864]\n",
      "1298/1298 08:05<00:00 , loss=0.0448, lr=0.000265, step=12980\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 10 | DICE 0.6954834451799492\n",
      "[0.70080643 0.70431903 0.70363557 0.69925608 0.69345318 0.68660847\n",
      " 0.6853361  0.69534323 0.69382785 0.69952291 0.69592046 0.69551274\n",
      " 0.69515577 0.68807041]\n",
      "1298/1298 07:08<00:00 , loss=0.0444, lr=0.000258, step=14278\n",
      "433/433 02:46<00:00 \n",
      "EPOCH 11 | DICE 0.6964929237241324\n",
      "[0.70191174 0.70633229 0.70506691 0.70061089 0.69488346 0.68925682\n",
      " 0.6877826  0.69505669 0.6948418  0.6998212  0.69850132 0.69479042\n",
      " 0.6926955  0.68934928]\n",
      "1298/1298 07:32<00:00 , loss=0.0434, lr=0.00025, step=15576 \n",
      "433/433 01:53<00:00 \n",
      "EPOCH 12 | DICE 0.6992384214376278\n",
      "[0.7064939  0.70843371 0.70728926 0.70559708 0.6987571  0.69247109\n",
      " 0.68897893 0.69831525 0.69514399 0.70301099 0.70145472 0.69707062\n",
      " 0.69660285 0.68971841]\n",
      "1298/1298 07:10<00:00 , loss=0.0437, lr=0.000242, step=16874\n",
      "433/433 01:49<00:00 \n",
      "EPOCH 13 | DICE 0.6920933139500408\n",
      "[0.6993373  0.70276831 0.69970079 0.6979517  0.68955668 0.68486627\n",
      " 0.6795132  0.6910973  0.68892676 0.69487447 0.69236855 0.69231225\n",
      " 0.69315878 0.68287402]\n",
      "1298/1298 07:09<00:00 , loss=0.0425, lr=0.000234, step=18172\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 14 | DICE 0.6893906593794455\n",
      "[0.6938404  0.69875131 0.69579845 0.69568924 0.68861903 0.68163611\n",
      " 0.67854511 0.68889389 0.68486811 0.69291676 0.69257708 0.68823242\n",
      " 0.68895312 0.68214821]\n",
      "1298/1298 07:05<00:00 , loss=0.0421, lr=0.000225, step=19470\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 15 | DICE 0.6943996286547944\n",
      "[0.70277441 0.70794564 0.70306747 0.70033117 0.69319882 0.68417201\n",
      " 0.68170698 0.69400076 0.69016621 0.69439624 0.69618398 0.69603198\n",
      " 0.69293756 0.68468157]\n",
      "1298/1298 07:08<00:00 , loss=0.043, lr=0.000216, step=20768 \n",
      "433/433 01:51<00:00 \n",
      "EPOCH 16 | DICE 0.6933144742825207\n",
      "[0.70117153 0.70627221 0.70358099 0.69827753 0.69310023 0.68698458\n",
      " 0.68166859 0.69176734 0.69039337 0.69305335 0.69208533 0.69535106\n",
      " 0.69034046 0.68235608]\n",
      "1298/1298 07:08<00:00 , loss=0.0415, lr=0.000206, step=22066\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 17 | DICE 0.6948478435099756\n",
      "[0.70317915 0.70572383 0.70346579 0.70059885 0.69485923 0.68712545\n",
      " 0.68330073 0.69371476 0.69156216 0.6965858  0.69374915 0.69517428\n",
      " 0.69346615 0.68536448]\n",
      "1298/1298 07:11<00:00 , loss=0.041, lr=0.000196, step=23364 \n",
      "433/433 01:51<00:00 \n",
      "EPOCH 18 | DICE 0.6890730627963643\n",
      "[0.69559991 0.69881858 0.69782488 0.69331454 0.68619213 0.68234333\n",
      " 0.67663639 0.68938289 0.68568544 0.6932402  0.68962716 0.69009678\n",
      " 0.68872657 0.67953409]\n",
      "1298/1298 07:09<00:00 , loss=0.0413, lr=0.000186, step=24662\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 19 | DICE 0.6952241059307\n",
      "[0.70046106 0.70406866 0.70327707 0.70066923 0.6946423  0.68817862\n",
      " 0.68362595 0.69669241 0.69172566 0.6996126  0.69464462 0.69671554\n",
      " 0.69346433 0.68535943]\n",
      "1298/1298 07:08<00:00 , loss=0.0417, lr=0.000176, step=25960\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 20 | DICE 0.6945061524826293\n",
      "[0.6996758  0.70520643 0.70541735 0.70136296 0.69531735 0.68709395\n",
      " 0.68188548 0.69290932 0.6905442  0.69694751 0.69315023 0.69640085\n",
      " 0.69325838 0.68391632]\n",
      "1298/1298 07:10<00:00 , loss=0.0413, lr=0.000166, step=27258\n",
      "433/433 01:52<00:00 \n",
      "EPOCH 21 | DICE 0.6926738388118423\n",
      "[0.70144425 0.70370503 0.70151726 0.69604726 0.69248265 0.6867698\n",
      " 0.68021928 0.69069428 0.68740894 0.69705119 0.69339029 0.69157617\n",
      " 0.69020488 0.68492247]\n",
      "1298/1298 07:09<00:00 , loss=0.0406, lr=0.000155, step=28556\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 22 | DICE 0.6936625225391673\n",
      "[0.70241537 0.70524712 0.70530783 0.69776926 0.69264122 0.68732458\n",
      " 0.68031424 0.69178358 0.68862495 0.6961232  0.69507624 0.69273974\n",
      " 0.69290508 0.68300289]\n",
      "1298/1298 07:07<00:00 , loss=0.0401, lr=0.000145, step=29854\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 23 | DICE 0.693229727295197\n",
      "[0.70080689 0.7055686  0.70378054 0.69933449 0.69247417 0.68627628\n",
      " 0.67944595 0.69059273 0.68630144 0.69571589 0.696123   0.69285124\n",
      " 0.69209422 0.68385073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298/1298 07:07<00:00 , loss=0.0405, lr=0.000134, step=31152\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 24 | DICE 0.6966846893973694\n",
      "[0.70319603 0.70541856 0.70631956 0.70142919 0.69535333 0.69192479\n",
      " 0.68664053 0.69658655 0.69378979 0.69879743 0.6950273  0.69695127\n",
      " 0.69576939 0.68638193]\n",
      "1298/1298 07:09<00:00 , loss=0.0403, lr=0.000124, step=32450\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 25 | DICE 0.6906408581046645\n",
      "[0.69598541 0.70001627 0.69704857 0.69799003 0.69137508 0.6840358\n",
      " 0.68129193 0.68968946 0.68525315 0.69208306 0.69231793 0.69099776\n",
      " 0.68940439 0.68148317]\n",
      "1298/1298 07:07<00:00 , loss=0.0399, lr=0.000114, step=33748\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 26 | DICE 0.6952245533393544\n",
      "[0.70224233 0.70497553 0.70284719 0.69980707 0.69722356 0.68938422\n",
      " 0.68440844 0.69382725 0.69151896 0.69905194 0.69380117 0.6952618\n",
      " 0.69455947 0.68423482]\n",
      "1298/1298 07:12<00:00 , loss=0.0396, lr=0.000104, step=35046\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 27 | DICE 0.693694926733308\n",
      "[0.70181747 0.70509973 0.70459197 0.70089462 0.69339459 0.68782218\n",
      " 0.6828115  0.69264162 0.68841119 0.69520209 0.69256771 0.69332925\n",
      " 0.69136455 0.68178049]\n",
      "1298/1298 07:08<00:00 , loss=0.0398, lr=9.38e-5, step=36344\n",
      "433/433 01:51<00:00 \n",
      "EPOCH 28 | DICE 0.6920628903446228\n",
      "[0.69998425 0.70232311 0.70143532 0.69867691 0.69418546 0.68601723\n",
      " 0.68193285 0.69093521 0.68593903 0.69396303 0.68995946 0.69275172\n",
      " 0.69052384 0.68025305]\n",
      "1298/1298 07:13<00:00 , loss=0.0395, lr=8.42e-5, step=37642\n",
      "433/433 01:50<00:00 \n",
      "EPOCH 29 | DICE 0.6918650491374443\n",
      "[0.69844588 0.70271995 0.69854121 0.69787668 0.69342142 0.6863875\n",
      " 0.68054847 0.69089666 0.68600429 0.69434172 0.69113439 0.69296874\n",
      " 0.69197449 0.68084929]\n",
      "1298/1298 07:09<00:00 , loss=0.0396, lr=7.5e-5, step=38940 \n",
      "433/433 01:52<00:00 \n",
      "EPOCH 30 | DICE 0.6911266620969712\n",
      "[0.69681392 0.70114545 0.70037085 0.69765253 0.69154658 0.68476262\n",
      " 0.67968568 0.69038389 0.68432311 0.69366622 0.68966038 0.6912618\n",
      " 0.69339913 0.68110112]\n",
      "[rank0]:[W308 06:28:35.519517257 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"3\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e070a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78e2d182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 35322 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 17:03:53.582495 1333870 site-packages/torch/distributed/run.py:792] \n",
      "W0308 17:03:53.582495 1333870 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 17:03:53.582495 1333870 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 17:03:53.582495 1333870 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W308 17:03:58.497302455 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W308 17:03:58.643508458 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 02:29<00:00 , loss=0.406, lr=0.0003, step=662\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 1 | AUC 0.7807513064993219\n",
      "SAVING BEST!\n",
      "662/662 02:29<00:00 , loss=0.373, lr=0.000299, step=1324\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 2 | AUC 0.8364957181362636\n",
      "SAVING BEST!\n",
      "662/662 02:29<00:00 , loss=0.35, lr=0.000297, step=1986 \n",
      "221/221 00:39<00:00 \n",
      "EPOCH 3 | AUC 0.8497519171241947\n",
      "SAVING BEST!\n",
      "662/662 02:29<00:00 , loss=0.329, lr=0.000294, step=2648\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 4 | AUC 0.8531024237313674\n",
      "SAVING BEST!\n",
      "662/662 02:28<00:00 , loss=0.306, lr=0.000291, step=3310\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 5 | AUC 0.8511811141568928\n",
      "662/662 02:50<00:00 , loss=0.281, lr=0.000287, step=3972\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 6 | AUC 0.8417565201607538\n",
      "662/662 02:29<00:00 , loss=0.26, lr=0.000282, step=4634 \n",
      "221/221 00:40<00:00 \n",
      "EPOCH 7 | AUC 0.8399682616047363\n",
      "662/662 02:30<00:00 , loss=0.253, lr=0.000277, step=5296\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 8 | AUC 0.8347695794266119\n",
      "662/662 02:30<00:00 , loss=0.242, lr=0.000271, step=5958\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 9 | AUC 0.8187545543539845\n",
      "662/662 02:30<00:00 , loss=0.239, lr=0.000265, step=6620\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 10 | AUC 0.8231928191219866\n",
      "662/662 02:29<00:00 , loss=0.232, lr=0.000258, step=7282\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 11 | AUC 0.8215825493456268\n",
      "662/662 02:31<00:00 , loss=0.233, lr=0.00025, step=7944 \n",
      "221/221 00:40<00:00 \n",
      "EPOCH 12 | AUC 0.7972135063525253\n",
      "662/662 02:29<00:00 , loss=0.23, lr=0.000242, step=8606 \n",
      "221/221 00:40<00:00 \n",
      "EPOCH 13 | AUC 0.831323469935316\n",
      "662/662 02:30<00:00 , loss=0.227, lr=0.000234, step=9268\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 14 | AUC 0.7985915976960146\n",
      "662/662 02:29<00:00 , loss=0.225, lr=0.000225, step=9930\n",
      "221/221 00:40<00:00 \n",
      "EPOCH 15 | AUC 0.8127403839799525\n",
      "662/662 02:29<00:00 , loss=0.221, lr=0.000216, step=10592\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 16 | AUC 0.8094630113763026\n",
      "662/662 02:30<00:00 , loss=0.225, lr=0.000206, step=11254\n",
      "221/221 00:39<00:00 \n",
      "EPOCH 17 | AUC 0.7959411509177435\n",
      "411/662 01:33<00:55 , loss=0.219, lr=0.0002, step=11665  "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"4\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3735f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d629c501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 39887 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 22:57:48.623129 1377373 site-packages/torch/distributed/run.py:792] \n",
      "W0308 22:57:48.623129 1377373 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 22:57:48.623129 1377373 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 22:57:48.623129 1377373 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W308 22:57:53.630963524 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W308 22:57:53.698823454 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:48<00:00 , loss=0.406, lr=0.000298, step=662\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7766271654934387 LOSS 0.6947214603424072\n",
      "SAVING BEST!\n",
      "662/662 03:46<00:00 , loss=0.374, lr=0.000293, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8259675055929889 LOSS 0.5826429724693298\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.352, lr=0.000285, step=1986\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.848828049621862 LOSS 0.5323999524116516\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.332, lr=0.000273, step=2648\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.8596532038420905 LOSS 0.55532306432724\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.31, lr=0.000259, step=3310 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8560537772831687 LOSS 0.5311465263366699\n",
      "662/662 03:47<00:00 , loss=0.275, lr=0.000243, step=3972\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8454427382780731 LOSS 0.6759728193283081\n",
      "662/662 03:46<00:00 , loss=0.255, lr=0.000224, step=4634\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.8256013950090889 LOSS 0.7572301030158997\n",
      "662/662 03:47<00:00 , loss=0.243, lr=0.000203, step=5296\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8229954454257324 LOSS 0.7164457440376282\n",
      "662/662 03:46<00:00 , loss=0.236, lr=0.000181, step=5958\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 9 | AUC 0.8301330598297828 LOSS 1.0190649032592773\n",
      "662/662 03:46<00:00 , loss=0.228, lr=0.000159, step=6620\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 10 | AUC 0.8288501308041305 LOSS 0.9045683741569519\n",
      "116/662 00:42<03:19 , loss=0.221, lr=0.000155, step=6736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7290fa60e1f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"5\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0959d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af0322b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 39784 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0308 23:56:17.391054 1384992 site-packages/torch/distributed/run.py:792] \n",
      "W0308 23:56:17.391054 1384992 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0308 23:56:17.391054 1384992 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0308 23:56:17.391054 1384992 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W308 23:56:22.471179263 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W308 23:56:22.511394008 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:46<00:00 , loss=0.567, lr=0.000298, step=662\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7513672974694754 LOSS 0.6016578674316406\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.499, lr=0.000293, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8024377413752539 LOSS 0.5360937714576721\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.443, lr=0.000285, step=1986\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8284637541710613 LOSS 0.5062417984008789\n",
      "SAVING BEST!\n",
      "662/662 03:46<00:00 , loss=0.391, lr=0.000273, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8404246882773242 LOSS 0.4695238173007965\n",
      "SAVING BEST!\n",
      "662/662 03:46<00:00 , loss=0.315, lr=0.000259, step=3310\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8449924795334932 LOSS 0.43330663442611694\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.225, lr=0.000243, step=3972\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8337020873149512 LOSS 0.5356934666633606\n",
      "662/662 03:57<00:00 , loss=0.132, lr=0.000224, step=4634 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.8338976987460602 LOSS 0.5619690418243408\n",
      "662/662 03:47<00:00 , loss=0.102, lr=0.000203, step=5296 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8283011852114234 LOSS 0.7756491303443909\n",
      "320/662 01:51<01:56 , loss=0.0547, lr=0.000193, step=5616"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function PtyProcess.__del__ at 0x7290fbeaf040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ptyprocess/ptyprocess.py\", line 370, in __del__\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"6\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e254ebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e612825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 36308 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 01:40:51.495298 1398744 site-packages/torch/distributed/run.py:792] \n",
      "W0309 01:40:51.495298 1398744 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 01:40:51.495298 1398744 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 01:40:51.495298 1398744 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W309 01:40:56.766718589 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 01:40:56.798354900 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:46<00:00 , loss=0.554, lr=9.94e-5, step=662\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7802424524386665 LOSS 0.6148620247840881\n",
      "SAVING BEST!\n",
      "662/662 03:46<00:00 , loss=0.42, lr=9.77e-5, step=1324 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8620877731400833 LOSS 0.40949976444244385\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.284, lr=9.5e-5, step=1986 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8598448501766229 LOSS 0.40327155590057373\n",
      "662/662 03:46<00:00 , loss=0.163, lr=9.11e-5, step=2648\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.835125116419641 LOSS 0.5426503419876099\n",
      "34/662 00:12<03:30 , loss=0.131, lr=9.09e-5, step=2682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"7\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e58c615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 36438 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 02:37:19.095382 1406366 site-packages/torch/distributed/run.py:792] \n",
      "W0309 02:37:19.095382 1406366 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 02:37:19.095382 1406366 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 02:37:19.095382 1406366 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 02:37:24.009879727 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 02:37:24.195386636 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:47<00:00 , loss=0.55, lr=9.94e-5, step=662 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.8063583407568753 LOSS 0.5342360734939575\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.421, lr=9.77e-5, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.86782174335604 LOSS 0.4002719521522522\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.306, lr=9.5e-5, step=1986 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8749738964475379 LOSS 0.3886791169643402\n",
      "SAVING BEST!\n",
      "662/662 03:46<00:00 , loss=0.239, lr=9.11e-5, step=2648\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.8713061821142425 LOSS 0.43357551097869873\n",
      "662/662 03:46<00:00 , loss=0.182, lr=8.64e-5, step=3310\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8730058868467174 LOSS 0.41396039724349976\n",
      "662/662 03:46<00:00 , loss=0.126, lr=8.08e-5, step=3972 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8735750984885933 LOSS 0.5734280943870544\n",
      "514/662 02:57<00:51 , loss=0.083, lr=7.6e-5, step=4486  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(filedata)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#!python \"{DIR}/{NAME}_v{V}/run.py\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/run.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | tee \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/log_\u001b[39;49m\u001b[38;5;132;43;01m{F}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:650\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGINT)\n\u001b[0;32m--> 650\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"8\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3e666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dc500b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 36571 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 03:38:26.256060 1413974 site-packages/torch/distributed/run.py:792] \n",
      "W0309 03:38:26.256060 1413974 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 03:38:26.256060 1413974 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 03:38:26.256060 1413974 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 03:38:31.251652860 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 03:38:31.411347958 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:47<00:00 , loss=0.556, lr=9.94e-5, step=662\n",
      "221/221 00:45<00:00 \n",
      "EPOCH 1 | AUC 0.7950767598640589 LOSS 0.5641025900840759\n",
      "SAVING BEST!\n",
      "662/662 03:51<00:00 , loss=0.437, lr=9.77e-5, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8713691830931807 LOSS 0.3989844024181366\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.359, lr=9.5e-5, step=1986 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.881521592594257 LOSS 0.3759911358356476\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.309, lr=9.11e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8834534757596023 LOSS 0.42170029878616333\n",
      "SAVING BEST!\n",
      "662/662 03:59<00:00 , loss=0.26, lr=8.64e-5, step=3310 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8879406433853818 LOSS 0.38650190830230713\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.207, lr=8.08e-5, step=3972\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8802267682788749 LOSS 0.4459366500377655\n",
      "662/662 03:47<00:00 , loss=0.166, lr=7.46e-5, step=4634\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8879851405802963 LOSS 0.37780922651290894\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.132, lr=6.77e-5, step=5296\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.885343505127751 LOSS 0.4826476275920868\n",
      "662/662 03:48<00:00 , loss=0.0961, lr=6.05e-5, step=5958\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8733874172506373 LOSS 0.4943036437034607\n",
      "662/662 03:47<00:00 , loss=0.104, lr=5.3e-5, step=6620  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(filedata)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#!python \"{DIR}/{NAME}_v{V}/run.py\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/run.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | tee \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/log_\u001b[39;49m\u001b[38;5;132;43;01m{F}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"9\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51f3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b86c5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 36574 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 04:23:40.308286 1420099 site-packages/torch/distributed/run.py:792] \n",
      "W0309 04:23:40.308286 1420099 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 04:23:40.308286 1420099 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 04:23:40.308286 1420099 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 04:23:45.905731896 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 04:23:45.911663299 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:47<00:00 , loss=0.556, lr=9.85e-5, step=662\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7952485807157087 LOSS 0.562808096408844\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.44, lr=9.43e-5, step=1324 \n",
      "221/221 00:46<00:00 \n",
      "EPOCH 2 | AUC 0.867364876117166 LOSS 0.40784645080566406\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.357, lr=8.74e-5, step=1986\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8673045185359454 LOSS 0.3767800033092499\n",
      "662/662 03:48<00:00 , loss=0.297, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8740099374131534 LOSS 0.3897135555744171\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.249, lr=6.77e-5, step=3310\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8727900093664392 LOSS 0.4211992621421814\n",
      "662/662 03:48<00:00 , loss=0.174, lr=5.6e-5, step=3972 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8745522745115661 LOSS 0.4572210907936096\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.132, lr=4.4e-5, step=4634 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8739724892788194 LOSS 0.41047438979148865\n",
      "662/662 03:48<00:00 , loss=0.109, lr=3.23e-5, step=5296 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8694298103009684 LOSS 0.49728381633758545\n",
      "662/662 03:47<00:00 , loss=0.0784, lr=2.16e-5, step=5958\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8716260332380829 LOSS 0.5025926232337952\n",
      "662/662 03:48<00:00 , loss=0.0677, lr=1.26e-5, step=6620\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 10 | AUC 0.8725080469432189 LOSS 0.6294639110565186\n",
      "[rank0]:[W309 05:09:20.432401396 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"10\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daffd1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985871c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 36620 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 06:00:54.551769 1433152 site-packages/torch/distributed/run.py:792] \n",
      "W0309 06:00:54.551769 1433152 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 06:00:54.551769 1433152 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 06:00:54.551769 1433152 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 06:01:00.415057882 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 06:01:00.424680825 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:48<00:00 , loss=0.56, lr=9.85e-5, step=662 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7756181135049182 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.459, lr=9.43e-5, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8512912837904395 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.379, lr=8.74e-5, step=1986\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 3 | AUC 0.870148670897654 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.31, lr=7.84e-5, step=2648 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.8797783304954758 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.241, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8793135140649846 LOSS -1\n",
      "662/662 03:47<00:00 , loss=0.193, lr=5.6e-5, step=3972 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8745096780321686 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.144, lr=4.4e-5, step=4634 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8710470814629272 LOSS -1\n",
      "662/662 03:49<00:00 , loss=0.122, lr=3.23e-5, step=5296\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8610603443423441 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.0867, lr=2.16e-5, step=5958\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.858536615397605 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.0723, lr=1.26e-5, step=6620\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 10 | AUC 0.8577789250383463 LOSS -1\n",
      "[rank0]:[W309 06:46:23.437817296 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 06:46:26.856393 1440770 site-packages/torch/distributed/run.py:792] \n",
      "W0309 06:46:26.856393 1440770 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 06:46:26.856393 1440770 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 06:46:26.856393 1440770 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W309 06:46:32.592370938 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 06:46:32.613905380 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:49<00:00 , loss=0.557, lr=9.85e-5, step=662\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 1 | AUC 0.8231878123671752 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.448, lr=9.43e-5, step=1324\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 2 | AUC 0.8795485607293086 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.357, lr=8.74e-5, step=1986\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8796044387284 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.275, lr=7.84e-5, step=2648\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 4 | AUC 0.8905409539931701 LOSS -1\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.232, lr=6.77e-5, step=3310\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8865864405164959 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.185, lr=5.6e-5, step=3972 \n",
      "221/221 00:41<00:00 \n",
      "EPOCH 6 | AUC 0.8849242990517229 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.133, lr=4.4e-5, step=4634 \n",
      "221/221 00:41<00:00 \n",
      "EPOCH 7 | AUC 0.8853172771109059 LOSS -1\n",
      "662/662 03:46<00:00 , loss=0.0981, lr=3.23e-5, step=5296\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8773569523223262 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.0853, lr=2.16e-5, step=5958\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 9 | AUC 0.8859090342816105 LOSS -1\n",
      "662/662 03:48<00:00 , loss=0.0618, lr=1.26e-5, step=6620\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 10 | AUC 0.8835905553357076 LOSS -1\n",
      "[rank0]:[W309 07:31:50.254956212 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 07:31:53.875276 1446719 site-packages/torch/distributed/run.py:792] \n",
      "W0309 07:31:53.875276 1446719 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 07:31:53.875276 1446719 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 07:31:53.875276 1446719 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W309 07:31:59.907397570 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 07:31:59.929486793 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/662 03:47<00:00 , loss=0.531, lr=9.85e-5, step=662\n",
      "221/221 00:41<00:00 \n",
      "EPOCH 1 | AUC 0.7818606461017781 LOSS 0.5596954226493835\n",
      "SAVING BEST!\n",
      "662/662 03:50<00:00 , loss=0.427, lr=9.43e-5, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8580530731749052 LOSS 0.40023186802864075\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.33, lr=8.74e-5, step=1986 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8683503254037005 LOSS 0.3845812976360321\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.276, lr=7.84e-5, step=2648\n",
      "221/221 00:47<00:00 \n",
      "EPOCH 4 | AUC 0.8710819724457803 LOSS 0.3947499394416809\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.233, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8686308529270703 LOSS 0.40182799100875854\n",
      "662/662 03:47<00:00 , loss=0.168, lr=5.6e-5, step=3972 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8642106934459393 LOSS 0.4144259989261627\n",
      "662/662 03:48<00:00 , loss=0.134, lr=4.4e-5, step=4634 \n",
      "221/221 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8656626907443192 LOSS 0.436232328414917\n",
      "662/662 03:49<00:00 , loss=0.108, lr=3.23e-5, step=5296\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8656532301386924 LOSS 0.4553343653678894\n",
      "662/662 03:48<00:00 , loss=0.0788, lr=2.16e-5, step=5958\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8653225202724326 LOSS 0.5317840576171875\n",
      "662/662 03:49<00:00 , loss=0.0659, lr=1.26e-5, step=6620\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 10 | AUC 0.8646775537670899 LOSS 0.5447156429290771\n",
      "[rank0]:[W309 08:17:36.513845070 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"10\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02f4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9056ca81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 37549 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 14:00:34.778814 1492898 site-packages/torch/distributed/run.py:792] \n",
      "W0309 14:00:34.778814 1492898 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 14:00:34.778814 1492898 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 14:00:34.778814 1492898 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 14:00:39.924604966 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 14:00:40.943722237 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:51<00:00 , loss=0.56, lr=9.85e-5, step=662 \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 1 | AUC 0.7883775089148589 LOSS 0.5487203598022461\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.448, lr=9.43e-5, step=1324\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 2 | AUC 0.8678472962006445 LOSS 0.41530537605285645\n",
      "SAVING BEST!\n",
      "662/662 03:50<00:00 , loss=0.359, lr=8.74e-5, step=1986\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 3 | AUC 0.880866470526556 LOSS 0.3796146810054779\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.304, lr=7.84e-5, step=2648\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 4 | AUC 0.8813017500174024 LOSS 0.4170685410499573\n",
      "662/662 03:50<00:00 , loss=0.251, lr=6.77e-5, step=3310\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 5 | AUC 0.8715498152705561 LOSS 0.432181179523468\n",
      "662/662 03:48<00:00 , loss=0.19, lr=5.6e-5, step=3972  \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 6 | AUC 0.8711312772985885 LOSS 0.4296959638595581\n",
      "662/662 03:49<00:00 , loss=0.146, lr=4.4e-5, step=4634 \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 7 | AUC 0.8754664495556008 LOSS 0.42298588156700134\n",
      "662/662 03:49<00:00 , loss=0.119, lr=3.23e-5, step=5296\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 8 | AUC 0.8741716252402187 LOSS 0.48279649019241333\n",
      "662/662 03:50<00:00 , loss=0.0879, lr=2.16e-5, step=5958\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 9 | AUC 0.8789270977343439 LOSS 0.5254629254341125\n",
      "662/662 03:49<00:00 , loss=0.0728, lr=1.26e-5, step=6620\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 10 | AUC 0.8790694006448128 LOSS 0.6082132458686829\n",
      "[rank0]:[W309 14:46:42.008245327 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 14:46:45.589069 1499027 site-packages/torch/distributed/run.py:792] \n",
      "W0309 14:46:45.589069 1499027 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 14:46:45.589069 1499027 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 14:46:45.589069 1499027 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 14:46:56.540888747 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 14:46:56.592278741 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:48<00:00 , loss=0.566, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 527, in calculate_competition_metric\n",
      "[rank0]:     pred_df[f'C{C}'].append(prediction[C-1])\n",
      "[rank0]: IndexError: index 6 is out of bounds for axis 0 with size 6\n",
      "\n",
      "[rank0]: During handling of the above exception, another exception occurred:\n",
      "\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 852, in <module>\n",
      "[rank0]:     run(model, get_loaders)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 781, in run\n",
      "[rank0]:     score = valid_one_epoch(f\"{OUTPUT_FOLDER}/{CFG.FOLD}_EMA.pth\", valid_loader, debug=False, running_dist=CFG.DDP_INIT_DONE)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 734, in valid_one_epoch\n",
      "[rank0]:     loss = calculate_competition_metric(OUTPUTS, TARGETS, IDS)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 529, in calculate_competition_metric\n",
      "[rank0]:     pred_Df[f'C{C}'].append(prediction.mean())\n",
      "[rank0]: NameError: name 'pred_Df' is not defined\n",
      "[rank0]:[W309 14:51:32.077181175 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W0309 14:51:33.523392 1499027 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1499087 closing signal SIGTERM\n",
      "E0309 14:51:33.988489 1499027 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1499086) of binary: /home/harshit/anaconda3/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 208, in <module>\n",
      "    main()\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/typing_extensions.py\", line 2853, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 204, in main\n",
      "    launch(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 189, in launch\n",
      "    run(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-03-09_14:51:33\n",
      "  host      : harshit\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1499086)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 14:51:35.772627 1499717 site-packages/torch/distributed/run.py:792] \n",
      "W0309 14:51:35.772627 1499717 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 14:51:35.772627 1499717 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 14:51:35.772627 1499717 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 14:51:41.660893506 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 14:51:41.661134349 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:49<00:00 , loss=0.565, lr=9.85e-5, step=662\n",
      "221/221 00:44<00:00 \n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 527, in calculate_competition_metric\n",
      "[rank0]:     pred_df[f'C{C}'].append(prediction[C-1])\n",
      "[rank0]: IndexError: index 5 is out of bounds for axis 0 with size 5\n",
      "\n",
      "[rank0]: During handling of the above exception, another exception occurred:\n",
      "\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 852, in <module>\n",
      "[rank0]:     run(model, get_loaders)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 781, in run\n",
      "[rank0]:     score = valid_one_epoch(f\"{OUTPUT_FOLDER}/{CFG.FOLD}_EMA.pth\", valid_loader, debug=False, running_dist=CFG.DDP_INIT_DONE)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 734, in valid_one_epoch\n",
      "[rank0]:     loss = calculate_competition_metric(OUTPUTS, TARGETS, IDS)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/classification/./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py\", line 529, in calculate_competition_metric\n",
      "[rank0]:     pred_Df[f'C{C}'].append(prediction.mean())\n",
      "[rank0]: NameError: name 'pred_Df' is not defined\n",
      "[rank0]:[W309 14:56:18.822198728 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W0309 14:56:20.298506 1499717 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1499777 closing signal SIGTERM\n",
      "E0309 14:56:20.814425 1499717 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1499776) of binary: /home/harshit/anaconda3/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 208, in <module>\n",
      "    main()\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/typing_extensions.py\", line 2853, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 204, in main\n",
      "    launch(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 189, in launch\n",
      "    run(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "./data/classification_model//tf_efficientnetv2_s.in21k_ft_in1k_v11/run.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-03-09_14:56:20\n",
      "  host      : harshit\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1499776)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 14:56:22.554958 1500412 site-packages/torch/distributed/run.py:792] \n",
      "W0309 14:56:22.554958 1500412 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 14:56:22.554958 1500412 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 14:56:22.554958 1500412 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 14:56:27.808798842 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank1]:[W309 14:56:27.872719774 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "127/662 00:45<03:04 , loss=0.597, lr=9.99e-5, step=127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x725eb404e1f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"11\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf18005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6468d631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 37549 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 14:57:32.934823 1500665 site-packages/torch/distributed/run.py:792] \n",
      "W0309 14:57:32.934823 1500665 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 14:57:32.934823 1500665 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 14:57:32.934823 1500665 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 14:57:37.820408609 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 14:57:38.974483931 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:49<00:00 , loss=0.566, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 1 | AUC 0.7750574314340797 LOSS 0.5538880228996277\n",
      "SAVING BEST!\n",
      "662/662 03:51<00:00 , loss=0.47, lr=9.43e-5, step=1324 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8289466740779308 LOSS 0.4788421094417572\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.38, lr=8.74e-5, step=1986 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8587419789482572 LOSS 0.4230944812297821\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.307, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8725897267213599 LOSS 0.37338683009147644\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.233, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.87231048506255 LOSS 0.37460511922836304\n",
      "662/662 03:50<00:00 , loss=0.195, lr=5.6e-5, step=3972 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8774538085923758 LOSS 0.39096587896347046\n",
      "30/662 00:11<03:33 , loss=0.158, lr=5.55e-5, step=4003"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"11\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9ab81a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 37549 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 15:39:13.281988 1506396 site-packages/torch/distributed/run.py:792] \n",
      "W0309 15:39:13.281988 1506396 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 15:39:13.281988 1506396 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 15:39:13.281988 1506396 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W309 15:39:18.435619783 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 15:39:18.446694593 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:49<00:00 , loss=0.565, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 1 | AUC 0.8054639522783568 LOSS 0.5087397694587708\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.455, lr=9.43e-5, step=1324\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8766090115639977 LOSS 0.39630696177482605\n",
      "SAVING BEST!\n",
      "662/662 03:53<00:00 , loss=0.373, lr=8.74e-5, step=1986\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8829406300839819 LOSS 0.39684242010116577\n",
      "662/662 03:48<00:00 , loss=0.291, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8973782226032918 LOSS 0.33598557114601135\n",
      "SAVING BEST!\n",
      "662/662 03:48<00:00 , loss=0.23, lr=6.77e-5, step=3310 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.9008472387108122 LOSS 0.34182101488113403\n",
      "662/662 03:48<00:00 , loss=0.181, lr=5.6e-5, step=3972 \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 6 | AUC 0.8961713494261971 LOSS 0.36465364694595337\n",
      "662/662 03:49<00:00 , loss=0.131, lr=4.4e-5, step=4634 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.8976937958932418 LOSS 0.409584105014801\n",
      "662/662 03:48<00:00 , loss=0.114, lr=3.23e-5, step=5296 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8947047809582436 LOSS 0.4226665198802948\n",
      "478/662 02:46<01:03 , loss=0.0821, lr=2.44e-5, step=5774^C\n",
      "W0309 16:18:46.238899 1506396 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0309 16:18:46.240207 1506396 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1506446 closing signal SIGINT\n",
      "W0309 16:18:46.240485 1506396 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1506447 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 16:18:48.437556 1513128 site-packages/torch/distributed/run.py:792] \n",
      "W0309 16:18:48.437556 1513128 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 16:18:48.437556 1513128 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 16:18:48.437556 1513128 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W309 16:18:53.669102892 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 16:18:53.719855374 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 03:48<00:00 , loss=0.538, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 1 | AUC 0.778203916361665 LOSS 0.5617588758468628\n",
      "SAVING BEST!\n",
      "662/662 03:49<00:00 , loss=0.444, lr=9.43e-5, step=1324\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8525918357441423 LOSS 0.408130019903183\n",
      "SAVING BEST!\n",
      "662/662 03:59<00:00 , loss=0.353, lr=8.74e-5, step=1986\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8579025261462346 LOSS 0.39654242992401123\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.302, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8772663292109772 LOSS 0.3844883143901825\n",
      "SAVING BEST!\n",
      "662/662 03:47<00:00 , loss=0.235, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8763461824810972 LOSS 0.41227665543556213\n",
      "662/662 03:48<00:00 , loss=0.168, lr=5.6e-5, step=3972 \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 6 | AUC 0.864223033366322 LOSS 0.49433112144470215\n",
      "41/662 00:15<03:32 , loss=0.166, lr=5.53e-5, step=4013 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x767243e8e1f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x767243e8e1f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(filedata)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#!python \"{DIR}/{NAME}_v{V}/run.py\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/run.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | tee \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/log_\u001b[39;49m\u001b[38;5;132;43;01m{F}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"11\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(2, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329ecef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87013707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 39940 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 19:16:34.878287 1537707 site-packages/torch/distributed/run.py:792] \n",
      "W0309 19:16:34.878287 1537707 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 19:16:34.878287 1537707 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 19:16:34.878287 1537707 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 19:16:40.978547629 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 19:16:40.072896277 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 05:54<00:00 , loss=1.15, lr=9.85e-5, step=662\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 1 | AUC 0.8081435153488887 LOSS 0.5524080395698547\n",
      "SAVING BEST!\n",
      "662/662 05:56<00:00 , loss=0.842, lr=9.43e-5, step=1324\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 2 | AUC 0.8508973894685272 LOSS 0.4346892237663269\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.7, lr=8.74e-5, step=1986  \n",
      "221/221 00:44<00:00 \n",
      "EPOCH 3 | AUC 0.8742914592700874 LOSS 0.3965553939342499\n",
      "SAVING BEST!\n",
      "662/662 05:55<00:00 , loss=0.625, lr=7.84e-5, step=2648\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 4 | AUC 0.8744535876634391 LOSS 0.40177950263023376\n",
      "662/662 05:55<00:00 , loss=0.572, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.884976072844992 LOSS 0.3542584478855133\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.506, lr=5.6e-5, step=3972 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8864118783719843 LOSS 0.3856930732727051\n",
      "662/662 05:54<00:00 , loss=0.425, lr=4.4e-5, step=4634 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.8816581681430042 LOSS 0.4291192889213562\n",
      "662/662 05:54<00:00 , loss=0.397, lr=3.23e-5, step=5296\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8817004625064874 LOSS 0.412691205739975\n",
      "662/662 05:55<00:00 , loss=0.352, lr=2.16e-5, step=5958\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 9 | AUC 0.8732706671847725 LOSS 0.4618540406227112\n",
      "662/662 05:54<00:00 , loss=0.336, lr=1.26e-5, step=6620\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 10 | AUC 0.87486463600854 LOSS 0.5379378199577332\n",
      "[rank0]:[W309 20:23:28.700021971 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 20:23:32.201774 1546418 site-packages/torch/distributed/run.py:792] \n",
      "W0309 20:23:32.201774 1546418 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 20:23:32.201774 1546418 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 20:23:32.201774 1546418 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 20:23:37.304460275 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 20:23:37.375054636 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 05:55<00:00 , loss=1.16, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 1 | AUC 0.7812082236888396 LOSS 0.5455222725868225\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.858, lr=9.43e-5, step=1324\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8253886516189859 LOSS 0.45764636993408203\n",
      "SAVING BEST!\n",
      "662/662 05:53<00:00 , loss=0.705, lr=8.74e-5, step=1986\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8509487180389232 LOSS 0.4233047664165497\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.62, lr=7.84e-5, step=2648 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8689833316915976 LOSS 0.37006810307502747\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.55, lr=6.77e-5, step=3310 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8686948552692682 LOSS 0.400495320558548\n",
      "662/662 05:55<00:00 , loss=0.506, lr=5.6e-5, step=3972 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 6 | AUC 0.8682889654250454 LOSS 0.41460999846458435\n",
      "662/662 05:54<00:00 , loss=0.45, lr=4.4e-5, step=4634  \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.871495627119598 LOSS 0.43457505106925964\n",
      "662/662 05:55<00:00 , loss=0.398, lr=3.23e-5, step=5296\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 8 | AUC 0.8740576143703473 LOSS 0.4458136558532715\n",
      "662/662 05:55<00:00 , loss=0.354, lr=2.16e-5, step=5958\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 9 | AUC 0.8680295125452064 LOSS 0.5028127431869507\n",
      "182/662 01:37<04:15 , loss=0.305, lr=1.89e-5, step=6140^C\n",
      "W0309 21:25:20.292383 1546418 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0309 21:25:20.293365 1546418 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1546468 closing signal SIGINT\n",
      "W0309 21:25:20.293641 1546418 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1546469 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 21:25:22.349210 1554583 site-packages/torch/distributed/run.py:792] \n",
      "W0309 21:25:22.349210 1554583 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 21:25:22.349210 1554583 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 21:25:22.349210 1554583 site-packages/torch/distributed/run.py:792] *****************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank1]:[W309 21:25:27.303267141 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W309 21:25:27.387945670 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 05:54<00:00 , loss=1.15, lr=9.85e-5, step=662\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 1 | AUC 0.814403058083806 LOSS 0.5181970000267029\n",
      "SAVING BEST!\n",
      "662/662 05:53<00:00 , loss=0.863, lr=9.43e-5, step=1324\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8728972467719005 LOSS 0.4044121205806732\n",
      "SAVING BEST!\n",
      "662/662 05:52<00:00 , loss=0.708, lr=8.74e-5, step=1986\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8837059754649783 LOSS 0.39425960183143616\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.619, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8923743935863049 LOSS 0.34472084045410156\n",
      "SAVING BEST!\n",
      "662/662 05:53<00:00 , loss=0.561, lr=6.77e-5, step=3310\n",
      "25/221 00:05<00:37 "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"12\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c32bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b48f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 39940 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0309 22:22:03.920857 1562375 site-packages/torch/distributed/run.py:792] \n",
      "W0309 22:22:03.920857 1562375 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0309 22:22:03.920857 1562375 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0309 22:22:03.920857 1562375 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W309 22:22:09.979177659 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W309 22:22:09.032699575 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "662/662 05:54<00:00 , loss=1.14, lr=9.85e-5, step=662\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.7665957532575334 LOSS 0.5728784203529358\n",
      "SAVING BEST!\n",
      "662/662 05:53<00:00 , loss=0.866, lr=9.43e-5, step=1324\n",
      "221/221 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8334267053975635 LOSS 0.4609724283218384\n",
      "SAVING BEST!\n",
      "662/662 05:54<00:00 , loss=0.714, lr=8.74e-5, step=1986\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 3 | AUC 0.8538266504437846 LOSS 0.4198792576789856\n",
      "SAVING BEST!\n",
      "662/662 05:53<00:00 , loss=0.619, lr=7.84e-5, step=2648\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.863397081362031 LOSS 0.42217305302619934\n",
      "662/662 05:54<00:00 , loss=0.534, lr=6.77e-5, step=3310\n",
      "221/221 00:43<00:00 \n",
      "EPOCH 5 | AUC 0.8780947491993447 LOSS 0.3816215395927429\n",
      "SAVING BEST!\n",
      "662/662 06:00<00:00 , loss=0.481, lr=5.6e-5, step=3972 \n",
      "221/221 00:48<00:00 \n",
      "EPOCH 6 | AUC 0.8778767439392481 LOSS 0.38651806116104126\n",
      "662/662 06:03<00:00 , loss=0.433, lr=4.4e-5, step=4634 \n",
      "221/221 00:43<00:00 \n",
      "EPOCH 7 | AUC 0.875544910317572 LOSS 0.40415239334106445\n",
      "662/662 05:55<00:00 , loss=0.391, lr=3.23e-5, step=5296\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 8 | AUC 0.8724615755445813 LOSS 0.4358873963356018\n",
      "662/662 05:56<00:00 , loss=0.351, lr=2.16e-5, step=5958\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 9 | AUC 0.8776916451335056 LOSS 0.4291060268878937\n",
      "662/662 05:55<00:00 , loss=0.325, lr=1.26e-5, step=6620\n",
      "221/221 00:44<00:00 \n",
      "EPOCH 10 | AUC 0.8813302763237237 LOSS 0.45777004957199097\n",
      "[rank0]:[W309 23:29:08.757145241 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"12\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(3, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35575d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472daf26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 40354 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0310 02:53:31.392318 1597332 site-packages/torch/distributed/run.py:792] \n",
      "W0310 02:53:31.392318 1597332 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0310 02:53:31.392318 1597332 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0310 02:53:31.392318 1597332 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W310 02:53:36.351400862 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W310 02:53:36.383687147 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "1324/1324 09:05<00:00 , loss=1.09, lr=9.85e-5, step=1324\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 1 | AUC 0.7953190713215138 LOSS 0.563512921333313\n",
      "SAVING BEST!\n",
      "1324/1324 09:06<00:00 , loss=0.859, lr=9.43e-5, step=2648\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 2 | AUC 0.830446302459329 LOSS 0.4536295533180237\n",
      "SAVING BEST!\n",
      "1324/1324 09:06<00:00 , loss=0.714, lr=8.74e-5, step=3972\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 3 | AUC 0.8517701512816513 LOSS 0.4429275393486023\n",
      "SAVING BEST!\n",
      "1324/1324 09:05<00:00 , loss=0.642, lr=7.84e-5, step=5296\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 4 | AUC 0.8734750899416073 LOSS 0.38725462555885315\n",
      "SAVING BEST!\n",
      "1324/1324 09:06<00:00 , loss=0.604, lr=6.77e-5, step=6620\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 5 | AUC 0.8709590158806523 LOSS 0.3966350555419922\n",
      "1324/1324 09:06<00:00 , loss=0.537, lr=5.6e-5, step=7944 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 6 | AUC 0.8852800635825264 LOSS 0.38242897391319275\n",
      "SAVING BEST!\n",
      "1324/1324 09:05<00:00 , loss=0.498, lr=4.4e-5, step=9268 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 7 | AUC 0.8851205785868924 LOSS 0.37414276599884033\n",
      "SAVING BEST!\n",
      "1324/1324 09:07<00:00 , loss=0.451, lr=3.23e-5, step=10592\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 8 | AUC 0.8871639250226672 LOSS 0.38089123368263245\n",
      "1324/1324 09:04<00:00 , loss=0.431, lr=2.16e-5, step=11916\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 9 | AUC 0.8812272943150208 LOSS 0.38478410243988037\n",
      "1324/1324 09:07<00:00 , loss=0.386, lr=1.26e-5, step=13240\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 10 | AUC 0.8840623383672437 LOSS 0.39252012968063354\n",
      "[rank0]:[W310 04:36:09.861281601 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0310 04:36:13.080691 1609911 site-packages/torch/distributed/run.py:792] \n",
      "W0310 04:36:13.080691 1609911 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0310 04:36:13.080691 1609911 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0310 04:36:13.080691 1609911 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W310 04:36:18.086404542 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W310 04:36:18.154084440 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "1324/1324 09:08<00:00 , loss=1.1, lr=9.85e-5, step=1324 \n",
      "442/442 01:07<00:00 \n",
      "EPOCH 1 | AUC 0.8012094022205648 LOSS 0.578223705291748\n",
      "SAVING BEST!\n",
      "1324/1324 09:10<00:00 , loss=0.902, lr=9.43e-5, step=2648\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 2 | AUC 0.8388502983268367 LOSS 0.4348970651626587\n",
      "SAVING BEST!\n",
      "1324/1324 09:04<00:00 , loss=0.729, lr=8.74e-5, step=3972\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 3 | AUC 0.8432253774819527 LOSS 0.49663230776786804\n",
      "1324/1324 09:06<00:00 , loss=0.656, lr=7.84e-5, step=5296\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 4 | AUC 0.8822061937998678 LOSS 0.39112523198127747\n",
      "SAVING BEST!\n",
      "1324/1324 09:07<00:00 , loss=0.584, lr=6.77e-5, step=6620\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 5 | AUC 0.8821441889590926 LOSS 0.4232579171657562\n",
      "1324/1324 09:07<00:00 , loss=0.521, lr=5.6e-5, step=7944 \n",
      "442/442 01:07<00:00 \n",
      "EPOCH 6 | AUC 0.8936216807621407 LOSS 0.37396004796028137\n",
      "SAVING BEST!\n",
      "52/1324 00:22<08:42 , loss=0.466, lr=5.56e-5, step=7996"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"13\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f06d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d10276b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 40706 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 07:18:21.070898 2407056 site-packages/torch/distributed/run.py:792] \n",
      "W0314 07:18:21.070898 2407056 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 07:18:21.070898 2407056 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 07:18:21.070898 2407056 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W314 07:18:26.020034820 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W314 07:18:26.058526560 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W314 07:18:29.497308371 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W314 07:18:29.518745949 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 05:40<00:00 , loss=0.983, lr=9.85e-5, step=1324\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.896802634233939 LOSS 0.36745405197143555\n",
      "SAVING BEST!\n",
      "1324/1324 05:37<00:00 , loss=0.78, lr=9.43e-5, step=2648 \n",
      "442/442 00:43<00:00 \n",
      "EPOCH 2 | AUC 0.8954421655419009 LOSS 0.33614760637283325\n",
      "SAVING BEST!\n",
      "1324/1324 05:37<00:00 , loss=0.667, lr=8.74e-5, step=3972\n",
      "442/442 00:44<00:00 \n",
      "EPOCH 3 | AUC 0.897112352333195 LOSS 0.356304794549942\n",
      "1324/1324 05:36<00:00 , loss=0.608, lr=7.84e-5, step=5296\n",
      "442/442 00:43<00:00 \n",
      "EPOCH 4 | AUC 0.8937058938076646 LOSS 0.36983534693717957\n",
      "1324/1324 05:38<00:00 , loss=0.568, lr=6.77e-5, step=6620\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.9017603266534673 LOSS 0.3556627631187439\n",
      "1324/1324 05:36<00:00 , loss=0.518, lr=5.6e-5, step=7944 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.9008139902705342 LOSS 0.3641277551651001\n",
      "1324/1324 05:36<00:00 , loss=0.481, lr=4.4e-5, step=9268 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8932212708927547 LOSS 0.38886505365371704\n",
      "1324/1324 05:38<00:00 , loss=0.434, lr=3.23e-5, step=10592\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8906347062259947 LOSS 0.40017107129096985\n",
      "176/1324 00:45<04:50 , loss=0.394, lr=3.08e-5, step=10768^C\n",
      "W0314 08:10:16.722969 2407056 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0314 08:10:16.723778 2407056 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2407115 closing signal SIGINT\n",
      "W0314 08:10:16.723965 2407056 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2407116 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 08:10:19.038644 2413834 site-packages/torch/distributed/run.py:792] \n",
      "W0314 08:10:19.038644 2413834 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 08:10:19.038644 2413834 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 08:10:19.038644 2413834 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W314 08:10:24.305475648 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W314 08:10:24.307094806 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W314 08:10:27.888869755 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W314 08:10:27.925551836 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 05:38<00:00 , loss=0.99, lr=9.85e-5, step=1324 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.8757563711073273 LOSS 0.3913697898387909\n",
      "SAVING BEST!\n",
      "1324/1324 05:38<00:00 , loss=0.795, lr=9.43e-5, step=2648\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8825360067827139 LOSS 0.3599514663219452\n",
      "SAVING BEST!\n",
      "1324/1324 05:36<00:00 , loss=0.686, lr=8.74e-5, step=3972\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8758161771948835 LOSS 0.3774760663509369\n",
      "1324/1324 05:36<00:00 , loss=0.616, lr=7.84e-5, step=5296\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.882671010230359 LOSS 0.37073054909706116\n",
      "1324/1324 05:36<00:00 , loss=0.563, lr=6.77e-5, step=6620\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8827734721303632 LOSS 0.3575218915939331\n",
      "SAVING BEST!\n",
      "1324/1324 05:37<00:00 , loss=0.494, lr=5.6e-5, step=7944 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8721139165247738 LOSS 0.38015004992485046\n",
      "1324/1324 05:38<00:00 , loss=0.474, lr=4.4e-5, step=9268 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8873574328412817 LOSS 0.3740360736846924\n",
      "1324/1324 05:37<00:00 , loss=0.447, lr=3.23e-5, step=10592\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.88440582652013 LOSS 0.37685734033584595\n",
      "1324/1324 05:37<00:00 , loss=0.393, lr=2.16e-5, step=11916\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8821362734475042 LOSS 0.3747617304325104\n",
      "1324/1324 05:38<00:00 , loss=0.378, lr=1.26e-5, step=13240\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 10 | AUC 0.8721688853552481 LOSS 0.41926559805870056\n",
      "[rank0]:[W314 09:14:06.527017437 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 09:14:10.051776 2421980 site-packages/torch/distributed/run.py:792] \n",
      "W0314 09:14:10.051776 2421980 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 09:14:10.051776 2421980 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 09:14:10.051776 2421980 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W314 09:14:15.939120600 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W314 09:14:15.977173470 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W314 09:14:19.924203124 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W314 09:14:20.985694844 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 05:36<00:00 , loss=0.991, lr=9.85e-5, step=1324\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.8943136349646045 LOSS 0.36955979466438293\n",
      "SAVING BEST!\n",
      "1324/1324 05:37<00:00 , loss=0.765, lr=9.43e-5, step=2648\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.908393974702839 LOSS 0.33470290899276733\n",
      "SAVING BEST!\n",
      "1324/1324 05:37<00:00 , loss=0.665, lr=8.74e-5, step=3972\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.9053257229330638 LOSS 0.34584304690361023\n",
      "1324/1324 05:36<00:00 , loss=0.596, lr=7.84e-5, step=5296\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.9070373301675241 LOSS 0.3550560176372528\n",
      "1324/1324 05:36<00:00 , loss=0.555, lr=6.77e-5, step=6620\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.9112176457224934 LOSS 0.34174615144729614\n",
      "1324/1324 05:37<00:00 , loss=0.494, lr=5.6e-5, step=7944 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.907612140731947 LOSS 0.3866184651851654\n",
      "1324/1324 05:36<00:00 , loss=0.458, lr=4.4e-5, step=9268 \n",
      "442/442 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8999119692506119 LOSS 0.39165475964546204\n",
      "1324/1324 05:37<00:00 , loss=0.444, lr=3.23e-5, step=10592\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8974945587653345 LOSS 0.3815096318721771\n",
      "1324/1324 05:36<00:00 , loss=0.396, lr=2.16e-5, step=11916\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8898415629717569 LOSS 0.4486350417137146\n",
      "1324/1324 05:37<00:00 , loss=0.377, lr=1.26e-5, step=13240\n",
      "442/442 00:42<00:00 \n",
      "EPOCH 10 | AUC 0.894352108341028 LOSS 0.44271185994148254\n",
      "[rank0]:[W314 10:17:55.140690874 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 10:17:58.451256 2430121 site-packages/torch/distributed/run.py:792] \n",
      "W0314 10:17:58.451256 2430121 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 10:17:58.451256 2430121 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 10:17:58.451256 2430121 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W314 10:18:03.410097900 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W314 10:18:03.416866505 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank0]:[W314 10:18:07.026809060 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W314 10:18:07.028750440 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 05:37<00:00 , loss=0.966, lr=9.85e-5, step=1325\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 1 | AUC 0.8800284147233348 LOSS 0.34475764632225037\n",
      "SAVING BEST!\n",
      "1325/1325 05:38<00:00 , loss=0.743, lr=9.43e-5, step=2650\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 2 | AUC 0.8766793603314338 LOSS 0.3457951247692108\n",
      "1325/1325 05:37<00:00 , loss=0.654, lr=8.74e-5, step=3975\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 3 | AUC 0.8848327570590514 LOSS 0.3377549946308136\n",
      "SAVING BEST!\n",
      "1325/1325 05:36<00:00 , loss=0.608, lr=7.84e-5, step=5300\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 4 | AUC 0.8895856830598395 LOSS 0.3354106843471527\n",
      "SAVING BEST!\n",
      "1325/1325 05:36<00:00 , loss=0.559, lr=6.77e-5, step=6625\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 5 | AUC 0.8850450036896361 LOSS 0.3555665910243988\n",
      "1325/1325 05:37<00:00 , loss=0.502, lr=5.6e-5, step=7950 \n",
      "441/441 00:42<00:00 \n",
      "EPOCH 6 | AUC 0.8902084377084931 LOSS 0.34247463941574097\n",
      "1325/1325 05:38<00:00 , loss=0.465, lr=4.4e-5, step=9275 \n",
      "441/441 00:42<00:00 \n",
      "EPOCH 7 | AUC 0.8888781942912238 LOSS 0.3534044921398163\n",
      "1325/1325 05:38<00:00 , loss=0.433, lr=3.23e-5, step=10600\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 8 | AUC 0.8859964115511527 LOSS 0.35178816318511963\n",
      "1325/1325 05:37<00:00 , loss=0.396, lr=2.16e-5, step=11925\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 9 | AUC 0.8855381891742701 LOSS 0.3710831105709076\n",
      "1325/1325 05:38<00:00 , loss=0.367, lr=1.26e-5, step=13250\n",
      "441/441 00:42<00:00 \n",
      "EPOCH 10 | AUC 0.8855237926004902 LOSS 0.38838955760002136\n",
      "[rank0]:[W314 11:21:50.297751652 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"14\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36257d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e1f062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 40650 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 19:04:28.279811 2493426 site-packages/torch/distributed/run.py:792] \n",
      "W0314 19:04:28.279811 2493426 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 19:04:28.279811 2493426 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 19:04:28.279811 2493426 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W314 19:04:33.297820036 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W314 19:04:33.378732671 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W314 19:04:38.789673335 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W314 19:04:38.797713534 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 08:55<00:00 , loss=0.943, lr=9.85e-5, step=1324\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 1 | AUC 0.9023425161521896 LOSS 0.3215281367301941\n",
      "SAVING BEST!\n",
      "1324/1324 08:58<00:00 , loss=0.785, lr=9.43e-5, step=2648\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 2 | AUC 0.9165232412060301 LOSS 0.3102208971977234\n",
      "SAVING BEST!\n",
      "1324/1324 08:59<00:00 , loss=0.653, lr=8.74e-5, step=3972\n",
      "442/442 01:08<00:00 \n",
      "EPOCH 3 | AUC 0.9122352835606604 LOSS 0.3177243173122406\n",
      "1324/1324 08:58<00:00 , loss=0.577, lr=7.84e-5, step=5296\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 4 | AUC 0.913734745154343 LOSS 0.30340737104415894\n",
      "SAVING BEST!\n",
      "1324/1324 08:56<00:00 , loss=0.528, lr=6.77e-5, step=6620\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 5 | AUC 0.9151512024407753 LOSS 0.3027724027633667\n",
      "SAVING BEST!\n",
      "1324/1324 08:59<00:00 , loss=0.456, lr=5.6e-5, step=7944 \n",
      "442/442 01:07<00:00 \n",
      "EPOCH 6 | AUC 0.916762832017229 LOSS 0.28703412413597107\n",
      "SAVING BEST!\n",
      "1324/1324 08:57<00:00 , loss=0.425, lr=4.4e-5, step=9268 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 7 | AUC 0.912174712849964 LOSS 0.30211180448532104\n",
      "1324/1324 08:57<00:00 , loss=0.392, lr=3.23e-5, step=10592\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 8 | AUC 0.9114985642498206 LOSS 0.3111102283000946\n",
      "1324/1324 08:59<00:00 , loss=0.346, lr=2.16e-5, step=11916\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 9 | AUC 0.905865488155061 LOSS 0.335016667842865\n",
      "1174/1324 07:57<01:00 , loss=0.324, lr=1.35e-5, step=13090^C\n",
      "W0314 20:43:40.870559 2493426 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0314 20:43:40.871222 2493426 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2493476 closing signal SIGINT\n",
      "W0314 20:43:40.871388 2493426 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2493477 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 20:43:42.926265 2505845 site-packages/torch/distributed/run.py:792] \n",
      "W0314 20:43:42.926265 2505845 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 20:43:42.926265 2505845 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 20:43:42.926265 2505845 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W314 20:43:48.149565137 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W314 20:43:48.173938697 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W314 20:43:53.625767183 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W314 20:43:53.629505567 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 09:00<00:00 , loss=0.943, lr=9.85e-5, step=1324\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 1 | AUC 0.9086425441608442 LOSS 0.3346012830734253\n",
      "SAVING BEST!\n",
      "1324/1324 09:00<00:00 , loss=0.776, lr=9.43e-5, step=2648\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 2 | AUC 0.921273852615536 LOSS 0.3065991699695587\n",
      "SAVING BEST!\n",
      "1324/1324 08:59<00:00 , loss=0.646, lr=8.74e-5, step=3972\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 3 | AUC 0.9266825868707053 LOSS 0.288560688495636\n",
      "SAVING BEST!\n",
      "1324/1324 08:59<00:00 , loss=0.58, lr=7.84e-5, step=5296 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 4 | AUC 0.9276874205282023 LOSS 0.2800285220146179\n",
      "SAVING BEST!\n",
      "1324/1324 09:01<00:00 , loss=0.497, lr=6.77e-5, step=6620\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 5 | AUC 0.93280285677576 LOSS 0.2727491855621338\n",
      "SAVING BEST!\n",
      "1324/1324 08:57<00:00 , loss=0.477, lr=5.6e-5, step=7944 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 6 | AUC 0.9345236565666412 LOSS 0.2797743082046509\n",
      "1324/1324 08:58<00:00 , loss=0.432, lr=4.4e-5, step=9268 \n",
      "442/442 01:06<00:00 \n",
      "EPOCH 7 | AUC 0.9391911709324838 LOSS 0.28605183959007263\n",
      "1324/1324 08:56<00:00 , loss=0.397, lr=3.23e-5, step=10592\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 8 | AUC 0.9355333637559866 LOSS 0.29387006163597107\n",
      "625/1324 04:13<04:44 , loss=0.366, lr=2.71e-5, step=11217^C\n",
      "W0314 22:09:08.892286 2505845 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0314 22:09:08.893090 2505845 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2505895 closing signal SIGINT\n",
      "W0314 22:09:08.893249 2505845 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2505896 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 22:09:10.901168 2516394 site-packages/torch/distributed/run.py:792] \n",
      "W0314 22:09:10.901168 2516394 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 22:09:10.901168 2516394 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 22:09:10.901168 2516394 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W314 22:09:16.078657561 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W314 22:09:16.091062045 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W314 22:09:19.540606444 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W314 22:09:19.541205196 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 09:02<00:00 , loss=0.942, lr=9.85e-5, step=1324\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 1 | AUC 0.8755149480038839 LOSS 0.362593412399292\n",
      "SAVING BEST!\n",
      "1324/1324 09:01<00:00 , loss=0.713, lr=9.43e-5, step=2648\n",
      "442/442 01:05<00:00 \n",
      "EPOCH 2 | AUC 0.8942527229359863 LOSS 0.3395836353302002\n",
      "SAVING BEST!\n",
      "1324/1324 08:58<00:00 , loss=0.592, lr=8.74e-5, step=3972\n",
      "442/442 01:06<00:00 \n",
      "EPOCH 3 | AUC 0.886640639291896 LOSS 0.3374728858470917\n",
      "SAVING BEST!\n",
      "1324/1324 08:58<00:00 , loss=0.543, lr=7.84e-5, step=5296\n",
      "442/442 01:07<00:00 \n",
      "EPOCH 4 | AUC 0.8925069128801204 LOSS 0.3321133553981781\n",
      "SAVING BEST!\n",
      "875/1324 05:54<03:00 , loss=0.479, lr=7.15e-5, step=6171"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"15\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75138523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 40650 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0314 23:21:17.404935 2525375 site-packages/torch/distributed/run.py:792] \n",
      "W0314 23:21:17.404935 2525375 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0314 23:21:17.404935 2525375 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0314 23:21:17.404935 2525375 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W314 23:21:22.560942565 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W314 23:21:22.579080266 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank1]:[W314 23:21:26.813878425 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W314 23:21:26.845159542 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 09:01<00:00 , loss=0.917, lr=9.85e-5, step=1325\n",
      "441/441 01:07<00:00 \n",
      "EPOCH 1 | AUC 0.9029642862802302 LOSS 0.373127281665802\n",
      "SAVING BEST!\n",
      "1325/1325 09:00<00:00 , loss=0.679, lr=9.43e-5, step=2650\n",
      "441/441 01:06<00:00 \n",
      "EPOCH 2 | AUC 0.9105113648210561 LOSS 0.34572356939315796\n",
      "SAVING BEST!\n",
      "1325/1325 08:59<00:00 , loss=0.579, lr=8.74e-5, step=3975\n",
      "441/441 01:06<00:00 \n",
      "EPOCH 3 | AUC 0.9053108113630697 LOSS 0.3411742150783539\n",
      "SAVING BEST!\n",
      "1325/1325 08:57<00:00 , loss=0.538, lr=7.84e-5, step=5300\n",
      "441/441 01:06<00:00 \n",
      "EPOCH 4 | AUC 0.9028846370371482 LOSS 0.344723105430603\n",
      "1325/1325 08:58<00:00 , loss=0.464, lr=6.77e-5, step=6625\n",
      "441/441 01:05<00:00 \n",
      "EPOCH 5 | AUC 0.8992795705112646 LOSS 0.34388184547424316\n",
      "1325/1325 08:58<00:00 , loss=0.422, lr=5.6e-5, step=7950 \n",
      "441/441 01:06<00:00 \n",
      "EPOCH 6 | AUC 0.9009951568256065 LOSS 0.351613312959671\n",
      "1325/1325 08:56<00:00 , loss=0.398, lr=4.4e-5, step=9275 \n",
      "441/441 01:06<00:00 \n",
      "EPOCH 7 | AUC 0.9051857078399044 LOSS 0.34840428829193115\n",
      "1325/1325 08:57<00:00 , loss=0.378, lr=3.23e-5, step=10600\n",
      "441/441 01:06<00:00 \n",
      "EPOCH 8 | AUC 0.9009697191092296 LOSS 0.3471095561981201\n",
      "1325/1325 08:57<00:00 , loss=0.336, lr=2.16e-5, step=11925\n",
      "441/441 01:06<00:00 \n",
      "EPOCH 9 | AUC 0.9011698847462941 LOSS 0.3647705912590027\n",
      "54/1325 00:22<08:34 , loss=0.295, lr=2.12e-5, step=11979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"15\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(3, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a1914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acded475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 40650 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 00:53:22.238397 2536817 site-packages/torch/distributed/run.py:792] \n",
      "W0315 00:53:22.238397 2536817 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 00:53:22.238397 2536817 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 00:53:22.238397 2536817 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 00:53:28.655701909 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 00:53:28.660354474 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W315 00:53:34.531391013 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 00:53:34.541327740 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:03<00:00 , loss=0.944, lr=9.85e-5, step=1324\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 1 | AUC 0.9071684314429289 LOSS 0.34006690979003906\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.783, lr=9.43e-5, step=2648\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.9195997846374732 LOSS 0.29564082622528076\n",
      "SAVING BEST!\n",
      "1324/1324 11:02<00:00 , loss=0.644, lr=8.74e-5, step=3972\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.91024003948313 LOSS 0.3132284879684448\n",
      "1324/1324 10:58<00:00 , loss=0.571, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9185992462311559 LOSS 0.296908974647522\n",
      "1324/1324 10:59<00:00 , loss=0.522, lr=6.77e-5, step=6620\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9256496769562096 LOSS 0.281758576631546\n",
      "SAVING BEST!\n",
      "1324/1324 10:58<00:00 , loss=0.459, lr=5.6e-5, step=7944 \n",
      "442/442 01:20<00:00 \n",
      "EPOCH 6 | AUC 0.9246765075376884 LOSS 0.2743934690952301\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.429, lr=4.4e-5, step=9268 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.9231299353912419 LOSS 0.2837391197681427\n",
      "1324/1324 11:00<00:00 , loss=0.392, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9135629038047379 LOSS 0.305251806974411\n",
      "1027/1324 08:33<02:28 , loss=0.335, lr=2.39e-5, step=11619^C\n",
      "W0315 02:41:18.845302 2536817 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0315 02:41:18.846247 2536817 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2536876 closing signal SIGINT\n",
      "W0315 02:41:18.846523 2536817 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2536877 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 02:41:21.054708 2550000 site-packages/torch/distributed/run.py:792] \n",
      "W0315 02:41:21.054708 2550000 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 02:41:21.054708 2550000 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 02:41:21.054708 2550000 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 02:41:26.661415345 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 02:41:26.666544800 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W315 02:41:32.521197628 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 02:41:32.593287201 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:03<00:00 , loss=0.945, lr=9.85e-5, step=1324\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 1 | AUC 0.9042288964994749 LOSS 0.3379178047180176\n",
      "SAVING BEST!\n",
      "1324/1324 11:08<00:00 , loss=0.787, lr=9.43e-5, step=2648\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.9207683344483384 LOSS 0.3015590012073517\n",
      "SAVING BEST!\n",
      "1324/1324 11:01<00:00 , loss=0.661, lr=8.74e-5, step=3972\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.9229614237801772 LOSS 0.30788251757621765\n",
      "1324/1324 10:59<00:00 , loss=0.587, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9244022170139428 LOSS 0.29866015911102295\n",
      "SAVING BEST!\n",
      "1324/1324 11:02<00:00 , loss=0.508, lr=6.77e-5, step=6620\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9276205202273725 LOSS 0.2829216420650482\n",
      "SAVING BEST!\n",
      "1324/1324 10:59<00:00 , loss=0.475, lr=5.6e-5, step=7944 \n",
      "442/442 01:20<00:00 \n",
      "EPOCH 6 | AUC 0.932594181002973 LOSS 0.29519984126091003\n",
      "1324/1324 11:01<00:00 , loss=0.437, lr=4.4e-5, step=9268 \n",
      "442/442 01:22<00:00 \n",
      "EPOCH 7 | AUC 0.9300621596834862 LOSS 0.296174019575119\n",
      "1324/1324 11:01<00:00 , loss=0.397, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9296168960918705 LOSS 0.29235929250717163\n",
      "1324/1324 11:01<00:00 , loss=0.368, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9261039657257797 LOSS 0.30626219511032104\n",
      "1324/1324 10:59<00:00 , loss=0.334, lr=1.26e-5, step=13240\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 10 | AUC 0.9194236827064939 LOSS 0.3110445737838745\n",
      "[rank0]:[W315 04:45:45.251480983 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 04:45:48.643737 2565158 site-packages/torch/distributed/run.py:792] \n",
      "W0315 04:45:48.643737 2565158 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 04:45:48.643737 2565158 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 04:45:48.643737 2565158 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank1]:[W315 04:45:53.449117779 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W315 04:45:53.901930372 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W315 04:45:58.345040863 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 04:45:58.411865165 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:07<00:00 , loss=0.947, lr=9.85e-5, step=1324\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 1 | AUC 0.8757084382871537 LOSS 0.3702602982521057\n",
      "SAVING BEST!\n",
      "1324/1324 11:04<00:00 , loss=0.725, lr=9.43e-5, step=2648\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 2 | AUC 0.896674869482009 LOSS 0.31993159651756287\n",
      "SAVING BEST!\n",
      "1324/1324 11:01<00:00 , loss=0.61, lr=8.74e-5, step=3972 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.8988327258911106 LOSS 0.3178822696208954\n",
      "SAVING BEST!\n",
      "1324/1324 11:03<00:00 , loss=0.531, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9019958522719277 LOSS 0.31635114550590515\n",
      "SAVING BEST!\n",
      "1324/1324 10:57<00:00 , loss=0.475, lr=6.77e-5, step=6620\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 5 | AUC 0.9077834104949131 LOSS 0.31889450550079346\n",
      "1324/1324 11:00<00:00 , loss=0.44, lr=5.6e-5, step=7944  \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.900054792930217 LOSS 0.3314089775085449\n",
      "1324/1324 11:00<00:00 , loss=0.401, lr=4.4e-5, step=9268 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.8983890174915217 LOSS 0.32754260301589966\n",
      "1324/1324 11:01<00:00 , loss=0.375, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9025565343427663 LOSS 0.3510269522666931\n",
      "1324/1324 11:01<00:00 , loss=0.358, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9040899448376792 LOSS 0.3450826108455658\n",
      "1324/1324 10:59<00:00 , loss=0.336, lr=1.26e-5, step=13240\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 10 | AUC 0.9031866970153244 LOSS 0.35903212428092957\n",
      "[rank0]:[W315 06:50:11.863272683 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 06:50:15.438778 2583342 site-packages/torch/distributed/run.py:792] \n",
      "W0315 06:50:15.438778 2583342 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 06:50:15.438778 2583342 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 06:50:15.438778 2583342 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 06:50:20.490967062 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 06:50:20.601350037 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank0]:[W315 06:50:26.574941618 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 06:50:26.589810597 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/1325 11:08<00:00 , loss=0.932, lr=9.85e-5, step=1325\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 1 | AUC 0.897342967972664 LOSS 0.36702847480773926\n",
      "SAVING BEST!\n",
      "1325/1325 11:04<00:00 , loss=0.698, lr=9.43e-5, step=2650\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.9004142594663751 LOSS 0.3402092754840851\n",
      "SAVING BEST!\n",
      "1325/1325 11:04<00:00 , loss=0.592, lr=8.74e-5, step=3975\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.8966257077731823 LOSS 0.35015562176704407\n",
      "1325/1325 11:00<00:00 , loss=0.542, lr=7.84e-5, step=5300\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9047745342604339 LOSS 0.3182673454284668\n",
      "SAVING BEST!\n",
      "1325/1325 11:00<00:00 , loss=0.465, lr=6.77e-5, step=6625\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.8912867064162261 LOSS 0.3426078259944916\n",
      "228/1325 01:53<09:06 , loss=0.448, lr=6.58e-5, step=6853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"16\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c2898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f83a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41360 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 20:28:46.460220 2685265 site-packages/torch/distributed/run.py:792] \n",
      "W0315 20:28:46.460220 2685265 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 20:28:46.460220 2685265 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 20:28:46.460220 2685265 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 20:28:51.411998024 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 20:28:51.503169265 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W315 20:28:57.423840728 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 20:28:57.447647826 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:03<00:00 , loss=0.959, lr=9.85e-5, step=1324\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 1 | AUC 0.8953834361943918 LOSS 0.3520534932613373\n",
      "SAVING BEST!\n",
      "1324/1324 11:05<00:00 , loss=0.796, lr=9.43e-5, step=2648\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.91296846824894 LOSS 0.3280775249004364\n",
      "SAVING BEST!\n",
      "1324/1324 11:02<00:00 , loss=0.693, lr=8.74e-5, step=3972\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 3 | AUC 0.9194640001063317 LOSS 0.305072546005249\n",
      "SAVING BEST!\n",
      "1324/1324 10:59<00:00 , loss=0.589, lr=7.84e-5, step=5296\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 4 | AUC 0.9220376679707056 LOSS 0.284125953912735\n",
      "SAVING BEST!\n",
      "1324/1324 10:56<00:00 , loss=0.526, lr=6.77e-5, step=6620\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9295079061978034 LOSS 0.29587188363075256\n",
      "1324/1324 11:00<00:00 , loss=0.478, lr=5.6e-5, step=7944 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.9334909108631025 LOSS 0.2804347276687622\n",
      "SAVING BEST!\n",
      "1324/1324 11:01<00:00 , loss=0.436, lr=4.4e-5, step=9268 \n",
      "442/442 01:22<00:00 \n",
      "EPOCH 7 | AUC 0.9263511867050052 LOSS 0.2727350890636444\n",
      "SAVING BEST!\n",
      "1324/1324 10:58<00:00 , loss=0.413, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9175810446193993 LOSS 0.28537964820861816\n",
      "1324/1324 10:58<00:00 , loss=0.368, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9061800814322868 LOSS 0.3125476837158203\n",
      "319/1324 02:39<08:19 , loss=0.301, lr=1.93e-5, step=12235"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"17\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fa8879c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41360 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 22:37:13.925983 2701610 site-packages/torch/distributed/run.py:792] \n",
      "W0315 22:37:13.925983 2701610 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 22:37:13.925983 2701610 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 22:37:13.925983 2701610 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 22:37:19.054334427 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 22:37:19.131265570 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W315 22:37:24.602244679 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 22:37:24.607172446 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:04<00:00 , loss=0.978, lr=9.85e-5, step=1324\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 1 | AUC 0.8499922603886692 LOSS 0.40133172273635864\n",
      "SAVING BEST!\n",
      "1324/1324 11:03<00:00 , loss=0.781, lr=9.43e-5, step=2648\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.8776055225644851 LOSS 0.3568212389945984\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.646, lr=8.74e-5, step=3972\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.8802712909671699 LOSS 0.40277424454689026\n",
      "1324/1324 11:01<00:00 , loss=0.577, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.8762959451472636 LOSS 0.42625361680984497\n",
      "568/1324 04:43<06:16 , loss=0.5, lr=7.4e-5, step=5864   ^C\n",
      "W0315 23:31:51.983823 2701610 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0315 23:31:51.985262 2701610 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2701660 closing signal SIGINT\n",
      "W0315 23:31:51.985578 2701610 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 2701661 closing signal SIGINT\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0315 23:31:53.994082 2708455 site-packages/torch/distributed/run.py:792] \n",
      "W0315 23:31:53.994082 2708455 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0315 23:31:53.994082 2708455 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0315 23:31:53.994082 2708455 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "[rank0]:[W315 23:31:58.878976240 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W315 23:31:59.027850972 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank0]:[W315 23:32:03.110713449 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W315 23:32:03.141520585 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 11:04<00:00 , loss=0.918, lr=9.85e-5, step=1325\n",
      "441/441 01:22<00:00 \n",
      "EPOCH 1 | AUC 0.9012157560381215 LOSS 0.3527103364467621\n",
      "SAVING BEST!\n",
      "1325/1325 11:03<00:00 , loss=0.668, lr=9.43e-5, step=2650\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.9074046273291149 LOSS 0.3396460711956024\n",
      "SAVING BEST!\n",
      "1325/1325 11:00<00:00 , loss=0.571, lr=8.74e-5, step=3975\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.9012749717057531 LOSS 0.341013103723526\n",
      "1325/1325 10:59<00:00 , loss=0.521, lr=7.84e-5, step=5300\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.900266220297296 LOSS 0.333366721868515\n",
      "SAVING BEST!\n",
      "1325/1325 10:59<00:00 , loss=0.46, lr=6.77e-5, step=6625 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9018371035365098 LOSS 0.36227235198020935\n",
      "1325/1325 11:01<00:00 , loss=0.413, lr=5.6e-5, step=7950 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.9096569077578363 LOSS 0.3360983729362488\n",
      "1325/1325 11:02<00:00 , loss=0.387, lr=4.4e-5, step=9275 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.913112684079409 LOSS 0.3389206528663635\n",
      "1325/1325 11:01<00:00 , loss=0.376, lr=3.23e-5, step=10600\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9157736360171376 LOSS 0.3290081024169922\n",
      "SAVING BEST!\n",
      "1325/1325 10:56<00:00 , loss=0.333, lr=2.16e-5, step=11925\n",
      "441/441 01:22<00:00 \n",
      "EPOCH 9 | AUC 0.9112719942419019 LOSS 0.350870817899704\n",
      "1325/1325 10:59<00:00 , loss=0.317, lr=1.26e-5, step=13250\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 10 | AUC 0.8999826523114544 LOSS 0.3774452209472656\n",
      "[rank0]:[W316 01:36:07.007309677 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"17\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(2, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb802adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a1e58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41551 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 03:46:28.402581 2740238 site-packages/torch/distributed/run.py:792] \n",
      "W0316 03:46:28.402581 2740238 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 03:46:28.402581 2740238 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 03:46:28.402581 2740238 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 03:46:43.979901297 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 03:46:43.407871382 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W316 03:46:46.484535641 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W316 03:46:46.509158568 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:53<00:00 , loss=0.927, lr=9.85e-5, step=1324\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 1 | AUC 0.9156799241501223 LOSS 0.3291066586971283\n",
      "SAVING BEST!\n",
      "1324/1324 10:55<00:00 , loss=0.8, lr=9.43e-5, step=2648  \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9175433855096606 LOSS 0.3131915032863617\n",
      "SAVING BEST!\n",
      "1324/1324 10:50<00:00 , loss=0.752, lr=8.74e-5, step=3972\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.918371885923911 LOSS 0.315738320350647\n",
      "1324/1324 10:53<00:00 , loss=0.705, lr=7.84e-5, step=5296\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9179190905103474 LOSS 0.30951374769210815\n",
      "SAVING BEST!\n",
      "1324/1324 10:52<00:00 , loss=0.644, lr=6.77e-5, step=6620\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 5 | AUC 0.9211856859939125 LOSS 0.3059206008911133\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.613, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9180112445671196 LOSS 0.29745787382125854\n",
      "SAVING BEST!\n",
      "1324/1324 10:54<00:00 , loss=0.589, lr=4.4e-5, step=9268 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 7 | AUC 0.9172425556801014 LOSS 0.3046233057975769\n",
      "1324/1324 10:53<00:00 , loss=0.551, lr=3.23e-5, step=10592\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 8 | AUC 0.9256843989384561 LOSS 0.29754409193992615\n",
      "1324/1324 10:53<00:00 , loss=0.536, lr=2.16e-5, step=11916\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 9 | AUC 0.9257490839975366 LOSS 0.2972117066383362\n",
      "SAVING BEST!\n",
      "1324/1324 10:52<00:00 , loss=0.505, lr=1.26e-5, step=13240\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 10 | AUC 0.9250964737781835 LOSS 0.2967812418937683\n",
      "SAVING BEST!\n",
      "[rank0]:[W316 05:48:54.459673279 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 05:48:57.699330 2755270 site-packages/torch/distributed/run.py:792] \n",
      "W0316 05:48:57.699330 2755270 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 05:48:57.699330 2755270 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 05:48:57.699330 2755270 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 05:49:12.710851585 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 05:49:13.327553045 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W316 05:49:16.282329391 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W316 05:49:16.284934896 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:58<00:00 , loss=0.935, lr=9.85e-5, step=1324\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 1 | AUC 0.8849256117810956 LOSS 0.3601946234703064\n",
      "SAVING BEST!\n",
      "1324/1324 10:55<00:00 , loss=0.781, lr=9.43e-5, step=2648\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.8869823255421245 LOSS 0.3387613594532013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING BEST!\n",
      "1324/1324 10:50<00:00 , loss=0.747, lr=8.74e-5, step=3972\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.8918789489607813 LOSS 0.33265864849090576\n",
      "SAVING BEST!\n",
      "1324/1324 10:49<00:00 , loss=0.703, lr=7.84e-5, step=5296\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 4 | AUC 0.8916045445590534 LOSS 0.3246079683303833\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.636, lr=6.77e-5, step=6620\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 5 | AUC 0.8968388964721444 LOSS 0.32707804441452026\n",
      "1324/1324 10:50<00:00 , loss=0.599, lr=5.6e-5, step=7944 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 6 | AUC 0.8923472833964229 LOSS 0.3256438374519348\n",
      "1324/1324 10:50<00:00 , loss=0.581, lr=4.4e-5, step=9268 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 7 | AUC 0.8945860539239829 LOSS 0.3184486925601959\n",
      "SAVING BEST!\n",
      "1324/1324 10:52<00:00 , loss=0.567, lr=3.23e-5, step=10592\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 8 | AUC 0.9011678018096618 LOSS 0.31010138988494873\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.537, lr=2.16e-5, step=11916\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.8998384356134697 LOSS 0.3128129243850708\n",
      "1324/1324 10:52<00:00 , loss=0.539, lr=1.26e-5, step=13240\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 10 | AUC 0.9016356964946597 LOSS 0.3074108958244324\n",
      "SAVING BEST!\n",
      "[rank0]:[W316 07:51:17.121707793 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 07:51:20.399879 2771815 site-packages/torch/distributed/run.py:792] \n",
      "W0316 07:51:20.399879 2771815 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 07:51:20.399879 2771815 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 07:51:20.399879 2771815 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 07:51:35.492690149 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 07:51:35.910466911 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank1]:[W316 07:51:38.520713545 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W316 07:51:38.521505540 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 10:58<00:00 , loss=0.916, lr=9.85e-5, step=1325\n",
      "441/441 01:18<00:00 \n",
      "EPOCH 1 | AUC 0.8980910870411933 LOSS 0.3618989884853363\n",
      "SAVING BEST!\n",
      "1325/1325 10:59<00:00 , loss=0.789, lr=9.43e-5, step=2650\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9081085431527922 LOSS 0.35483554005622864\n",
      "SAVING BEST!\n",
      "1325/1325 10:55<00:00 , loss=0.753, lr=8.74e-5, step=3975\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.8969684914266555 LOSS 0.35306426882743835\n",
      "SAVING BEST!\n",
      "1325/1325 10:54<00:00 , loss=0.711, lr=7.84e-5, step=5300\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9071640115528934 LOSS 0.3392046093940735\n",
      "SAVING BEST!\n",
      "1325/1325 10:51<00:00 , loss=0.64, lr=6.77e-5, step=6625 \n",
      "441/441 01:18<00:00 \n",
      "EPOCH 5 | AUC 0.9133462106559844 LOSS 0.3287014067173004\n",
      "SAVING BEST!\n",
      "1325/1325 10:52<00:00 , loss=0.602, lr=5.6e-5, step=7950 \n",
      "441/441 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9125113531447273 LOSS 0.33511021733283997\n",
      "1325/1325 10:50<00:00 , loss=0.576, lr=4.4e-5, step=9275 \n",
      "441/441 01:17<00:00 \n",
      "EPOCH 7 | AUC 0.912428784819438 LOSS 0.33920788764953613\n",
      "1325/1325 10:54<00:00 , loss=0.57, lr=3.23e-5, step=10600 \n",
      "441/441 01:18<00:00 \n",
      "EPOCH 8 | AUC 0.909567667244645 LOSS 0.3428650498390198\n",
      "1325/1325 10:53<00:00 , loss=0.533, lr=2.16e-5, step=11925\n",
      "441/441 01:18<00:00 \n",
      "EPOCH 9 | AUC 0.9113766641896168 LOSS 0.3353981673717499\n",
      "1325/1325 10:51<00:00 , loss=0.523, lr=1.26e-5, step=13250\n",
      "441/441 01:18<00:00 \n",
      "EPOCH 10 | AUC 0.912005934911139 LOSS 0.3438563942909241\n",
      "[rank0]:[W316 09:53:56.207971145 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3459581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a7f5bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41553 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 12:00:53.504559 2802895 site-packages/torch/distributed/run.py:792] \n",
      "W0316 12:00:53.504559 2802895 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 12:00:53.504559 2802895 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 12:00:53.504559 2802895 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 12:01:08.363176989 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W316 12:01:08.465541632 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W316 12:01:11.067862432 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W316 12:01:11.069890295 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:43<00:00 , loss=0.933, lr=9.85e-5, step=1324\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.9194454414931803 LOSS 0.3124934732913971\n",
      "SAVING BEST!\n",
      "1324/1324 10:46<00:00 , loss=0.779, lr=9.43e-5, step=2648\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9227629217516153 LOSS 0.3052193820476532\n",
      "SAVING BEST!\n",
      "1324/1324 10:41<00:00 , loss=0.719, lr=8.74e-5, step=3972\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.9239020997846376 LOSS 0.29366806149482727\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.717, lr=7.84e-5, step=5296\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 4 | AUC 0.9265905419956928 LOSS 0.2921978831291199\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.685, lr=6.77e-5, step=6620\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 5 | AUC 0.9217004666188083 LOSS 0.2864399254322052\n",
      "SAVING BEST!\n",
      "1324/1324 10:42<00:00 , loss=0.612, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9217300789662598 LOSS 0.2997441589832306\n",
      "1324/1324 10:41<00:00 , loss=0.572, lr=4.4e-5, step=9268 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 7 | AUC 0.918868000717875 LOSS 0.30890244245529175\n",
      "1324/1324 10:40<00:00 , loss=0.551, lr=3.23e-5, step=10592\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 8 | AUC 0.9192587939698492 LOSS 0.300176203250885\n",
      "1324/1324 10:40<00:00 , loss=0.516, lr=2.16e-5, step=11916\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 9 | AUC 0.9184668880114859 LOSS 0.29839062690734863\n",
      "1324/1324 10:39<00:00 , loss=0.5, lr=1.26e-5, step=13240  \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9156205132806892 LOSS 0.31152990460395813\n",
      "[rank0]:[W316 14:01:10.952557664 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 14:01:13.222223 2817589 site-packages/torch/distributed/run.py:792] \n",
      "W0316 14:01:13.222223 2817589 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 14:01:13.222223 2817589 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 14:01:13.222223 2817589 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 14:01:27.394815423 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 14:01:28.388212882 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W316 14:01:31.319908098 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W316 14:01:31.351695669 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:43<00:00 , loss=0.928, lr=9.85e-5, step=1324\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.9189248102645442 LOSS 0.3276847004890442\n",
      "SAVING BEST!\n",
      "1324/1324 10:42<00:00 , loss=0.778, lr=9.43e-5, step=2648\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 2 | AUC 0.925476609262369 LOSS 0.3199916481971741\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.731, lr=8.74e-5, step=3972\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.9311737679933011 LOSS 0.30280256271362305\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.705, lr=7.84e-5, step=5296\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9333416035691976 LOSS 0.30412790179252625\n",
      "1324/1324 10:39<00:00 , loss=0.673, lr=6.77e-5, step=6620\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 5 | AUC 0.9276373560646672 LOSS 0.29071658849716187\n",
      "SAVING BEST!\n",
      "1324/1324 10:41<00:00 , loss=0.615, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9255355346929011 LOSS 0.3047448694705963\n",
      "1324/1324 10:40<00:00 , loss=0.575, lr=4.4e-5, step=9268 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 7 | AUC 0.927160636040211 LOSS 0.3224343955516815\n",
      "1324/1324 10:42<00:00 , loss=0.546, lr=3.23e-5, step=10592\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 8 | AUC 0.9299234855499781 LOSS 0.3023611009120941\n",
      "1324/1324 10:41<00:00 , loss=0.525, lr=2.16e-5, step=11916\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.9308880018076372 LOSS 0.30570822954177856\n",
      "1324/1324 10:38<00:00 , loss=0.485, lr=1.26e-5, step=13240\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9269493019773247 LOSS 0.31177157163619995\n",
      "[rank0]:[W316 16:01:27.691125275 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 16:01:30.906095 2832274 site-packages/torch/distributed/run.py:792] \n",
      "W0316 16:01:30.906095 2832274 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 16:01:30.906095 2832274 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 16:01:30.906095 2832274 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 16:01:45.350785664 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 16:01:46.351483898 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W316 16:01:49.339513903 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W316 16:01:49.396945321 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:43<00:00 , loss=0.934, lr=9.85e-5, step=1324\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.8916450016182823 LOSS 0.3524571657180786\n",
      "SAVING BEST!\n",
      "1324/1324 10:44<00:00 , loss=0.755, lr=9.43e-5, step=2648\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 2 | AUC 0.9014224174324191 LOSS 0.3307570219039917\n",
      "SAVING BEST!\n",
      "1324/1324 10:39<00:00 , loss=0.727, lr=8.74e-5, step=3972\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 3 | AUC 0.8980297412155411 LOSS 0.32862529158592224\n",
      "SAVING BEST!\n",
      "1324/1324 10:39<00:00 , loss=0.672, lr=7.84e-5, step=5296\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9024760599749517 LOSS 0.32831597328186035\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.612, lr=6.77e-5, step=6620\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 5 | AUC 0.9025134387796744 LOSS 0.3316498100757599\n",
      "1324/1324 10:40<00:00 , loss=0.577, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9066923891476578 LOSS 0.32822078466415405\n",
      "SAVING BEST!\n",
      "1324/1324 10:42<00:00 , loss=0.542, lr=4.4e-5, step=9268 \n",
      "442/442 01:16<00:00 \n",
      "EPOCH 7 | AUC 0.9024303259079972 LOSS 0.32560428977012634\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.528, lr=3.23e-5, step=10592\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 8 | AUC 0.9067834175309233 LOSS 0.3242943584918976\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.504, lr=2.16e-5, step=11916\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.9065323199133163 LOSS 0.32410427927970886\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.499, lr=1.26e-5, step=13240\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9053889682394494 LOSS 0.3188931941986084\n",
      "SAVING BEST!\n",
      "[rank0]:[W316 18:01:40.563565512 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 18:01:43.887571 2846954 site-packages/torch/distributed/run.py:792] \n",
      "W0316 18:01:43.887571 2846954 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 18:01:43.887571 2846954 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 18:01:43.887571 2846954 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 18:01:58.520319652 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 18:01:59.133886063 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1325 00:00<? [rank1]:[W316 18:02:02.122965254 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W316 18:02:02.152027991 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 10:44<00:00 , loss=0.92, lr=9.85e-5, step=1325 \n",
      "441/441 01:16<00:00 \n",
      "EPOCH 1 | AUC 0.9073554199433365 LOSS 0.3625682294368744\n",
      "SAVING BEST!\n",
      "1325/1325 10:45<00:00 , loss=0.756, lr=9.43e-5, step=2650\n",
      "441/441 01:16<00:00 \n",
      "EPOCH 2 | AUC 0.9187773716083392 LOSS 0.33448153734207153\n",
      "SAVING BEST!\n",
      "1325/1325 10:39<00:00 , loss=0.724, lr=8.74e-5, step=3975\n",
      "441/441 01:16<00:00 \n",
      "EPOCH 3 | AUC 0.9084621691116066 LOSS 0.3576958477497101\n",
      "1325/1325 10:42<00:00 , loss=0.657, lr=7.84e-5, step=5300\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9098595754653641 LOSS 0.34371402859687805\n",
      "1325/1325 10:41<00:00 , loss=0.595, lr=6.77e-5, step=6625\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 5 | AUC 0.9124709030055704 LOSS 0.34320276975631714\n",
      "1325/1325 10:43<00:00 , loss=0.564, lr=5.6e-5, step=7950 \n",
      "441/441 01:16<00:00 \n",
      "EPOCH 6 | AUC 0.9098216273966708 LOSS 0.35305047035217285\n",
      "1325/1325 10:38<00:00 , loss=0.543, lr=4.4e-5, step=9275 \n",
      "441/441 01:16<00:00 \n",
      "EPOCH 7 | AUC 0.9105818398057726 LOSS 0.34310874342918396\n",
      "1325/1325 10:39<00:00 , loss=0.53, lr=3.23e-5, step=10600 \n",
      "441/441 01:17<00:00 \n",
      "EPOCH 8 | AUC 0.9122307042410929 LOSS 0.3485008180141449\n",
      "1325/1325 10:38<00:00 , loss=0.495, lr=2.16e-5, step=11925\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.9149087536603207 LOSS 0.3459586501121521\n",
      "1325/1325 10:40<00:00 , loss=0.485, lr=1.26e-5, step=13250\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9079984520524067 LOSS 0.3566969931125641\n",
      "[rank0]:[W316 20:01:58.613793095 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "V = \"2\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25baa1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32e3e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41562 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 20:18:14.571860 2863773 site-packages/torch/distributed/run.py:792] \n",
      "W0316 20:18:14.571860 2863773 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 20:18:14.571860 2863773 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 20:18:14.571860 2863773 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 20:18:28.862816151 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W316 20:18:29.319635424 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W316 20:18:31.855150107 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W316 20:18:31.868133845 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:42<00:00 , loss=0.936, lr=9.85e-5, step=1324\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.9041154761219091 LOSS 0.3334292471408844\n",
      "SAVING BEST!\n",
      "1324/1324 10:45<00:00 , loss=0.777, lr=9.43e-5, step=2648\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9162208861853094 LOSS 0.31893089413642883\n",
      "SAVING BEST!\n",
      "1324/1324 10:39<00:00 , loss=0.726, lr=8.74e-5, step=3972\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 3 | AUC 0.9185016990904218 LOSS 0.30350223183631897\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.688, lr=7.84e-5, step=5296\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9218759553230044 LOSS 0.31042417883872986\n",
      "1324/1324 10:38<00:00 , loss=0.625, lr=6.77e-5, step=6620\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 5 | AUC 0.9229605376834774 LOSS 0.30008113384246826\n",
      "SAVING BEST!\n",
      "1324/1324 10:39<00:00 , loss=0.597, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.9201387627431781 LOSS 0.3073351979255676\n",
      "1324/1324 10:41<00:00 , loss=0.555, lr=4.4e-5, step=9268 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 7 | AUC 0.9200869260862439 LOSS 0.30940181016921997\n",
      "1324/1324 10:40<00:00 , loss=0.53, lr=3.23e-5, step=10592 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 8 | AUC 0.9199451506142866 LOSS 0.3216094970703125\n",
      "1324/1324 10:39<00:00 , loss=0.518, lr=2.16e-5, step=11916\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.9189899383719745 LOSS 0.33125320076942444\n",
      "1324/1324 10:41<00:00 , loss=0.473, lr=1.26e-5, step=13240\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9145984431280985 LOSS 0.3415580093860626\n",
      "[rank0]:[W316 22:18:24.450107032 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0316 22:18:27.712519 2878467 site-packages/torch/distributed/run.py:792] \n",
      "W0316 22:18:27.712519 2878467 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0316 22:18:27.712519 2878467 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0316 22:18:27.712519 2878467 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W316 22:18:42.468237648 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W316 22:18:42.762428467 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W316 22:18:45.804339944 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W316 22:18:45.822720074 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:43<00:00 , loss=0.944, lr=9.85e-5, step=1324\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.8862263941854411 LOSS 0.34575873613357544\n",
      "SAVING BEST!\n",
      "1324/1324 10:44<00:00 , loss=0.765, lr=9.43e-5, step=2648\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 2 | AUC 0.8962553473678285 LOSS 0.33505862951278687\n",
      "SAVING BEST!\n",
      "1324/1324 10:37<00:00 , loss=0.723, lr=8.74e-5, step=3972\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 3 | AUC 0.8979329960739063 LOSS 0.3278900980949402\n",
      "SAVING BEST!\n",
      "1324/1324 10:40<00:00 , loss=0.68, lr=7.84e-5, step=5296 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9045340929879121 LOSS 0.3213195502758026\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.609, lr=6.77e-5, step=6620\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 5 | AUC 0.8989769641022755 LOSS 0.33968377113342285\n",
      "1324/1324 10:39<00:00 , loss=0.589, lr=5.6e-5, step=7944 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 6 | AUC 0.8999224279864346 LOSS 0.33606845140457153\n",
      "1324/1324 10:38<00:00 , loss=0.564, lr=4.4e-5, step=9268 \n",
      "442/442 01:17<00:00 \n",
      "EPOCH 7 | AUC 0.9037359455694243 LOSS 0.31813982129096985\n",
      "SAVING BEST!\n",
      "1324/1324 10:38<00:00 , loss=0.537, lr=3.23e-5, step=10592\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 8 | AUC 0.9037983901608432 LOSS 0.3194087743759155\n",
      "1324/1324 10:40<00:00 , loss=0.515, lr=2.16e-5, step=11916\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 9 | AUC 0.9024874934916904 LOSS 0.3330223262310028\n",
      "1324/1324 10:39<00:00 , loss=0.506, lr=1.26e-5, step=13240\n",
      "442/442 01:16<00:00 \n",
      "EPOCH 10 | AUC 0.9047073547415674 LOSS 0.3289077579975128\n",
      "[rank0]:[W317 00:18:29.831357571 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 00:18:32.999417 2893194 site-packages/torch/distributed/run.py:792] \n",
      "W0317 00:18:32.999417 2893194 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 00:18:32.999417 2893194 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 00:18:32.999417 2893194 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W317 00:18:47.838814431 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 00:18:48.683947168 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank0]:[W317 00:18:51.660100899 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W317 00:18:51.677798351 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 10:43<00:00 , loss=0.923, lr=9.85e-5, step=1325\n",
      "441/441 01:17<00:00 \n",
      "EPOCH 1 | AUC 0.8985656464057341 LOSS 0.3530072569847107\n",
      "SAVING BEST!\n",
      "1325/1325 10:44<00:00 , loss=0.766, lr=9.43e-5, step=2650\n",
      "441/441 01:16<00:00 \n",
      "EPOCH 2 | AUC 0.9103979376267195 LOSS 0.33041462302207947\n",
      "SAVING BEST!\n",
      "1325/1325 10:43<00:00 , loss=0.74, lr=8.74e-5, step=3975 \n",
      "441/441 01:16<00:00 \n",
      "EPOCH 3 | AUC 0.9053541805844335 LOSS 0.3852625787258148\n",
      "1325/1325 10:40<00:00 , loss=0.709, lr=7.84e-5, step=5300\n",
      "441/441 01:16<00:00 \n",
      "EPOCH 4 | AUC 0.9137799028696247 LOSS 0.3303441107273102\n",
      "SAVING BEST!\n",
      "1325/1325 10:41<00:00 , loss=0.634, lr=6.77e-5, step=6625\n",
      "441/441 01:16<00:00 \n",
      "EPOCH 5 | AUC 0.9128745703736508 LOSS 0.33553823828697205\n",
      "931/1325 07:29<03:10 , loss=0.603, lr=5.96e-5, step=7556"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "V = \"3\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c5d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc31099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41561 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 02:19:05.133006 2907965 site-packages/torch/distributed/run.py:792] \n",
      "W0317 02:19:05.133006 2907965 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 02:19:05.133006 2907965 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 02:19:05.133006 2907965 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W317 02:19:20.554250465 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W317 02:19:20.656419037 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W317 02:19:23.264418522 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W317 02:19:23.277226164 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:54<00:00 , loss=0.928, lr=9.85e-5, step=1324\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 1 | AUC 0.906115839421556 LOSS 0.3386457562446594\n",
      "SAVING BEST!\n",
      "1324/1324 10:55<00:00 , loss=0.799, lr=9.43e-5, step=2648\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9087484327164623 LOSS 0.34066474437713623\n",
      "1324/1324 10:50<00:00 , loss=0.759, lr=8.74e-5, step=3972\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 3 | AUC 0.917058247566557 LOSS 0.3249616026878357\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.723, lr=7.84e-5, step=5296\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 4 | AUC 0.9213194865955723 LOSS 0.312775582075119\n",
      "SAVING BEST!\n",
      "1324/1324 10:50<00:00 , loss=0.665, lr=6.77e-5, step=6620\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 5 | AUC 0.9200838247477947 LOSS 0.30278682708740234\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.618, lr=5.6e-5, step=7944 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 6 | AUC 0.920487441794523 LOSS 0.31809306144714355\n",
      "1324/1324 10:49<00:00 , loss=0.603, lr=4.4e-5, step=9268 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 7 | AUC 0.9287821930007222 LOSS 0.30616265535354614\n",
      "1324/1324 10:53<00:00 , loss=0.567, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9295601859030875 LOSS 0.302620530128479\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.555, lr=2.16e-5, step=11916\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 9 | AUC 0.9282274964666895 LOSS 0.30004820227622986\n",
      "SAVING BEST!\n",
      "1324/1324 11:13<00:00 , loss=0.523, lr=1.26e-5, step=13240\n",
      "442/442 01:23<00:00 \n",
      "EPOCH 10 | AUC 0.9303014057924142 LOSS 0.2984902262687683\n",
      "SAVING BEST!\n",
      "[rank0]:[W317 04:22:01.839740185 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 04:22:05.387240 2922970 site-packages/torch/distributed/run.py:792] \n",
      "W0317 04:22:05.387240 2922970 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 04:22:05.387240 2922970 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 04:22:05.387240 2922970 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W317 04:22:21.593091532 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 04:22:22.494094916 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W317 04:22:25.813844001 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W317 04:22:25.823443130 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:11<00:00 , loss=0.935, lr=9.85e-5, step=1324\n",
      "442/442 01:23<00:00 \n",
      "EPOCH 1 | AUC 0.8784419282889829 LOSS 0.36063888669013977\n",
      "SAVING BEST!\n",
      "1324/1324 10:59<00:00 , loss=0.786, lr=9.43e-5, step=2648\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 2 | AUC 0.8885913731477704 LOSS 0.3389303982257843\n",
      "SAVING BEST!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1324 08:17<02:34 , loss=0.759, lr=8.93e-5, step=3656--- Logging error ---\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 04:55:40.205800 2927598 site-packages/torch/distributed/run.py:792] \n",
      "W0317 04:55:40.205800 2927598 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 04:55:40.205800 2927598 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 04:55:40.205800 2927598 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 04:55:55.780305053 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W317 04:55:55.782700394 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank1]:[W317 04:55:58.815762149 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W317 04:55:58.843157153 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "5/1325 00:04<19:10 , loss=1.66, lr=0.0001, step=5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "V = \"4\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb739912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac2841f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41523 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 07:44:27.864017 2952308 site-packages/torch/distributed/run.py:792] \n",
      "W0317 07:44:27.864017 2952308 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 07:44:27.864017 2952308 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 07:44:27.864017 2952308 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 07:44:42.341112679 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W317 07:44:42.763528148 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W317 07:44:45.810037155 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W317 07:44:45.820535728 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:55<00:00 , loss=0.903, lr=9.85e-5, step=1324\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 1 | AUC 0.9188446697774586 LOSS 0.30714210867881775\n",
      "SAVING BEST!\n",
      "1324/1324 10:56<00:00 , loss=0.785, lr=9.43e-5, step=2648\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 2 | AUC 0.9203275305096914 LOSS 0.2900960147380829\n",
      "SAVING BEST!\n",
      "1324/1324 10:53<00:00 , loss=0.715, lr=8.74e-5, step=3972\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 3 | AUC 0.9299919239052405 LOSS 0.2991366684436798\n",
      "1324/1324 10:52<00:00 , loss=0.675, lr=7.84e-5, step=5296\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 4 | AUC 0.9269862706389088 LOSS 0.2955724895000458\n",
      "1324/1324 10:54<00:00 , loss=0.622, lr=6.77e-5, step=6620\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 5 | AUC 0.9278252871500359 LOSS 0.29400452971458435\n",
      "1324/1324 10:51<00:00 , loss=0.579, lr=5.6e-5, step=7944 \n",
      "442/442 01:19<00:00 \n",
      "EPOCH 6 | AUC 0.9330141780330223 LOSS 0.2819973826408386\n",
      "SAVING BEST!\n",
      "1324/1324 10:51<00:00 , loss=0.545, lr=4.4e-5, step=9268 \n",
      "442/442 01:20<00:00 \n",
      "EPOCH 7 | AUC 0.9315882986360372 LOSS 0.2845953702926636\n",
      "1324/1324 10:53<00:00 , loss=0.522, lr=3.23e-5, step=10592\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 8 | AUC 0.9329253409906676 LOSS 0.28507712483406067\n",
      "1324/1324 10:52<00:00 , loss=0.498, lr=2.16e-5, step=11916\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 9 | AUC 0.9325565326633166 LOSS 0.28582823276519775\n",
      "1324/1324 10:53<00:00 , loss=0.499, lr=1.26e-5, step=13240\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 10 | AUC 0.9302584350323044 LOSS 0.29157525300979614\n",
      "[rank0]:[W317 09:47:08.053502162 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 09:47:11.876126 2967275 site-packages/torch/distributed/run.py:792] \n",
      "W0317 09:47:11.876126 2967275 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 09:47:11.876126 2967275 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 09:47:11.876126 2967275 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W317 09:47:28.103165116 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 09:47:28.575671286 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W317 09:47:31.670712784 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W317 09:47:31.697997635 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:00<00:00 , loss=0.901, lr=9.85e-5, step=1324\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 1 | AUC 0.9215512008825524 LOSS 0.32268109917640686\n",
      "SAVING BEST!\n",
      "1324/1324 10:57<00:00 , loss=0.781, lr=9.43e-5, step=2648\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 2 | AUC 0.9322450589032781 LOSS 0.30277150869369507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING BEST!\n",
      "1324/1324 10:52<00:00 , loss=0.725, lr=8.74e-5, step=3972\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 3 | AUC 0.9331196363459145 LOSS 0.29384884238243103\n",
      "SAVING BEST!\n",
      "1324/1324 10:53<00:00 , loss=0.689, lr=7.84e-5, step=5296\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 4 | AUC 0.9279944530346595 LOSS 0.30112341046333313\n",
      "1324/1324 10:49<00:00 , loss=0.627, lr=6.77e-5, step=6620\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 5 | AUC 0.9250645742969931 LOSS 0.30714571475982666\n",
      "1324/1324 10:52<00:00 , loss=0.593, lr=5.6e-5, step=7944 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 6 | AUC 0.9229747152306732 LOSS 0.29644647240638733\n",
      "1324/1324 10:51<00:00 , loss=0.567, lr=4.4e-5, step=9268 \n",
      "442/442 01:18<00:00 \n",
      "EPOCH 7 | AUC 0.9244726617015715 LOSS 0.31540438532829285\n",
      "1324/1324 10:49<00:00 , loss=0.526, lr=3.23e-5, step=10592\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 8 | AUC 0.9332419176904776 LOSS 0.28371164202690125\n",
      "SAVING BEST!\n",
      "1324/1324 10:50<00:00 , loss=0.516, lr=2.16e-5, step=11916\n",
      "442/442 01:18<00:00 \n",
      "EPOCH 9 | AUC 0.9297125945354416 LOSS 0.29343515634536743\n",
      "1324/1324 10:54<00:00 , loss=0.491, lr=1.26e-5, step=13240\n",
      "442/442 01:17<00:00 \n",
      "EPOCH 10 | AUC 0.9296806950542513 LOSS 0.2935155928134918\n",
      "[rank0]:[W317 11:49:44.025640478 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0317 11:49:47.462683 2982233 site-packages/torch/distributed/run.py:792] \n",
      "W0317 11:49:47.462683 2982233 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0317 11:49:47.462683 2982233 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0317 11:49:47.462683 2982233 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W317 11:50:02.377597456 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W317 11:50:02.514012878 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W317 11:50:05.178272233 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W317 11:50:05.216711033 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 10:56<00:00 , loss=0.901, lr=9.85e-5, step=1324\n",
      "442/442 01:19<00:00 \n",
      "EPOCH 1 | AUC 0.9019215344131264 LOSS 0.32568421959877014\n",
      "SAVING BEST!\n",
      "1324/1324 10:58<00:00 , loss=0.759, lr=9.43e-5, step=2648\n",
      "45/442 00:08<01:09 "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnet_b3.ns_jft_in1k\"\n",
    "V = \"5\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26d868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beee71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 41699 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0318 00:15:29.378662 3072075 site-packages/torch/distributed/run.py:792] \n",
      "W0318 00:15:29.378662 3072075 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0318 00:15:29.378662 3072075 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0318 00:15:29.378662 3072075 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W318 00:15:43.758872536 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W318 00:15:43.771716244 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W318 00:15:46.504757367 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W318 00:15:46.551566683 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:01<00:00 , loss=0.913, lr=9.85e-5, step=1324\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 1 | AUC 0.9047922648959081 LOSS 0.33254295587539673\n",
      "SAVING BEST!\n",
      "1324/1324 11:01<00:00 , loss=0.783, lr=9.43e-5, step=2648\n",
      "442/442 01:26<00:00 \n",
      "EPOCH 2 | AUC 0.9178508614501076 LOSS 0.29822176694869995\n",
      "SAVING BEST!\n",
      "1324/1324 11:03<00:00 , loss=0.738, lr=8.74e-5, step=3972\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.914417175161522 LOSS 0.3378426432609558\n",
      "1324/1324 10:59<00:00 , loss=0.683, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9231312814070352 LOSS 0.2967609167098999\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.632, lr=6.77e-5, step=6620\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9236692390524048 LOSS 0.279183954000473\n",
      "SAVING BEST!\n",
      "1324/1324 11:00<00:00 , loss=0.592, lr=5.6e-5, step=7944 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.9213967157214644 LOSS 0.2935754656791687\n",
      "1324/1324 11:03<00:00 , loss=0.554, lr=4.4e-5, step=9268 \n",
      "442/442 01:23<00:00 \n",
      "EPOCH 7 | AUC 0.9218462849964106 LOSS 0.2876734435558319\n",
      "1324/1324 11:03<00:00 , loss=0.547, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9277229899497488 LOSS 0.2886265814304352\n",
      "1324/1324 11:00<00:00 , loss=0.511, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9256312814070352 LOSS 0.28543326258659363\n",
      "1324/1324 11:07<00:00 , loss=0.489, lr=1.26e-5, step=13240\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 10 | AUC 0.9272231694185211 LOSS 0.2775975465774536\n",
      "SAVING BEST!\n",
      "[rank0]:[W318 02:20:10.744853801 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0318 02:20:14.646588 3089298 site-packages/torch/distributed/run.py:792] \n",
      "W0318 02:20:14.646588 3089298 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0318 02:20:14.646588 3089298 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0318 02:20:14.646588 3089298 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W318 02:20:31.934506917 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W318 02:20:32.395856528 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank0]:[W318 02:20:35.510272457 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W318 02:20:35.510645745 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:06<00:00 , loss=0.918, lr=9.85e-5, step=1324\n",
      "442/442 01:23<00:00 \n",
      "EPOCH 1 | AUC 0.90305171703388 LOSS 0.3343035876750946\n",
      "SAVING BEST!\n",
      "1324/1324 11:07<00:00 , loss=0.783, lr=9.43e-5, step=2648\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 2 | AUC 0.9141553947782322 LOSS 0.32446202635765076\n",
      "SAVING BEST!\n",
      "1324/1324 10:59<00:00 , loss=0.734, lr=8.74e-5, step=3972\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 3 | AUC 0.9222707114027354 LOSS 0.3121471405029297\n",
      "SAVING BEST!\n",
      "1324/1324 10:57<00:00 , loss=0.694, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9195371030840596 LOSS 0.325430691242218\n",
      "1324/1324 10:59<00:00 , loss=0.627, lr=6.77e-5, step=6620\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 5 | AUC 0.9175779432809502 LOSS 0.3129362463951111\n",
      "1324/1324 10:59<00:00 , loss=0.592, lr=5.6e-5, step=7944 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.9183927091963546 LOSS 0.3121180832386017\n",
      "SAVING BEST!\n",
      "1324/1324 10:59<00:00 , loss=0.559, lr=4.4e-5, step=9268 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.9191388026175297 LOSS 0.35411593317985535\n",
      "1324/1324 11:00<00:00 , loss=0.537, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9123220607064848 LOSS 0.38124510645866394\n",
      "1324/1324 11:03<00:00 , loss=0.518, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9098219388681887 LOSS 0.367111474275589\n",
      "1324/1324 11:01<00:00 , loss=0.495, lr=1.26e-5, step=13240\n",
      "442/442 01:27<00:00 \n",
      "EPOCH 10 | AUC 0.9126016242152506 LOSS 0.3950180411338806\n",
      "[rank0]:[W318 04:24:54.126324742 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0318 04:24:58.283891 3115789 site-packages/torch/distributed/run.py:792] \n",
      "W0318 04:24:58.283891 3115789 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0318 04:24:58.283891 3115789 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0318 04:24:58.283891 3115789 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W318 04:25:15.588620639 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W318 04:25:16.085939220 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1324 00:00<? [rank1]:[W318 04:25:19.067191717 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank0]:[W318 04:25:19.122064989 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1324/1324 11:03<00:00 , loss=0.908, lr=9.85e-5, step=1324\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 1 | AUC 0.891555732237592 LOSS 0.3480534851551056\n",
      "SAVING BEST!\n",
      "1324/1324 11:02<00:00 , loss=0.759, lr=9.43e-5, step=2648\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 2 | AUC 0.8998305201018815 LOSS 0.32403501868247986\n",
      "SAVING BEST!\n",
      "1324/1324 11:02<00:00 , loss=0.707, lr=8.74e-5, step=3972\n",
      "442/442 01:22<00:00 \n",
      "EPOCH 3 | AUC 0.8967206035489635 LOSS 0.32829749584198\n",
      "1324/1324 11:01<00:00 , loss=0.641, lr=7.84e-5, step=5296\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.8971251741412548 LOSS 0.32768774032592773\n",
      "1324/1324 11:00<00:00 , loss=0.588, lr=6.77e-5, step=6620\n",
      "442/442 01:20<00:00 \n",
      "EPOCH 5 | AUC 0.9030077185032999 LOSS 0.32244446873664856\n",
      "SAVING BEST!\n",
      "1324/1324 11:03<00:00 , loss=0.541, lr=5.6e-5, step=7944 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.8992944640670955 LOSS 0.3377707004547119\n",
      "1324/1324 10:58<00:00 , loss=0.529, lr=4.4e-5, step=9268 \n",
      "442/442 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.8985649177490396 LOSS 0.3264620006084442\n",
      "1324/1324 10:58<00:00 , loss=0.513, lr=3.23e-5, step=10592\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 8 | AUC 0.9027425488650915 LOSS 0.3501039445400238\n",
      "1324/1324 11:00<00:00 , loss=0.489, lr=2.16e-5, step=11916\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 9 | AUC 0.9048071781377088 LOSS 0.3555460274219513\n",
      "1324/1324 10:59<00:00 , loss=0.494, lr=1.26e-5, step=13240\n",
      "442/442 01:21<00:00 \n",
      "EPOCH 10 | AUC 0.8996203192941474 LOSS 0.38499054312705994\n",
      "[rank0]:[W318 06:29:22.750857907 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0318 06:29:26.195561 3138228 site-packages/torch/distributed/run.py:792] \n",
      "W0318 06:29:26.195561 3138228 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0318 06:29:26.195561 3138228 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0318 06:29:26.195561 3138228 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank1]:[W318 06:29:40.729693754 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 15, 2])\n",
      "torch.Size([15, 2, 256, 256])\n",
      "[rank0]:[W318 06:29:41.165247023 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/1325 00:00<? [rank0]:[W318 06:29:44.330646530 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank1]:[W318 06:29:44.367476733 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "1325/1325 11:06<00:00 , loss=0.903, lr=9.85e-5, step=1325\n",
      "441/441 01:22<00:00 \n",
      "EPOCH 1 | AUC 0.9149562929991235 LOSS 0.3428924083709717\n",
      "SAVING BEST!\n",
      "1325/1325 11:07<00:00 , loss=0.759, lr=9.43e-5, step=2650\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 2 | AUC 0.9217469122365425 LOSS 0.3287520706653595\n",
      "SAVING BEST!\n",
      "1325/1325 11:01<00:00 , loss=0.732, lr=8.74e-5, step=3975\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 3 | AUC 0.9176873029098245 LOSS 0.3397231996059418\n",
      "1325/1325 10:59<00:00 , loss=0.68, lr=7.84e-5, step=5300 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 4 | AUC 0.9120597294261001 LOSS 0.33982858061790466\n",
      "1325/1325 10:59<00:00 , loss=0.612, lr=6.77e-5, step=6625\n",
      "441/441 01:21<00:00 \n",
      "EPOCH 5 | AUC 0.9186864630481724 LOSS 0.33988234400749207\n",
      "1325/1325 11:00<00:00 , loss=0.567, lr=5.6e-5, step=7950 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 6 | AUC 0.9209575090053685 LOSS 0.3261159062385559\n",
      "SAVING BEST!\n",
      "1325/1325 10:58<00:00 , loss=0.548, lr=4.4e-5, step=9275 \n",
      "441/441 01:21<00:00 \n",
      "EPOCH 7 | AUC 0.9289599643705166 LOSS 0.3056991696357727\n",
      "SAVING BEST!\n",
      "850/1325 07:01<03:54 , loss=0.526, lr=3.64e-5, step=10125"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/classification_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"18\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7723d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6619e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274749e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b95b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391733dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdde79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cfcd8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3542584478855133,\n",
       "  0.37006810307502747,\n",
       "  0.3344306945800781,\n",
       "  0.3816215395927429],\n",
       " 0.36009469628334045)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v12/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca43144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.37414276599884033,\n",
       "  0.37396004796028137,\n",
       "  0.308594673871994,\n",
       "  0.3299085199832916],\n",
       " 0.34665150195360184)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v13/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ba35dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.33614760637283325,\n",
       "  0.3575218915939331,\n",
       "  0.33470290899276733,\n",
       "  0.3354106843471527],\n",
       " 0.3409457728266716)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v14/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b74ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.28703412413597107,\n",
       "  0.2727491855621338,\n",
       "  0.3321133553981781,\n",
       "  0.3411742150783539],\n",
       " 0.3082677200436592)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v15/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e9ff40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2743934690952301,\n",
       "  0.2829216420650482,\n",
       "  0.31635114550590515,\n",
       "  0.3182673454284668],\n",
       " 0.29798340052366257)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v16/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaa602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2743934690952301,\n",
       "  0.2727350890636444,\n",
       "  0.3568212389945984,\n",
       "  0.3290081024169922],\n",
       " 0.30823947489261627)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v17/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "140752c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.29775387048721313,\n",
       "  0.2967812418937683,\n",
       "  0.3074108958244324,\n",
       "  0.3287014067173004],\n",
       " 0.30766185373067856)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnet_b3.ns_jft_in1k_v1/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b69288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2864399254322052,\n",
       "  0.29071658849716187,\n",
       "  0.3188931941986084,\n",
       "  0.33448153734207153],\n",
       " 0.30763281136751175)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnet_b3.ns_jft_in1k_v2/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c9a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2819973826408386,\n",
       "  0.28371164202690125,\n",
       "  0.2843354642391205,\n",
       "  0.2931705415248871],\n",
       " 0.28580375760793686)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnet_b3.ns_jft_in1k_v5/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4b29d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2775975465774536,\n",
       "  0.3121180832386017,\n",
       "  0.32244446873664856,\n",
       "  0.3056991696357727],\n",
       " 0.30446481704711914)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split(' LOSS ')[1].split(' |')[0]) for line in open(f'./data/classification_model/tf_efficientnetv2_s.in21k_ft_in1k_v18/log_{F}.txt').readlines() if 'LOSS' in line]).min() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f63664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd289e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd0914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b459ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
