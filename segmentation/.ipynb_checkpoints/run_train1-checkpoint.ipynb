{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e72d0a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 28739 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 01:32:34.307512 1006200 site-packages/torch/distributed/run.py:792] \n",
      "W0307 01:32:34.307512 1006200 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 01:32:34.307512 1006200 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 01:32:34.307512 1006200 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "Convert layer weights: blocks.0.0.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.0.1.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_exp.weight. Shape: torch.Size([96, 24, 3, 3]) -> torch.Size([96, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_pwl.weight. Shape: torch.Size([48, 96, 1, 1]) -> torch.Size([48, 96, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.1.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.1.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.2.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.2.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.3.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.3.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.0.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.0.conv_pwl.weight. Shape: torch.Size([64, 192, 1, 1]) -> torch.Size([64, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.1.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.1.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.2.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.2.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.3.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.3.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_dw.weight. Shape: torch.Size([256, 1, 3, 3]) -> torch.Size([256, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.0.conv_pw.weight. Shape: torch.Size([256, 64, 1, 1]) -> torch.Size([256, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_pwl.weight. Shape: torch.Size([128, 256, 1, 1]) -> torch.Size([128, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_expand.weight. Shape: torch.Size([256, 16, 1, 1]) -> torch.Size([256, 16, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_reduce.weight. Shape: torch.Size([16, 256, 1, 1]) -> torch.Size([16, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.1.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.2.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.3.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.4.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.5.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_dw.weight. Shape: torch.Size([768, 1, 3, 3]) -> torch.Size([768, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.0.conv_pw.weight. Shape: torch.Size([768, 128, 1, 1]) -> torch.Size([768, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_pwl.weight. Shape: torch.Size([160, 768, 1, 1]) -> torch.Size([160, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_expand.weight. Shape: torch.Size([768, 32, 1, 1]) -> torch.Size([768, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_reduce.weight. Shape: torch.Size([32, 768, 1, 1]) -> torch.Size([32, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.1.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.2.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.3.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.4.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.5.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.6.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.7.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.8.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.0.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_pwl.weight. Shape: torch.Size([256, 960, 1, 1]) -> torch.Size([256, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.1.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.10.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.11.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: blocks.5.12.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.13.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.14.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.2.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.3.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.4.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.5.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.6.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.7.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.8.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.9.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: conv_head.weight. Shape: torch.Size([1280, 256, 1, 1]) -> torch.Size([1280, 256, 1, 1, 1])\n",
      "Convert layer weights: conv_stem.weight. Shape: torch.Size([24, 1, 3, 3]) -> torch.Size([24, 1, 3, 3, 3])\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Convert layer weights: blocks.0.0.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.0.1.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_exp.weight. Shape: torch.Size([96, 24, 3, 3]) -> torch.Size([96, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_pwl.weight. Shape: torch.Size([48, 96, 1, 1]) -> torch.Size([48, 96, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.1.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.1.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.2.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.2.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.3.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.3.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.0.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.0.conv_pwl.weight. Shape: torch.Size([64, 192, 1, 1]) -> torch.Size([64, 192, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: blocks.2.1.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.2.1.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.2.2.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.2.2.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.2.3.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.2.3.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.0.conv_dw.weight. Shape: torch.Size([256, 1, 3, 3]) -> torch.Size([256, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.0.conv_pw.weight. Shape: torch.Size([256, 64, 1, 1]) -> torch.Size([256, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.0.conv_pwl.weight. Shape: torch.Size([128, 256, 1, 1]) -> torch.Size([128, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.0.se.conv_expand.weight. Shape: torch.Size([256, 16, 1, 1]) -> torch.Size([256, 16, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.0.se.conv_reduce.weight. Shape: torch.Size([16, 256, 1, 1]) -> torch.Size([16, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.1.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.1.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.1.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.1.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.1.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.2.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.2.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.2.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.2.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.2.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.3.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.3.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.3.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.3.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.3.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.4.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.4.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.4.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.4.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.4.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.5.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.3.5.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.5.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.5.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.3.5.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.0.conv_dw.weight. Shape: torch.Size([768, 1, 3, 3]) -> torch.Size([768, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.0.conv_pw.weight. Shape: torch.Size([768, 128, 1, 1]) -> torch.Size([768, 128, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.0.conv_pwl.weight. Shape: torch.Size([160, 768, 1, 1]) -> torch.Size([160, 768, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.0.se.conv_expand.weight. Shape: torch.Size([768, 32, 1, 1]) -> torch.Size([768, 32, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.0.se.conv_reduce.weight. Shape: torch.Size([32, 768, 1, 1]) -> torch.Size([32, 768, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.1.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.1.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.1.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.1.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.1.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.2.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.2.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.2.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.2.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.2.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.3.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.3.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.3.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.3.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.3.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.4.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.4.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.4.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.4.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.4.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.5.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.5.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.5.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.5.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.5.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.6.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.6.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.6.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.6.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.6.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.7.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.7.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.7.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.7.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.7.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.8.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.4.8.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.8.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.8.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.4.8.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.0.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.0.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.0.conv_pwl.weight. Shape: torch.Size([256, 960, 1, 1]) -> torch.Size([256, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.0.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.0.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.1.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.1.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.1.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.1.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.1.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.10.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.10.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.10.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.10.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.10.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.11.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.11.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.11.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.11.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.11.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.12.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.12.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.12.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.12.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.12.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.13.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.13.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.13.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.13.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.13.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.14.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\r\n",
      "Convert layer weights: blocks.5.14.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\r\n",
      "Convert layer weights: blocks.5.14.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: blocks.5.14.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.2.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.3.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.4.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.5.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.6.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.7.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.8.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.9.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: conv_head.weight. Shape: torch.Size([1280, 256, 1, 1]) -> torch.Size([1280, 256, 1, 1, 1])\n",
      "Convert layer weights: conv_stem.weight. Shape: torch.Size([24, 1, 3, 3]) -> torch.Size([24, 1, 3, 3, 3])\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256, 32])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256, 32])\n",
      "[rank0]:[W307 01:32:51.937506097 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W307 01:32:51.983454453 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "DOING DDP\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Convert layer weights: blocks.0.0.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.0.1.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_exp.weight. Shape: torch.Size([96, 24, 3, 3]) -> torch.Size([96, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_pwl.weight. Shape: torch.Size([48, 96, 1, 1]) -> torch.Size([48, 96, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.1.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.1.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.2.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.2.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.3.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.3.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.0.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.0.conv_pwl.weight. Shape: torch.Size([64, 192, 1, 1]) -> torch.Size([64, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.1.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.1.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.2.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.2.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.3.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.3.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_dw.weight. Shape: torch.Size([256, 1, 3, 3]) -> torch.Size([256, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.0.conv_pw.weight. Shape: torch.Size([256, 64, 1, 1]) -> torch.Size([256, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_pwl.weight. Shape: torch.Size([128, 256, 1, 1]) -> torch.Size([128, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_expand.weight. Shape: torch.Size([256, 16, 1, 1]) -> torch.Size([256, 16, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_reduce.weight. Shape: torch.Size([16, 256, 1, 1]) -> torch.Size([16, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.1.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.2.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.3.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.4.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.5.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_dw.weight. Shape: torch.Size([768, 1, 3, 3]) -> torch.Size([768, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.0.conv_pw.weight. Shape: torch.Size([768, 128, 1, 1]) -> torch.Size([768, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_pwl.weight. Shape: torch.Size([160, 768, 1, 1]) -> torch.Size([160, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_expand.weight. Shape: torch.Size([768, 32, 1, 1]) -> torch.Size([768, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_reduce.weight. Shape: torch.Size([32, 768, 1, 1]) -> torch.Size([32, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.1.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.2.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.3.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.4.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.5.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.6.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.7.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.8.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.0.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_pwl.weight. Shape: torch.Size([256, 960, 1, 1]) -> torch.Size([256, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.1.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.10.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.11.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.12.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.13.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: blocks.5.13.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.14.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.2.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.3.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.4.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.5.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.6.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.7.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.8.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.9.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: conv_head.weight. Shape: torch.Size([1280, 256, 1, 1]) -> torch.Size([1280, 256, 1, 1, 1])\n",
      "Convert layer weights: conv_stem.weight. Shape: torch.Size([24, 1, 3, 3]) -> torch.Size([24, 1, 3, 3, 3])\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "169/169 03:08<00:00 , loss=1.1, lr=0.000999, step=169 \n",
      "Convert layer weights: blocks.0.0.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.0.1.conv.weight. Shape: torch.Size([24, 24, 3, 3]) -> torch.Size([24, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_exp.weight. Shape: torch.Size([96, 24, 3, 3]) -> torch.Size([96, 24, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.0.conv_pwl.weight. Shape: torch.Size([48, 96, 1, 1]) -> torch.Size([48, 96, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.1.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.1.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.2.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.2.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.1.3.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.1.3.conv_pwl.weight. Shape: torch.Size([48, 192, 1, 1]) -> torch.Size([48, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.0.conv_exp.weight. Shape: torch.Size([192, 48, 3, 3]) -> torch.Size([192, 48, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.0.conv_pwl.weight. Shape: torch.Size([64, 192, 1, 1]) -> torch.Size([64, 192, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.1.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.1.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.2.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.2.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.2.3.conv_exp.weight. Shape: torch.Size([256, 64, 3, 3]) -> torch.Size([256, 64, 3, 3, 3])\n",
      "Convert layer weights: blocks.2.3.conv_pwl.weight. Shape: torch.Size([64, 256, 1, 1]) -> torch.Size([64, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_dw.weight. Shape: torch.Size([256, 1, 3, 3]) -> torch.Size([256, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.0.conv_pw.weight. Shape: torch.Size([256, 64, 1, 1]) -> torch.Size([256, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.conv_pwl.weight. Shape: torch.Size([128, 256, 1, 1]) -> torch.Size([128, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_expand.weight. Shape: torch.Size([256, 16, 1, 1]) -> torch.Size([256, 16, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.0.se.conv_reduce.weight. Shape: torch.Size([16, 256, 1, 1]) -> torch.Size([16, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.1.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.1.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.2.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.2.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.3.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.3.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.4.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.4.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_dw.weight. Shape: torch.Size([512, 1, 3, 3]) -> torch.Size([512, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.3.5.conv_pw.weight. Shape: torch.Size([512, 128, 1, 1]) -> torch.Size([512, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.conv_pwl.weight. Shape: torch.Size([128, 512, 1, 1]) -> torch.Size([128, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_expand.weight. Shape: torch.Size([512, 32, 1, 1]) -> torch.Size([512, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.3.5.se.conv_reduce.weight. Shape: torch.Size([32, 512, 1, 1]) -> torch.Size([32, 512, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_dw.weight. Shape: torch.Size([768, 1, 3, 3]) -> torch.Size([768, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.0.conv_pw.weight. Shape: torch.Size([768, 128, 1, 1]) -> torch.Size([768, 128, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.conv_pwl.weight. Shape: torch.Size([160, 768, 1, 1]) -> torch.Size([160, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_expand.weight. Shape: torch.Size([768, 32, 1, 1]) -> torch.Size([768, 32, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.0.se.conv_reduce.weight. Shape: torch.Size([32, 768, 1, 1]) -> torch.Size([32, 768, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.1.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.1.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.2.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.2.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.3.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.3.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.4.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.4.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.5.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.5.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.6.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.6.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.7.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.7.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.4.8.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.conv_pwl.weight. Shape: torch.Size([160, 960, 1, 1]) -> torch.Size([160, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.4.8.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_dw.weight. Shape: torch.Size([960, 1, 3, 3]) -> torch.Size([960, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.0.conv_pw.weight. Shape: torch.Size([960, 160, 1, 1]) -> torch.Size([960, 160, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.conv_pwl.weight. Shape: torch.Size([256, 960, 1, 1]) -> torch.Size([256, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_expand.weight. Shape: torch.Size([960, 40, 1, 1]) -> torch.Size([960, 40, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.0.se.conv_reduce.weight. Shape: torch.Size([40, 960, 1, 1]) -> torch.Size([40, 960, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.1.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.1.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.10.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.10.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.11.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.11.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.12.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.12.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.13.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.13.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.14.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.14.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.2.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.2.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: blocks.5.2.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.3.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.3.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.4.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.4.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.5.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.5.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.6.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.6.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.7.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.7.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.8.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.8.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_dw.weight. Shape: torch.Size([1536, 1, 3, 3]) -> torch.Size([1536, 1, 3, 3, 3])\n",
      "Convert layer weights: blocks.5.9.conv_pw.weight. Shape: torch.Size([1536, 256, 1, 1]) -> torch.Size([1536, 256, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.conv_pwl.weight. Shape: torch.Size([256, 1536, 1, 1]) -> torch.Size([256, 1536, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_expand.weight. Shape: torch.Size([1536, 64, 1, 1]) -> torch.Size([1536, 64, 1, 1, 1])\n",
      "Convert layer weights: blocks.5.9.se.conv_reduce.weight. Shape: torch.Size([64, 1536, 1, 1]) -> torch.Size([64, 1536, 1, 1, 1])\n",
      "Convert layer weights: conv_head.weight. Shape: torch.Size([1280, 256, 1, 1]) -> torch.Size([1280, 256, 1, 1, 1])\n",
      "Convert layer weights: conv_stem.weight. Shape: torch.Size([24, 1, 3, 3]) -> torch.Size([24, 1, 3, 3, 3])\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 798, in <module>\n",
      "[rank1]:     run(model, get_loaders)\n",
      "[rank1]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 725, in run\n",
      "[rank1]:     score = valid_one_epoch(f\"{OUTPUT_FOLDER}/{CFG.FOLD}_EMA.pth\", valid_loader, debug=False, running_dist=CFG.DDP_INIT_DONE)\n",
      "[rank1]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 612, in valid_one_epoch\n",
      "[rank1]:     PixelLevelF1Scorer = PixelLevelF1()\n",
      "[rank1]: NameError: name 'PixelLevelF1' is not defined\n",
      "0/58 00:00<? [rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 798, in <module>\n",
      "[rank0]:     run(model, get_loaders)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 725, in run\n",
      "[rank0]:     score = valid_one_epoch(f\"{OUTPUT_FOLDER}/{CFG.FOLD}_EMA.pth\", valid_loader, debug=False, running_dist=CFG.DDP_INIT_DONE)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py\", line 612, in valid_one_epoch\n",
      "[rank0]:     PixelLevelF1Scorer = PixelLevelF1()\n",
      "[rank0]: NameError: name 'PixelLevelF1' is not defined\n",
      "0/58 00:00<? \n",
      "[rank0]:[W307 01:36:02.676340330 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W0307 01:36:04.006026 1006200 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1006250 closing signal SIGTERM\n",
      "E0307 01:36:04.120511 1006200 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 1 (pid: 1006251) of binary: /home/harshit/anaconda3/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 208, in <module>\n",
      "    main()\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/typing_extensions.py\", line 2853, in wrapper\n",
      "    return arg(*args, **kwargs)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 204, in main\n",
      "    launch(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py\", line 189, in launch\n",
      "    run(args)\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "./data/segmentation_model//tf_efficientnetv2_s.in21k_ft_in1k_v1/run.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-03-07_01:36:04\n",
      "  host      : harshit\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 1006251)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835f1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db412d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 29397 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 01:52:43.529455 1008764 site-packages/torch/distributed/run.py:792] \n",
      "W0307 01:52:43.529455 1008764 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 01:52:43.529455 1008764 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 01:52:43.529455 1008764 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "Convert layer weights: conv1.weight. Shape: torch.Size([64, 1, 7, 7]) -> torch.Size([64, 1, 7, 7, 7])\n",
      "Convert layer weights: layer1.0.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.0.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv1.weight. Shape: torch.Size([128, 64, 3, 3]) -> torch.Size([128, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.downsample.0.weight. Shape: torch.Size([128, 64, 1, 1]) -> torch.Size([128, 64, 1, 1, 1])\n",
      "Convert layer weights: layer2.1.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.1.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv1.weight. Shape: torch.Size([256, 128, 3, 3]) -> torch.Size([256, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.downsample.0.weight. Shape: torch.Size([256, 128, 1, 1]) -> torch.Size([256, 128, 1, 1, 1])\n",
      "Convert layer weights: layer3.1.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.1.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.conv1.weight. Shape: torch.Size([512, 256, 3, 3]) -> torch.Size([512, 256, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.downsample.0.weight. Shape: torch.Size([512, 256, 1, 1]) -> torch.Size([512, 256, 1, 1, 1])\n",
      "Convert layer weights: layer4.1.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.1.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: conv1.weight. Shape: torch.Size([64, 1, 7, 7]) -> torch.Size([64, 1, 7, 7, 7])\n",
      "Convert layer weights: layer1.0.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.0.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv1.weight. Shape: torch.Size([128, 64, 3, 3]) -> torch.Size([128, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.downsample.0.weight. Shape: torch.Size([128, 64, 1, 1]) -> torch.Size([128, 64, 1, 1, 1])\n",
      "Convert layer weights: layer2.1.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.1.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv1.weight. Shape: torch.Size([256, 128, 3, 3]) -> torch.Size([256, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.downsample.0.weight. Shape: torch.Size([256, 128, 1, 1]) -> torch.Size([256, 128, 1, 1, 1])\n",
      "Convert layer weights: layer3.1.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.1.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert layer weights: layer4.0.conv1.weight. Shape: torch.Size([512, 256, 3, 3]) -> torch.Size([512, 256, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.downsample.0.weight. Shape: torch.Size([512, 256, 1, 1]) -> torch.Size([512, 256, 1, 1, 1])\n",
      "Convert layer weights: layer4.1.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.1.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256, 32])\n",
      "[rank0]:[W307 01:53:00.005586539 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256, 32])\n",
      "[rank1]:[W307 01:53:00.784280712 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "Convert layer weights: conv1.weight. Shape: torch.Size([64, 1, 7, 7]) -> torch.Size([64, 1, 7, 7, 7])\n",
      "Convert layer weights: layer1.0.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.0.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.1.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv1.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer1.2.conv2.weight. Shape: torch.Size([64, 64, 3, 3]) -> torch.Size([64, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv1.weight. Shape: torch.Size([128, 64, 3, 3]) -> torch.Size([128, 64, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.0.downsample.0.weight. Shape: torch.Size([128, 64, 1, 1]) -> torch.Size([128, 64, 1, 1, 1])\n",
      "Convert layer weights: layer2.1.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.1.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.2.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv1.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer2.3.conv2.weight. Shape: torch.Size([128, 128, 3, 3]) -> torch.Size([128, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv1.weight. Shape: torch.Size([256, 128, 3, 3]) -> torch.Size([256, 128, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.0.downsample.0.weight. Shape: torch.Size([256, 128, 1, 1]) -> torch.Size([256, 128, 1, 1, 1])\n",
      "Convert layer weights: layer3.1.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.1.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.2.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.3.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.4.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv1.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer3.5.conv2.weight. Shape: torch.Size([256, 256, 3, 3]) -> torch.Size([256, 256, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.conv1.weight. Shape: torch.Size([512, 256, 3, 3]) -> torch.Size([512, 256, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.0.downsample.0.weight. Shape: torch.Size([512, 256, 1, 1]) -> torch.Size([512, 256, 1, 1, 1])\n",
      "Convert layer weights: layer4.1.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.1.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv1.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "Convert layer weights: layer4.2.conv2.weight. Shape: torch.Size([512, 512, 3, 3]) -> torch.Size([512, 512, 3, 3, 3])\n",
      "169/169 02:59<00:00 , loss=0.998, lr=0.000999, step=169\n",
      "58/58 02:29<00:00 \n",
      "EPOCH 1 | DICE 0.3027521365806663\n",
      "[0.15814512 0.31885574 0.39785966 0.43845262 0.38096489 0.3087809\n",
      " 0.23139531 0.18756287]\n",
      "SAVING BEST!\n",
      "169/169 02:57<00:00 , loss=0.82, lr=0.000995, step=338 \n",
      "58/58 02:31<00:00 \n",
      "EPOCH 2 | DICE 0.38031410735189225\n",
      "[0.16473355 0.40439779 0.60394771 0.60851672 0.49440971 0.30367286\n",
      " 0.20572308 0.25711143]\n",
      "SAVING BEST!\n",
      "169/169 02:57<00:00 , loss=0.706, lr=0.000989, step=507\n",
      "58/58 02:42<00:00 \n",
      "EPOCH 3 | DICE 0.45833622207949754\n",
      "[0.34445784 0.31383632 0.62815391 0.65319259 0.63047672 0.32111264\n",
      " 0.41585827 0.35960148]\n",
      "SAVING BEST!\n",
      "169/169 02:56<00:00 , loss=0.667, lr=0.000981, step=676\n",
      "58/58 02:34<00:00 \n",
      "EPOCH 4 | DICE 0.4843975659990907\n",
      "[0.47840867 0.2616726  0.61527506 0.67625922 0.62390227 0.15106785\n",
      " 0.41658471 0.65201014]\n",
      "SAVING BEST!\n",
      "169/169 02:56<00:00 , loss=0.59, lr=0.00097, step=845  \n",
      "58/58 02:36<00:00 \n",
      "EPOCH 5 | DICE 0.5782059686485016\n",
      "[0.5164422  0.43574483 0.70278708 0.75640418 0.71214561 0.43166945\n",
      " 0.43156578 0.6388886 ]\n",
      "SAVING BEST!\n",
      "169/169 03:01<00:00 , loss=0.538, lr=0.000957, step=1014\n",
      "17/58 00:43<01:39 ^C\n",
      "W0307 02:24:38.593256 1008764 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGINT death signal, shutting down workers\n",
      "W0307 02:24:38.594279 1008764 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1008814 closing signal SIGINT\n",
      "W0307 02:24:38.594533 1008764 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1008815 closing signal SIGINT\n",
      "17/58 00:44<01:47 \n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//resnet34_v1/run.py\", line 797, in <module>\n",
      "[rank0]:     run(model, get_loaders)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//resnet34_v1/run.py\", line 726, in run\n",
      "[rank0]:     score = valid_one_epoch(f\"{OUTPUT_FOLDER}/{CFG.FOLD}_EMA.pth\", valid_loader, debug=False, running_dist=CFG.DDP_INIT_DONE)\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//resnet34_v1/run.py\", line 647, in valid_one_epoch\n",
      "[rank0]:     outputs = np.concatenate([np.load(f\"{CFG.cache_dir}/preds_{_}.npy\") for _ in range(CFG.N_GPUS)])\n",
      "[rank0]:   File \"/home/harshit/codes/uni_rsna_spine/FINAL/segmentation/./data/segmentation_model//resnet34_v1/run.py\", line 647, in <listcomp>\n",
      "[rank0]:     outputs = np.concatenate([np.load(f\"{CFG.cache_dir}/preds_{_}.npy\") for _ in range(CFG.N_GPUS)])\n",
      "[rank0]:   File \"/home/harshit/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\", line 432, in load\n",
      "[rank0]:     return format.read_array(fid, allow_pickle=allow_pickle,\n",
      "[rank0]:   File \"/home/harshit/anaconda3/lib/python3.9/site-packages/numpy/lib/format.py\", line 801, in read_array\n",
      "[rank0]:     array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
      "[rank0]: KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(filedata)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#!python \"{DIR}/{NAME}_v{V}/run.py\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/run.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | tee \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/log_\u001b[39;49m\u001b[38;5;132;43;01m{F}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"resnet34\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eae0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313165b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 29898 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 02:32:52.230894 1014064 site-packages/torch/distributed/run.py:792] \n",
      "W0307 02:32:52.230894 1014064 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 02:32:52.230894 1014064 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 02:32:52.230894 1014064 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W307 02:32:59.283815254 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W307 02:32:59.311849831 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:01<00:00 , loss=0.728, lr=0.000999, step=351\n",
      "115/115 01:12<00:00 \n",
      "EPOCH 1 | DICE 0.841099860065713\n",
      "[0.93773949 0.9076721  0.69832363 0.84284648 0.85532    0.72828906\n",
      " 0.89952337 0.85908475]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.336, lr=0.000995, step=702\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 2 | DICE 0.9027298585138817\n",
      "[0.94081961 0.91718482 0.92042919 0.86929319 0.86095815 0.91421004\n",
      " 0.9223863  0.87655757]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.211, lr=0.000989, step=1053\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 3 | DICE 0.9183638564244384\n",
      "[0.94681971 0.92187935 0.92766179 0.91898059 0.90383583 0.92368607\n",
      " 0.92669491 0.8773526 ]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.154, lr=0.000981, step=1404\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 4 | DICE 0.92348867345588\n",
      "[0.94984385 0.92487863 0.92682178 0.92576668 0.92199856 0.92876363\n",
      " 0.92653766 0.8832986 ]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.167, lr=0.00097, step=1755 \n",
      "115/115 00:53<00:00 \n",
      "EPOCH 5 | DICE 0.9260016210484893\n",
      "[0.94743159 0.92821274 0.93817992 0.92726819 0.91716166 0.93212281\n",
      " 0.93037351 0.88726255]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.128, lr=0.000957, step=2106\n",
      "115/115 00:53<00:00 \n",
      "EPOCH 6 | DICE 0.9264382133778081\n",
      "[0.95054706 0.92992904 0.9301409  0.9300675  0.92433607 0.93198745\n",
      " 0.93666563 0.87783204]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.127, lr=0.000941, step=2457\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 7 | DICE 0.9271951820697402\n",
      "[0.94975577 0.92660622 0.93251874 0.93207229 0.92668648 0.92823779\n",
      " 0.93214104 0.88954312]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.128, lr=0.000924, step=2808\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 8 | DICE 0.9261346390629966\n",
      "[0.94950571 0.92383864 0.93685344 0.93133837 0.92535048 0.92853938\n",
      " 0.92967094 0.88398016]\n",
      "351/351 01:01<00:00 , loss=0.117, lr=0.000905, step=3159\n",
      "115/115 00:53<00:00 \n",
      "EPOCH 9 | DICE 0.9285789028103353\n",
      "[0.95033341 0.9306654  0.93042205 0.9394869  0.92680571 0.93281028\n",
      " 0.93574087 0.8823666 ]\n",
      "SAVING BEST!\n",
      "186/351 00:33<00:29 , loss=0.101, lr=0.000893, step=3345 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56a717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad49948a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 29963 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 02:55:54.098128 1018617 site-packages/torch/distributed/run.py:792] \n",
      "W0307 02:55:54.098128 1018617 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 02:55:54.098128 1018617 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 02:55:54.098128 1018617 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W307 02:56:01.043990591 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W307 02:56:01.485663529 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:01<00:00 , loss=0.728, lr=0.000989, step=351\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 1 | DICE 0.8711345103961697\n",
      "[0.93504024 0.89930341 0.89216046 0.85047521 0.88764858 0.80823495\n",
      " 0.90170434 0.79450888]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.309, lr=0.000957, step=702\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 2 | DICE 0.9140756738671985\n",
      "[0.94248544 0.9201215  0.92437157 0.90953644 0.90577476 0.9076248\n",
      " 0.92439485 0.87829602]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.201, lr=0.000905, step=1053\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 3 | DICE 0.9191538174504141\n",
      "[0.9464442  0.9164559  0.93158115 0.92466095 0.91126484 0.91784605\n",
      " 0.92817417 0.87680328]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.161, lr=0.000835, step=1404\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 4 | DICE 0.922770276511057\n",
      "[0.94631735 0.92474685 0.94024345 0.93517153 0.9333705  0.91403893\n",
      " 0.92164944 0.86662416]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.152, lr=0.00075, step=1755 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 5 | DICE 0.9272672859931849\n",
      "[0.94965518 0.92649323 0.93944595 0.93496574 0.92506367 0.92532246\n",
      " 0.9301928  0.88699926]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.123, lr=0.000655, step=2106\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 6 | DICE 0.9249379421824664\n",
      "[0.95075259 0.9274126  0.93698301 0.9216515  0.92352558 0.92797104\n",
      " 0.93151851 0.8796887 ]\n",
      "351/351 01:01<00:00 , loss=0.115, lr=0.000552, step=2457\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 7 | DICE 0.9269882770086179\n",
      "[0.94899756 0.92358905 0.93699509 0.93557823 0.9316821  0.92627615\n",
      " 0.93188571 0.88090233]\n",
      "351/351 01:01<00:00 , loss=0.11, lr=0.000448, step=2808 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 8 | DICE 0.9264134067584233\n",
      "[0.94520574 0.92228095 0.94102787 0.93401909 0.92869853 0.93413177\n",
      " 0.92929148 0.87665182]\n",
      "351/351 01:01<00:00 , loss=0.102, lr=0.000345, step=3159 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 9 | DICE 0.9263317305810531\n",
      "[0.94478325 0.92149278 0.94014077 0.93601267 0.93537951 0.92851126\n",
      " 0.92867761 0.87565598]\n",
      "351/351 01:01<00:00 , loss=0.0954, lr=0.00025, step=3510 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 10 | DICE 0.9278554909935919\n",
      "[0.9452421  0.92399704 0.9414996  0.93865618 0.93677297 0.9329779\n",
      " 0.92893626 0.87476188]\n",
      "SAVING BEST!\n",
      "[rank0]:[W307 03:15:10.492289496 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5141e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd88266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 29991 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 03:49:29.134739 1028625 site-packages/torch/distributed/run.py:792] \n",
      "W0307 03:49:29.134739 1028625 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 03:49:29.134739 1028625 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 03:49:29.134739 1028625 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W307 03:49:35.294675713 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W307 03:49:35.882072812 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:00<00:00 , loss=0.932, lr=0.0003, step=351\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 1 | DICE 0.7796454277016709\n",
      "[0.92852685 0.83421992 0.66455288 0.76051741 0.7882562  0.77932996\n",
      " 0.7029231  0.7788371 ]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.418, lr=0.000299, step=702\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 2 | DICE 0.8624139510742874\n",
      "[0.94263451 0.86031374 0.77309064 0.88859587 0.8952952  0.87615706\n",
      " 0.90356735 0.75965724]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.24, lr=0.000297, step=1053 \n",
      "115/115 00:51<00:00 \n",
      "EPOCH 3 | DICE 0.9006913435564544\n",
      "[0.94530795 0.91025661 0.84258138 0.9088664  0.90685948 0.91056866\n",
      " 0.91237138 0.86871889]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.164, lr=0.000294, step=1404\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 4 | DICE 0.9146521713670883\n",
      "[0.94402562 0.91317981 0.9141956  0.91928486 0.91473159 0.92159729\n",
      " 0.91836147 0.87184114]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.152, lr=0.000291, step=1755\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 5 | DICE 0.9204117678933316\n",
      "[0.947375   0.92255611 0.93134733 0.92020171 0.91101314 0.91965098\n",
      " 0.92094384 0.89020603]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.132, lr=0.000287, step=2106\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 6 | DICE 0.9218071256029502\n",
      "[0.94712426 0.92457949 0.93590084 0.92613128 0.91538994 0.91988516\n",
      " 0.92395626 0.88148979]\n",
      "SAVING BEST!\n",
      "351/351 00:59<00:00 , loss=0.122, lr=0.000282, step=2457\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 7 | DICE 0.920002907436688\n",
      "[0.94731069 0.92450623 0.93370142 0.92335234 0.91622528 0.92056716\n",
      " 0.92423872 0.87012141]\n",
      "351/351 01:00<00:00 , loss=0.124, lr=0.000277, step=2808\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 8 | DICE 0.9218068153798411\n",
      "[0.94697036 0.92217583 0.93660933 0.92671602 0.91669678 0.92717107\n",
      " 0.92613226 0.87198288]\n",
      "351/351 01:00<00:00 , loss=0.114, lr=0.000271, step=3159\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 9 | DICE 0.9237525142639116\n",
      "[0.94680475 0.92896918 0.93120133 0.92574716 0.92396284 0.92876024\n",
      " 0.92501098 0.87956363]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.105, lr=0.000265, step=3510 \n",
      "115/115 00:51<00:00 \n",
      "EPOCH 10 | DICE 0.9217675367263026\n",
      "[0.94372492 0.92329489 0.94139191 0.92898628 0.92223793 0.92580247\n",
      " 0.918838   0.86986389]\n",
      "351/351 01:00<00:00 , loss=0.115, lr=0.000258, step=3861\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 11 | DICE 0.9218418880017368\n",
      "[0.94266274 0.91977501 0.93982389 0.93049793 0.91660394 0.92035543\n",
      " 0.92377035 0.88124582]\n",
      "351/351 01:00<00:00 , loss=0.112, lr=0.00025, step=4212 \n",
      "115/115 00:50<00:00 \n",
      "EPOCH 12 | DICE 0.9240052655463554\n",
      "[0.94460736 0.92177346 0.93731103 0.93676232 0.92354348 0.93079834\n",
      " 0.92136907 0.87587707]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.107, lr=0.000242, step=4563\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 13 | DICE 0.9243454405843597\n",
      "[0.94374915 0.91947503 0.93835044 0.93865259 0.92409706 0.92997221\n",
      " 0.92769675 0.8727703 ]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.103, lr=0.000234, step=4914 \n",
      "115/115 00:51<00:00 \n",
      "EPOCH 14 | DICE 0.9228711359959997\n",
      "[0.94300877 0.92115469 0.94266043 0.92947499 0.91849796 0.93453484\n",
      " 0.92336287 0.87027454]\n",
      "351/351 01:00<00:00 , loss=0.103, lr=0.000225, step=5265\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 15 | DICE 0.9240583371577642\n",
      "[0.94460652 0.92245894 0.93943312 0.93526017 0.92604133 0.92471653\n",
      " 0.92298351 0.87696656]\n",
      "351/351 01:00<00:00 , loss=0.0998, lr=0.000216, step=5616\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 16 | DICE 0.9279191883748814\n",
      "[0.94577298 0.92791639 0.94614593 0.93693892 0.92930234 0.93324199\n",
      " 0.92682513 0.87720984]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.0908, lr=0.000206, step=5967\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 17 | DICE 0.9286470547439084\n",
      "[0.94830747 0.92477615 0.94505367 0.93434282 0.93144903 0.93577979\n",
      " 0.93073655 0.87873095]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.091, lr=0.000196, step=6318 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 18 | DICE 0.926867169973531\n",
      "[0.94712122 0.92647486 0.94231956 0.93304944 0.92972216 0.93226309\n",
      " 0.92809115 0.87589587]\n",
      "351/351 01:00<00:00 , loss=0.0897, lr=0.000186, step=6669\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 19 | DICE 0.927156833254923\n",
      "[0.94619728 0.92761196 0.94633809 0.93689897 0.929239   0.92514012\n",
      " 0.92736766 0.87846158]\n",
      "351/351 01:00<00:00 , loss=0.0886, lr=0.000176, step=7020\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 20 | DICE 0.9272319935390607\n",
      "[0.9437742  0.92490372 0.94439185 0.93557608 0.92843723 0.92259055\n",
      " 0.93157572 0.88660659]\n",
      "351/351 01:00<00:00 , loss=0.0889, lr=0.000166, step=7371\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 21 | DICE 0.9288361152723523\n",
      "[0.94559157 0.93007323 0.94417426 0.9386008  0.9302639  0.92616938\n",
      " 0.93301461 0.88280116]\n",
      "SAVING BEST!\n",
      "351/351 01:00<00:00 , loss=0.0844, lr=0.000155, step=7722\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 22 | DICE 0.9243721955852207\n",
      "[0.94462543 0.92942005 0.9389587  0.93495875 0.92955879 0.9199288\n",
      " 0.92735425 0.87017279]\n",
      "351/351 01:00<00:00 , loss=0.0857, lr=0.000145, step=8073\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 23 | DICE 0.9264733948130572\n",
      "[0.94694219 0.92829039 0.9417571  0.93592368 0.92997334 0.92368591\n",
      " 0.92987694 0.87533761]\n",
      "351/351 01:00<00:00 , loss=0.0869, lr=0.000134, step=8424\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 24 | DICE 0.9260108650217127\n",
      "[0.94834143 0.93101525 0.94152122 0.93088671 0.92558943 0.92434614\n",
      " 0.92812522 0.87826152]\n",
      "351/351 01:00<00:00 , loss=0.0799, lr=0.000124, step=8775\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 25 | DICE 0.9233942669337664\n",
      "[0.94617123 0.92680989 0.94128295 0.93143761 0.92435027 0.92376053\n",
      " 0.92183805 0.87150359]\n",
      "351/351 01:00<00:00 , loss=0.0827, lr=0.000114, step=9126\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 26 | DICE 0.9260778030822044\n",
      "[0.94719447 0.92658438 0.94117804 0.9318102  0.92864972 0.9256071\n",
      " 0.92820375 0.87939476]\n",
      "351/351 01:00<00:00 , loss=0.0795, lr=0.000104, step=9477\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 27 | DICE 0.9272399274772234\n",
      "[0.94695629 0.92721814 0.94276341 0.93244302 0.9281474  0.92889066\n",
      " 0.9300688  0.8814317 ]\n",
      "351/351 00:59<00:00 , loss=0.0814, lr=9.38e-5, step=9828 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 28 | DICE 0.9278000943806874\n",
      "[0.94775329 0.9274215  0.94412441 0.93494718 0.92792098 0.92963561\n",
      " 0.92948929 0.8811085 ]\n",
      "351/351 01:00<00:00 , loss=0.0785, lr=8.42e-5, step=10179\n",
      "115/115 00:52<00:00 \n",
      "EPOCH 29 | DICE 0.9269058115704383\n",
      "[0.94645322 0.92681946 0.9460406  0.93216325 0.92658363 0.93182203\n",
      " 0.93117309 0.87419123]\n",
      "351/351 01:00<00:00 , loss=0.0764, lr=7.5e-5, step=10530 \n",
      "115/115 00:52<00:00 \n",
      "EPOCH 30 | DICE 0.926369736770193\n",
      "[0.94774719 0.92785075 0.94496031 0.93217836 0.925534   0.93018086\n",
      " 0.93132688 0.87117954]\n",
      "[rank0]:[W307 04:46:15.975378082 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 04:46:18.219268 1039233 site-packages/torch/distributed/run.py:792] \n",
      "W0307 04:46:18.219268 1039233 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 04:46:18.219268 1039233 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 04:46:18.219268 1039233 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W307 04:46:24.676742849 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W307 04:46:24.751974673 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "349/349 01:01<00:00 , loss=0.94, lr=0.0003, step=349 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 1 | DICE 0.7604939338645332\n",
      "[0.78027203 0.8328562  0.56340682 0.7227277  0.85723284 0.79594738\n",
      " 0.72590149 0.80560702]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.437, lr=0.000299, step=698\n",
      "118/118 00:51<00:00 \n",
      "EPOCH 2 | DICE 0.8713559678608007\n",
      "[0.81764734 0.87836606 0.91596037 0.91382918 0.85007486 0.85564021\n",
      " 0.92366431 0.81566541]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.268, lr=0.000297, step=1047\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 3 | DICE 0.9098524069089053\n",
      "[0.95230452 0.92313147 0.92514076 0.92679751 0.8416445  0.90858621\n",
      " 0.93295347 0.86826081]\n",
      "SAVING BEST!\n",
      "349/349 01:01<00:00 , loss=0.194, lr=0.000294, step=1396\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 4 | DICE 0.924197959420223\n",
      "[0.95191823 0.93425886 0.93617669 0.9315197  0.8793229  0.9256866\n",
      " 0.93637341 0.89832728]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.14, lr=0.000291, step=1745 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 5 | DICE 0.9302895196100872\n",
      "[0.95554878 0.93698158 0.93888792 0.93401608 0.91041879 0.93504563\n",
      " 0.93741495 0.89400242]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.137, lr=0.000287, step=2094\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 6 | DICE 0.9365571433837508\n",
      "[0.95897231 0.93430635 0.94341184 0.93614797 0.92729361 0.93686146\n",
      " 0.94073549 0.91472812]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.129, lr=0.000282, step=2443\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 7 | DICE 0.9360890180779039\n",
      "[0.95245641 0.94055569 0.9431947  0.93875394 0.924487   0.93911645\n",
      " 0.94235046 0.90779749]\n",
      "349/349 01:01<00:00 , loss=0.119, lr=0.000277, step=2792\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 8 | DICE 0.9388038300169018\n",
      "[0.95645453 0.94222725 0.94170793 0.93700736 0.93066672 0.94164058\n",
      " 0.94825582 0.91247046]\n",
      "SAVING BEST!\n",
      "349/349 01:01<00:00 , loss=0.125, lr=0.000271, step=3141\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 9 | DICE 0.9384721992846282\n",
      "[0.96006025 0.9427543  0.94512403 0.94077284 0.93067355 0.93315272\n",
      " 0.94247365 0.91276625]\n",
      "349/349 01:01<00:00 , loss=0.106, lr=0.000265, step=3490\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 10 | DICE 0.9395771271432263\n",
      "[0.95787191 0.9445105  0.94811186 0.93754727 0.93274396 0.93820878\n",
      " 0.94647982 0.91114292]\n",
      "SAVING BEST!\n",
      "349/349 01:01<00:00 , loss=0.106, lr=0.000258, step=3839\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 11 | DICE 0.9399914155496372\n",
      "[0.9585398  0.94583676 0.94788096 0.93693158 0.92878631 0.94139022\n",
      " 0.94949759 0.91106812]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.1, lr=0.00025, step=4188    \n",
      "118/118 00:53<00:00 \n",
      "EPOCH 12 | DICE 0.9405927455833573\n",
      "[0.96097916 0.94618131 0.94797153 0.93734966 0.9282748  0.94201004\n",
      " 0.94783482 0.91414064]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.101, lr=0.000242, step=4537 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 13 | DICE 0.9348297300177826\n",
      "[0.95351028 0.94126997 0.94774258 0.93087127 0.92556184 0.9395765\n",
      " 0.94491803 0.89518737]\n",
      "349/349 01:01<00:00 , loss=0.102, lr=0.000234, step=4886 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 14 | DICE 0.9404345255389084\n",
      "[0.95875661 0.94307437 0.94844468 0.94218789 0.92915628 0.94041654\n",
      " 0.94843307 0.91300675]\n",
      "349/349 01:00<00:00 , loss=0.0913, lr=0.000225, step=5235\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 15 | DICE 0.9398343861601479\n",
      "[0.95841965 0.94446969 0.94867102 0.94305495 0.93077009 0.93856843\n",
      " 0.94887081 0.90585045]\n",
      "349/349 01:00<00:00 , loss=0.0945, lr=0.000216, step=5584\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 16 | DICE 0.9415475963685089\n",
      "[0.9586111  0.94086561 0.94848509 0.94426374 0.93132532 0.94106409\n",
      " 0.95029457 0.91747125]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0954, lr=0.000206, step=5933\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 17 | DICE 0.9395721941663207\n",
      "[0.95986981 0.94647069 0.94894989 0.93752658 0.92658183 0.93902272\n",
      " 0.94892006 0.90923597]\n",
      "349/349 01:01<00:00 , loss=0.0898, lr=0.000196, step=6282\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 18 | DICE 0.941674063875082\n",
      "[0.96193209 0.9482474  0.94821256 0.93991684 0.93080748 0.94152569\n",
      " 0.94693132 0.91581912]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0876, lr=0.000186, step=6631\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 19 | DICE 0.9423233935200206\n",
      "[0.96123575 0.94622535 0.94965134 0.94503039 0.92999983 0.93937525\n",
      " 0.95019563 0.91687362]\n",
      "SAVING BEST!\n",
      "349/349 01:01<00:00 , loss=0.0866, lr=0.000176, step=6980\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 20 | DICE 0.9418019895446718\n",
      "[0.96209579 0.94792202 0.94952217 0.94196078 0.92650217 0.93900349\n",
      " 0.95155595 0.91585355]\n",
      "349/349 01:00<00:00 , loss=0.0834, lr=0.000166, step=7329\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 21 | DICE 0.9402816871233357\n",
      "[0.95794775 0.94723988 0.9468596  0.94297843 0.92712965 0.93803287\n",
      " 0.94888012 0.9131852 ]\n",
      "349/349 01:01<00:00 , loss=0.0872, lr=0.000155, step=7678\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 22 | DICE 0.9406710028593587\n",
      "[0.96085746 0.94586495 0.94811133 0.9433059  0.92864567 0.93820144\n",
      " 0.94784109 0.91254018]\n",
      "349/349 01:01<00:00 , loss=0.0813, lr=0.000145, step=8027\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 23 | DICE 0.9410117917486632\n",
      "[0.95763574 0.94572072 0.94704052 0.94270251 0.93092093 0.94145297\n",
      " 0.94751504 0.91510591]\n",
      "349/349 01:00<00:00 , loss=0.0827, lr=0.000134, step=8376\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 24 | DICE 0.9421682534994635\n",
      "[0.9597964  0.9471196  0.94884341 0.94125968 0.93143356 0.94263594\n",
      " 0.95035196 0.91590547]\n",
      "349/349 01:00<00:00 , loss=0.0769, lr=0.000124, step=8725\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 25 | DICE 0.9407387966201647\n",
      "[0.95938613 0.94686455 0.94886243 0.93925931 0.92951131 0.94166329\n",
      " 0.94917793 0.91118542]\n",
      "349/349 01:00<00:00 , loss=0.0755, lr=0.000114, step=9074\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 26 | DICE 0.9417089698030651\n",
      "[0.95898951 0.94747746 0.94931785 0.94105616 0.93462578 0.94441739\n",
      " 0.95058609 0.90720151]\n",
      "349/349 01:00<00:00 , loss=0.075, lr=0.000104, step=9423 \n",
      "118/118 00:53<00:00 \n",
      "EPOCH 27 | DICE 0.940518882359059\n",
      "[0.95973178 0.94649262 0.94954224 0.94053606 0.93159102 0.94093704\n",
      " 0.94798865 0.90733163]\n",
      "349/349 01:01<00:00 , loss=0.0752, lr=9.38e-5, step=9772 \n",
      "118/118 00:53<00:00 \n",
      "EPOCH 28 | DICE 0.9425492742314894\n",
      "[0.96086906 0.94621981 0.94919786 0.94132113 0.93375395 0.94331233\n",
      " 0.95040224 0.9153178 ]\n",
      "SAVING BEST!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 01:01<00:00 , loss=0.0735, lr=8.42e-5, step=10121\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 29 | DICE 0.9420720819862882\n",
      "[0.96111578 0.9459937  0.94868291 0.94261841 0.93334419 0.94282204\n",
      " 0.95037673 0.91162289]\n",
      "349/349 01:00<00:00 , loss=0.0715, lr=7.5e-5, step=10470 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 30 | DICE 0.9417798679690679\n",
      "[0.95944145 0.94663687 0.94892692 0.9429725  0.9314481  0.94088019\n",
      " 0.95018786 0.91374505]\n",
      "[rank0]:[W307 05:43:43.717864003 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0307 05:43:46.992730 1051450 site-packages/torch/distributed/run.py:792] \n",
      "W0307 05:43:46.992730 1051450 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0307 05:43:46.992730 1051450 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0307 05:43:46.992730 1051450 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W307 05:43:53.364297083 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W307 05:43:53.749749025 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "349/349 01:00<00:00 , loss=0.944, lr=0.0003, step=349\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 1 | DICE 0.7594686824619158\n",
      "[0.79146358 0.82102214 0.5718363  0.76935316 0.81879082 0.79640444\n",
      " 0.7073375  0.79954151]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.43, lr=0.000299, step=698 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 2 | DICE 0.8852423821101547\n",
      "[0.96045727 0.93633433 0.78073371 0.87137041 0.86632911 0.90732766\n",
      " 0.93744948 0.82193709]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.265, lr=0.000297, step=1047\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 3 | DICE 0.9283741618870535\n",
      "[0.96581143 0.94644271 0.9388117  0.91582291 0.91891718 0.93252235\n",
      " 0.95141429 0.85725071]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.196, lr=0.000294, step=1396\n",
      "118/118 00:51<00:00 \n",
      "EPOCH 4 | DICE 0.9368150743764053\n",
      "[0.96680415 0.95271639 0.94772755 0.9297159  0.92681631 0.94788709\n",
      " 0.95932605 0.86352716]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.157, lr=0.000291, step=1745\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 5 | DICE 0.9502954379303394\n",
      "[0.97061731 0.96091155 0.95511748 0.93781097 0.92635973 0.94628906\n",
      " 0.96144245 0.94381496]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.138, lr=0.000287, step=2094\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 6 | DICE 0.9510395979866504\n",
      "[0.97245708 0.96214359 0.95700859 0.93156459 0.93082805 0.94978234\n",
      " 0.95975145 0.94478109]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.136, lr=0.000282, step=2443\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 7 | DICE 0.952783221719969\n",
      "[0.97175486 0.96465689 0.95898312 0.93823548 0.93399759 0.95147998\n",
      " 0.96099902 0.94215883]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.137, lr=0.000277, step=2792\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 8 | DICE 0.9537431799489845\n",
      "[0.97217099 0.96499928 0.96209464 0.94186942 0.93391097 0.95047399\n",
      " 0.96473701 0.93968913]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.122, lr=0.000271, step=3141\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 9 | DICE 0.9542460693872167\n",
      "[0.97371393 0.96749444 0.95820576 0.93836719 0.93377671 0.95114913\n",
      " 0.9641942  0.94706719]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.12, lr=0.000265, step=3490 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 10 | DICE 0.9546968700794448\n",
      "[0.97383761 0.96692311 0.96367683 0.94121508 0.93207141 0.95113158\n",
      " 0.9656523  0.94306704]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.12, lr=0.000258, step=3839 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 11 | DICE 0.9572305794259005\n",
      "[0.9750535  0.96647297 0.96387754 0.94531854 0.93879728 0.95270259\n",
      " 0.96628637 0.94933583]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.12, lr=0.00025, step=4188  \n",
      "118/118 00:53<00:00 \n",
      "EPOCH 12 | DICE 0.9573153700733326\n",
      "[0.97577631 0.96879075 0.96532105 0.94389337 0.94003612 0.95263859\n",
      " 0.96455674 0.94751004]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.109, lr=0.000242, step=4537\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 13 | DICE 0.9568653161627192\n",
      "[0.97546463 0.96696541 0.96423443 0.9378069  0.94117602 0.95314178\n",
      " 0.96618705 0.9499463 ]\n",
      "349/349 00:59<00:00 , loss=0.109, lr=0.000234, step=4886\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 14 | DICE 0.9570911765906398\n",
      "[0.97520918 0.96904343 0.96534904 0.94224271 0.9378517  0.95278418\n",
      " 0.96668335 0.94756583]\n",
      "349/349 01:00<00:00 , loss=0.106, lr=0.000225, step=5235 \n",
      "118/118 00:52<00:00 \n",
      "EPOCH 15 | DICE 0.9573938384425724\n",
      "[0.97552854 0.96827343 0.9638321  0.94461587 0.94020593 0.95285367\n",
      " 0.96664269 0.94719848]\n",
      "SAVING BEST!\n",
      "349/349 00:59<00:00 , loss=0.107, lr=0.000216, step=5584\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 16 | DICE 0.9562805688300778\n",
      "[0.97469723 0.96896627 0.9631004  0.94542391 0.93652047 0.95438154\n",
      " 0.96587267 0.94128205]\n",
      "349/349 01:00<00:00 , loss=0.113, lr=0.000206, step=5933\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 17 | DICE 0.9563976882204459\n",
      "[0.97292782 0.96944759 0.96359613 0.94030014 0.9386965  0.9568166\n",
      " 0.96517233 0.9442244 ]\n",
      "349/349 01:00<00:00 , loss=0.101, lr=0.000196, step=6282\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 18 | DICE 0.9568230664714856\n",
      "[0.97469583 0.96833223 0.96268347 0.94104836 0.94367117 0.9568852\n",
      " 0.96608795 0.94118032]\n",
      "349/349 01:00<00:00 , loss=0.0947, lr=0.000186, step=6631\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 19 | DICE 0.9576015824965559\n",
      "[0.9746792  0.96711434 0.96348258 0.94463757 0.9461994  0.95640997\n",
      " 0.96809612 0.94019348]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0936, lr=0.000176, step=6980\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 20 | DICE 0.9577240019647778\n",
      "[0.97505567 0.96692594 0.96315618 0.94332455 0.94638257 0.95745854\n",
      " 0.96814815 0.9413404 ]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0915, lr=0.000166, step=7329\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 21 | DICE 0.9565966121864323\n",
      "[0.97496951 0.96687584 0.96006273 0.94206394 0.94078887 0.95536636\n",
      " 0.96754938 0.94509626]\n",
      "349/349 00:59<00:00 , loss=0.0912, lr=0.000155, step=7678\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 22 | DICE 0.9576181237378042\n",
      "[0.97497514 0.96707269 0.96434674 0.94488135 0.94265324 0.95596949\n",
      " 0.96722192 0.94382442]\n",
      "349/349 01:00<00:00 , loss=0.0863, lr=0.000145, step=8027\n",
      "118/118 00:53<00:00 \n",
      "EPOCH 23 | DICE 0.9585138492393095\n",
      "[0.97603664 0.96699823 0.96416244 0.94527225 0.94365517 0.95654047\n",
      " 0.96770904 0.94773655]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0872, lr=0.000134, step=8376\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 24 | DICE 0.9587212897816095\n",
      "[0.97569437 0.968215   0.9653923  0.94884166 0.94515811 0.95421667\n",
      " 0.96729557 0.94495663]\n",
      "SAVING BEST!\n",
      "349/349 01:00<00:00 , loss=0.0872, lr=0.000124, step=8725\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 25 | DICE 0.9585645821063807\n",
      "[0.97554504 0.96722043 0.9634757  0.94580963 0.94527119 0.95763575\n",
      " 0.96729821 0.9462607 ]\n",
      "349/349 01:00<00:00 , loss=0.0828, lr=0.000114, step=9074\n",
      "118/118 00:52<00:00 \n",
      "EPOCH 26 | DICE 0.9576076025189973\n",
      "[0.97609068 0.96684889 0.96359835 0.94382606 0.9413887  0.95638644\n",
      " 0.96731991 0.94540178]\n",
      "349/349 01:00<00:00 , loss=0.081, lr=0.000104, step=9423 \n",
      "99/118 00:44<00:08 "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"1\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf429c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378de218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 29557 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0311 23:25:43.952445 1925141 site-packages/torch/distributed/run.py:792] \n",
      "W0311 23:25:43.952445 1925141 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0311 23:25:43.952445 1925141 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0311 23:25:43.952445 1925141 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W311 23:25:52.179461454 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W311 23:25:53.217699547 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:02<00:00 , loss=0.907, lr=0.0003, step=351\n",
      "115/115 02:44<00:00 \n",
      "EPOCH 1 | DICE 0.5825042311771824\n",
      "[0.86953846 0.67679302 0.49926054 0.39399179 0.47787353 0.44796686\n",
      " 0.44642648 0.73832454]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.392, lr=0.000299, step=702\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.187, lr=0.000297, step=1053\n",
      "115/115 02:49<00:00 \n",
      "EPOCH 3 | DICE 0.860361408794507\n",
      "[0.91454732 0.92082977 0.86117754 0.78539294 0.71719141 0.76612676\n",
      " 0.8736678  0.89557561]\n",
      "SAVING BEST!\n",
      "351/351 01:02<00:00 , loss=0.127, lr=0.000294, step=1404\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.111, lr=0.000291, step=1755\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.1, lr=0.000287, step=2106  \n",
      "115/115 02:42<00:00 \n",
      "EPOCH 6 | DICE 0.87685456047693\n",
      "[0.92120489 0.92763348 0.88253227 0.8176987  0.75446547 0.80000517\n",
      " 0.88537169 0.90465092]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0916, lr=0.000282, step=2457\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0949, lr=0.000277, step=2808\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0848, lr=0.000271, step=3159\n",
      "115/115 02:44<00:00 \n",
      "EPOCH 9 | DICE 0.8814458067723301\n",
      "[0.92563143 0.93699377 0.89788007 0.80821175 0.73972266 0.80676122\n",
      " 0.9008111  0.90751582]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0831, lr=0.000265, step=3510\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0796, lr=0.000258, step=3861\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0806, lr=0.00025, step=4212 \n",
      "115/115 02:49<00:00 \n",
      "EPOCH 12 | DICE 0.8832371974748184\n",
      "[0.9264279  0.93654542 0.89616681 0.81604822 0.75190646 0.80942594\n",
      " 0.89651812 0.91086142]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0762, lr=0.000242, step=4563\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.077, lr=0.000234, step=4914 \n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0718, lr=0.000225, step=5265\n",
      "115/115 02:49<00:00 \n",
      "EPOCH 15 | DICE 0.8870356932939136\n",
      "[0.92841479 0.93341132 0.89231678 0.81475433 0.76318754 0.83059865\n",
      " 0.9015212  0.91314538]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0698, lr=0.000216, step=5616\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.066, lr=0.000206, step=5967 \n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0651, lr=0.000196, step=6318\n",
      "115/115 02:59<00:00 \n",
      "EPOCH 18 | DICE 0.88782957291984\n",
      "[0.92930941 0.93610252 0.89449452 0.81605301 0.74446396 0.82644097\n",
      " 0.90855562 0.91572043]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.064, lr=0.000186, step=6669 \n",
      "SAVING BEST!\n",
      "351/351 01:02<00:00 , loss=0.0644, lr=0.000176, step=7020\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0632, lr=0.000166, step=7371\n",
      "115/115 02:52<00:00 \n",
      "EPOCH 21 | DICE 0.8888363972889959\n",
      "[0.92869099 0.92792631 0.89117883 0.81368373 0.77560297 0.82832843\n",
      " 0.89977213 0.91757373]\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0612, lr=0.000155, step=7722\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0599, lr=0.000145, step=8073\n",
      "SAVING BEST!\n",
      "351/351 01:01<00:00 , loss=0.0629, lr=0.000134, step=8424\n",
      "115/115 02:42<00:00 \n",
      "EPOCH 24 | DICE 0.8876804660116502\n",
      "[0.9291622  0.93492837 0.89908834 0.81007867 0.75279839 0.82711362\n",
      " 0.9055981  0.91497853]\n",
      "351/351 01:01<00:00 , loss=0.0588, lr=0.000124, step=8775\n",
      "12/351 00:03<00:59 , loss=0.0527, lr=0.000124, step=8787"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:153\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# res is the index of the pattern that caused the match, so we\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# know whether we've finished (if we matched EOF) or not\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     res_idx \u001b[38;5;241m=\u001b[39m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mprint\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore[out_size:]\u001b[38;5;241m.\u001b[39mdecode(enc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/spawnbase.py:372\u001b[0m, in \u001b[0;36mSpawnBase.expect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpect_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/expect.py:169\u001b[0m, in \u001b[0;36mExpecter.expect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Still have time left, so read more data\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m incoming \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_nonblocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspawn\u001b[38;5;241m.\u001b[39mdelayafterread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:500\u001b[0m, in \u001b[0;36mspawn.read_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Because of the select(0) check above, we know that no data\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# is available right now. But if a non-zero timeout is given\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# (possibly timeout=None), we call select() with a timeout.\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(spawn, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mread_nonblocking(size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:450\u001b[0m, in \u001b[0;36mspawn.read_nonblocking.<locals>.select\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(timeout):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect_ignore_interrupts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchild_fd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/utils.py:143\u001b[0m, in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43miwtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mewtd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(filedata)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#!python \"{DIR}/{NAME}_v{V}/run.py\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/run.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | tee \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{DIR}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{NAME}\u001b[39;49;00m\u001b[38;5;124;43m_v\u001b[39;49m\u001b[38;5;132;43;01m{V}\u001b[39;49;00m\u001b[38;5;124;43m/log_\u001b[39;49m\u001b[38;5;132;43;01m{F}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:657\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/IPython/utils/_process_posix.py:177\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Ensure the subprocess really is terminated\u001b[39;00m\n\u001b[0;32m--> 177\u001b[0m         \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# add isalive check, to ensure exitstatus is set:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m child\u001b[38;5;241m.\u001b[39misalive()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pexpect/pty_spawn.py:646\u001b[0m, in \u001b[0;36mspawn.terminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkill(signal\u001b[38;5;241m.\u001b[39mSIGCONT)\n\u001b[0;32m--> 646\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelayafterterminate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misalive():\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"2\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b868b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13038b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 30369 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 00:27:38.308177 1938266 site-packages/torch/distributed/run.py:792] \n",
      "W0312 00:27:38.308177 1938266 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 00:27:38.308177 1938266 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 00:27:38.308177 1938266 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W312 00:27:45.998211407 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W312 00:27:45.998798270 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:05<00:00 , loss=0.694, lr=0.000992, step=351\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 1 | DICE 0.6590348982313435\n",
      "[0.88418022 0.90345663 0.80408569 0.72027837 0.54859702 0.4155736\n",
      " 0.42252545 0.77501973]\n",
      "SAVING BEST!\n",
      "351/351 01:03<00:00 , loss=0.284, lr=0.00097, step=702 \n",
      "115/115 00:31<00:00 \n",
      "EPOCH 2 | DICE 0.8265002035223161\n",
      "[0.909642   0.92336482 0.85857735 0.80351466 0.74183069 0.73631451\n",
      " 0.8441676  0.80883833]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.162, lr=0.000933, step=1053\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.117, lr=0.000883, step=1404\n",
      "115/115 00:31<00:00 \n",
      "EPOCH 4 | DICE 0.8972659755256068\n",
      "[0.92494816 0.93284658 0.90279856 0.870105   0.82214706 0.84609506\n",
      " 0.89964125 0.91096844]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.105, lr=0.000821, step=1755 \n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0978, lr=0.00075, step=2106 \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 6 | DICE 0.9055809466122099\n",
      "[0.93030447 0.93773198 0.91211099 0.8875813  0.84683685 0.86346824\n",
      " 0.90655526 0.91432728]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0848, lr=0.000671, step=2457\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0786, lr=0.000587, step=2808\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 8 | DICE 0.905638169708269\n",
      "[0.92900108 0.94065752 0.91011266 0.88981424 0.8577768  0.86182523\n",
      " 0.91251355 0.91042034]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0755, lr=0.0005, step=3159  \n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0741, lr=0.000413, step=3510\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 10 | DICE 0.9089718737405403\n",
      "[0.93233218 0.94121308 0.91239816 0.89822072 0.86406255 0.86177551\n",
      " 0.91032108 0.91541999]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0685, lr=0.000329, step=3861\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.0641, lr=0.00025, step=4212 \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 12 | DICE 0.909381993981556\n",
      "[0.93239546 0.94363593 0.9234733  0.90079483 0.86827122 0.86781983\n",
      " 0.90307495 0.91295968]\n",
      "SAVING BEST!\n",
      "[rank0]:[W312 00:44:38.846521233 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"3\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dbbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ea3c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 30450 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 00:46:33.709502 1941913 site-packages/torch/distributed/run.py:792] \n",
      "W0312 00:46:33.709502 1941913 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 00:46:33.709502 1941913 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 00:46:33.709502 1941913 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank1]:[W312 00:46:40.324765487 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank0]:[W312 00:46:40.558485695 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:05<00:00 , loss=0.721, lr=0.000992, step=351\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 1 | DICE 0.6980551553880819\n",
      "[0.88600355 0.89719224 0.767209   0.72981988 0.65211992 0.43198207\n",
      " 0.40789305 0.88736385]\n",
      "SAVING BEST!\n",
      "351/351 01:04<00:00 , loss=0.263, lr=0.00097, step=702 \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 2 | DICE 0.8660015549261564\n",
      "[0.91545023 0.91646819 0.85289128 0.81117978 0.73207518 0.77543336\n",
      " 0.87229472 0.89871738]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.168, lr=0.000933, step=1053\n",
      "351/351 01:05<00:00 , loss=0.129, lr=0.000883, step=1404\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 4 | DICE 0.9006649389228525\n",
      "[0.9219348  0.93335618 0.89865997 0.86552696 0.85696146 0.8626549\n",
      " 0.90514566 0.91048599]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.124, lr=0.000821, step=1755\n",
      "351/351 01:05<00:00 , loss=0.106, lr=0.00075, step=2106  \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 6 | DICE 0.9025484225669512\n",
      "[0.92541102 0.93782145 0.90179848 0.87456943 0.85719756 0.84620955\n",
      " 0.91076507 0.91163   ]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.106, lr=0.000671, step=2457\n",
      "351/351 01:05<00:00 , loss=0.101, lr=0.000587, step=2808\n",
      "115/115 00:32<00:00 \n",
      "EPOCH 8 | DICE 0.9046839639505371\n",
      "[0.92593328 0.93996154 0.90440606 0.86113457 0.8633108  0.87284725\n",
      " 0.90017198 0.91567012]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.0924, lr=0.0005, step=3159  \n",
      "351/351 01:05<00:00 , loss=0.083, lr=0.000413, step=3510 \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 10 | DICE 0.9135301333531493\n",
      "[0.92859232 0.93937347 0.91729411 0.88887066 0.8827341  0.89495066\n",
      " 0.91476182 0.91681615]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.0795, lr=0.000329, step=3861\n",
      "351/351 01:06<00:00 , loss=0.0765, lr=0.00025, step=4212 \n",
      "115/115 00:32<00:00 \n",
      "EPOCH 12 | DICE 0.9162703063508727\n",
      "[0.93090791 0.94164701 0.92758192 0.90124562 0.88972308 0.89938183\n",
      " 0.9164341  0.91536075]\n",
      "SAVING BEST!\n",
      "[rank0]:[W312 01:03:47.769251587 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"4\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d2ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcfe3c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 30419 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 01:07:05.239958 1945903 site-packages/torch/distributed/run.py:792] \n",
      "W0312 01:07:05.239958 1945903 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 01:07:05.239958 1945903 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 01:07:05.239958 1945903 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "torch.Size([2, 8])\n",
      "torch.Size([2, 8, 256, 256])\n",
      "[rank0]:[W312 01:07:12.264347877 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W312 01:07:12.339536269 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "351/351 01:17<00:00 , loss=0.711, lr=0.000997, step=351\n",
      "115/115 00:49<00:00 \n",
      "EPOCH 1 | DICE 0.6941130132252555\n",
      "[0.87406842 0.90375564 0.82416215 0.7544026  0.57828706 0.4622842\n",
      " 0.49176105 0.80100221]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.248, lr=0.000989, step=702\n",
      "115/115 00:51<00:00 \n",
      "EPOCH 2 | DICE 0.8755612884657328\n",
      "[0.91727996 0.91855238 0.85791455 0.8018494  0.78241524 0.80572562\n",
      " 0.8828004  0.90380459]\n",
      "SAVING BEST!\n",
      "351/351 01:06<00:00 , loss=0.165, lr=0.000976, step=1053\n",
      "351/351 01:09<00:00 , loss=0.143, lr=0.000957, step=1404\n",
      "115/115 00:45<00:00 \n",
      "EPOCH 4 | DICE 0.8994577121935572\n",
      "[0.92289292 0.93221243 0.90091181 0.88447553 0.8508347  0.8423454\n",
      " 0.90453713 0.90975683]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.138, lr=0.000933, step=1755\n",
      "351/351 01:05<00:00 , loss=0.123, lr=0.000905, step=2106\n",
      "115/115 00:45<00:00 \n",
      "EPOCH 6 | DICE 0.9016757574725451\n",
      "[0.92608076 0.92968626 0.89601491 0.89311095 0.85887112 0.85286871\n",
      " 0.90918111 0.90831499]\n",
      "SAVING BEST!\n",
      "351/351 01:05<00:00 , loss=0.107, lr=0.000872, step=2457\n",
      "351/351 01:06<00:00 , loss=0.0979, lr=0.000835, step=2808\n",
      "115/115 00:47<00:00 \n",
      "EPOCH 8 | DICE 0.9122750639831434\n",
      "[0.92543385 0.93974794 0.92138265 0.89542892 0.87769626 0.88243177\n",
      " 0.91687832 0.91565166]\n",
      "SAVING BEST!\n",
      "351/351 01:07<00:00 , loss=0.0914, lr=0.000794, step=3159\n",
      "351/351 01:06<00:00 , loss=0.0971, lr=0.00075, step=3510 \n",
      "115/115 00:43<00:00 \n",
      "EPOCH 10 | DICE 0.9085548027702061\n",
      "[0.91783371 0.93628481 0.92102989 0.9046471  0.87108954 0.87475433\n",
      " 0.92163434 0.90809987]\n",
      "351/351 01:06<00:00 , loss=0.0866, lr=0.000703, step=3861\n",
      "351/351 01:06<00:00 , loss=0.0833, lr=0.000655, step=4212\n",
      "115/115 00:45<00:00 \n",
      "EPOCH 12 | DICE 0.9131996038197754\n",
      "[0.93064827 0.94356398 0.93243844 0.9058256  0.86933848 0.87750909\n",
      " 0.92119417 0.91314266]\n",
      "SAVING BEST!\n",
      "351/351 01:06<00:00 , loss=0.0845, lr=0.000604, step=4563\n",
      "351/351 01:06<00:00 , loss=0.0961, lr=0.000552, step=4914\n",
      "115/115 00:45<00:00 \n",
      "EPOCH 14 | DICE 0.9135699253365397\n",
      "[0.92894409 0.94300129 0.92417159 0.90943321 0.87452304 0.87390568\n",
      " 0.91698755 0.91670465]\n",
      "SAVING BEST!\n",
      "351/351 01:06<00:00 , loss=0.0931, lr=0.0005, step=5265  \n",
      "351/351 01:06<00:00 , loss=0.082, lr=0.000448, step=5616 \n",
      "115/115 00:42<00:00 \n",
      "EPOCH 16 | DICE 0.9161123513240401\n",
      "[0.93021091 0.9427923  0.9211453  0.90594055 0.89202134 0.89668235\n",
      " 0.91498683 0.91570613]\n",
      "SAVING BEST!\n",
      "351/351 01:06<00:00 , loss=0.0819, lr=0.000396, step=5967\n",
      "351/351 01:05<00:00 , loss=0.0753, lr=0.000345, step=6318\n",
      "115/115 00:42<00:00 \n",
      "EPOCH 18 | DICE 0.9171870650897591\n",
      "[0.93106282 0.94217715 0.92908366 0.893613   0.88258175 0.90696638\n",
      " 0.92484514 0.91624618]\n",
      "SAVING BEST!\n",
      "351/351 01:06<00:00 , loss=0.0729, lr=0.000297, step=6669\n",
      "351/351 01:06<00:00 , loss=0.0737, lr=0.00025, step=7020 \n",
      "115/115 00:37<00:00 \n",
      "EPOCH 20 | DICE 0.9177586798561688\n",
      "[0.93231977 0.94300053 0.92769997 0.89143145 0.88854699 0.90767644\n",
      " 0.92233936 0.91721662]\n",
      "SAVING BEST!\n",
      "[rank0]:[W312 01:38:11.622719457 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"5\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(0, 1):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179ab22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c081cd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: usage: kill [-s sigspec | -n signum | -sigspec] pid | jobspec ... or kill -l [sigspec]\n",
      "[NbConvertApp] Converting notebook train1.ipynb to script\n",
      "[NbConvertApp] Writing 30521 bytes to train1.py\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 04:43:29.926449 2012625 site-packages/torch/distributed/run.py:792] \n",
      "W0312 04:43:29.926449 2012625 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 04:43:29.926449 2012625 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 04:43:29.926449 2012625 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "[rank0]:[W312 04:43:40.931341491 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W312 04:43:41.972554984 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/349 00:00<? [rank0]:[W312 04:43:43.820105752 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W312 04:43:43.849921028 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "349/349 01:05<00:00 , loss=0.727, lr=0.000992, step=349\n",
      "118/118 00:35<00:00 \n",
      "EPOCH 1 | DICE 0.629216381380004\n",
      "[0.88894362 0.89205747 0.79447014 0.60124025 0.58868087 0.35354218\n",
      " 0.45078997 0.76680008]\n",
      "SAVING BEST!\n",
      "349/349 01:04<00:00 , loss=0.31, lr=0.00097, step=698  \n",
      "118/118 00:34<00:00 \n",
      "EPOCH 2 | DICE 0.8717026910193174\n",
      "[0.9227601  0.92250106 0.85868509 0.80765221 0.7853599  0.83260222\n",
      " 0.88952655 0.88572048]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.178, lr=0.000933, step=1047\n",
      "349/349 01:05<00:00 , loss=0.163, lr=0.000883, step=1396\n",
      "118/118 00:35<00:00 \n",
      "EPOCH 4 | DICE 0.9045401254704631\n",
      "[0.93284874 0.93378016 0.88591355 0.85834613 0.86716845 0.88593202\n",
      " 0.91202193 0.91452873]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.138, lr=0.000821, step=1745\n",
      "349/349 01:05<00:00 , loss=0.128, lr=0.00075, step=2094 \n",
      "118/118 00:39<00:00 \n",
      "EPOCH 6 | DICE 0.9150880750361807\n",
      "[0.93273551 0.94042192 0.90955618 0.8847206  0.88331307 0.90040439\n",
      " 0.92262997 0.92026307]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.0996, lr=0.000671, step=2443\n",
      "349/349 01:05<00:00 , loss=0.0986, lr=0.000587, step=2792\n",
      "118/118 00:36<00:00 \n",
      "EPOCH 8 | DICE 0.9210027239969906\n",
      "[0.93748712 0.94346599 0.90942931 0.88874882 0.89931871 0.91154066\n",
      " 0.92939313 0.92489764]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.0989, lr=0.0005, step=3141  \n",
      "349/349 01:05<00:00 , loss=0.089, lr=0.000413, step=3490 \n",
      "118/118 00:34<00:00 \n",
      "EPOCH 10 | DICE 0.9230612376641913\n",
      "[0.93943633 0.9456716  0.91527307 0.89371168 0.90395538 0.9095708\n",
      " 0.92620206 0.9273816 ]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.0879, lr=0.000329, step=3839\n",
      "349/349 01:05<00:00 , loss=0.0837, lr=0.00025, step=4188 \n",
      "118/118 00:36<00:00 \n",
      "EPOCH 12 | DICE 0.9250958151622709\n",
      "[0.94059121 0.94727795 0.91785323 0.8971665  0.90505962 0.9140561\n",
      " 0.93205598 0.92763175]\n",
      "SAVING BEST!\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 05:01:15.988121 2015957 site-packages/torch/distributed/run.py:792] \n",
      "W0312 05:01:15.988121 2015957 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 05:01:15.988121 2015957 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 05:01:15.988121 2015957 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "[rank0]:[W312 05:01:23.808354984 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "[rank1]:[W312 05:01:23.849407635 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/349 00:00<? [rank0]:[W312 05:01:27.990898239 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W312 05:01:27.134963744 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "349/349 01:05<00:00 , loss=0.68, lr=0.000992, step=349 \n",
      "118/118 00:34<00:00 \n",
      "EPOCH 1 | DICE 0.7460651334235241\n",
      "[0.89949551 0.91819393 0.81186764 0.74584038 0.64968997 0.46439738\n",
      " 0.86344206 0.76911967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING BEST!\n",
      "349/349 01:04<00:00 , loss=0.251, lr=0.00097, step=698 \n",
      "118/118 00:33<00:00 \n",
      "EPOCH 2 | DICE 0.8817584346427239\n",
      "[0.92232707 0.92969806 0.87417138 0.82622506 0.79132728 0.83366028\n",
      " 0.90407333 0.89755936]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.17, lr=0.000933, step=1047 \n",
      "349/349 01:05<00:00 , loss=0.149, lr=0.000883, step=1396\n",
      "118/118 00:33<00:00 \n",
      "EPOCH 4 | DICE 0.9042118787016814\n",
      "[0.93449152 0.93866059 0.88893004 0.85897133 0.8243196  0.87007459\n",
      " 0.92741545 0.91846788]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.139, lr=0.000821, step=1745\n",
      "349/349 01:05<00:00 , loss=0.115, lr=0.00075, step=2094 \n",
      "118/118 00:33<00:00 \n",
      "EPOCH 6 | DICE 0.9108684083405585\n",
      "[0.94270197 0.95065998 0.9143974  0.8748387  0.8437324  0.87573445\n",
      " 0.93123423 0.91558179]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.114, lr=0.000671, step=2443\n",
      "349/349 01:05<00:00 , loss=0.103, lr=0.000587, step=2792 \n",
      "118/118 00:33<00:00 \n",
      "EPOCH 8 | DICE 0.9147523704316725\n",
      "[0.94283392 0.94800938 0.91214514 0.87266781 0.84607382 0.89515904\n",
      " 0.93294114 0.92230302]\n",
      "SAVING BEST!\n",
      "349/349 01:05<00:00 , loss=0.0932, lr=0.0005, step=3141  \n",
      "349/349 01:05<00:00 , loss=0.0939, lr=0.000413, step=3490\n",
      "118/118 00:33<00:00 \n",
      "EPOCH 10 | DICE 0.9121456806504822\n",
      "[0.94395898 0.95412553 0.9058105  0.85819377 0.84035969 0.88245611\n",
      " 0.93574459 0.9206111 ]\n",
      "349/349 01:05<00:00 , loss=0.0865, lr=0.000329, step=3839\n",
      "349/349 01:05<00:00 , loss=0.0835, lr=0.00025, step=4188 \n",
      "118/118 00:33<00:00 \n",
      "EPOCH 12 | DICE 0.9221875105639453\n",
      "[0.9463426  0.95504908 0.92318882 0.89809043 0.87334594 0.90053593\n",
      " 0.9343053  0.92329383]\n",
      "SAVING BEST!\n",
      "/home/harshit/anaconda3/lib/python3.9/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use-env is set by default in torchrun.\n",
      "If your script expects `--local-rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  main()\n",
      "W0312 05:18:42.307760 2019335 site-packages/torch/distributed/run.py:792] \n",
      "W0312 05:18:42.307760 2019335 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "W0312 05:18:42.307760 2019335 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0312 05:18:42.307760 2019335 site-packages/torch/distributed/run.py:792] *****************************************\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "[rank1]:[W312 05:18:48.368768013 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1, 8, 256, 256])\n",
      "[rank0]:[W312 05:18:48.736039988 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n",
      "0/348 00:00<? [rank0]:[W312 05:18:52.975018243 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "[rank1]:[W312 05:18:52.975193871 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "348/348 01:04<00:00 , loss=0.707, lr=0.000992, step=348\n",
      "118/118 00:34<00:00 \n",
      "EPOCH 1 | DICE 0.6819540311413426\n",
      "[0.86992224 0.89181697 0.78560672 0.73614794 0.71054116 0.3878706\n",
      " 0.50740758 0.76743403]\n",
      "SAVING BEST!\n",
      "348/348 01:03<00:00 , loss=0.274, lr=0.00097, step=696 \n",
      "118/118 00:33<00:00 \n",
      "EPOCH 2 | DICE 0.8643512662888421\n",
      "[0.89535163 0.90938657 0.83878128 0.78185938 0.77406939 0.80846607\n",
      " 0.88334057 0.89658064]\n",
      "SAVING BEST!\n",
      "348/348 01:04<00:00 , loss=0.168, lr=0.000933, step=1044\n",
      "348/348 01:04<00:00 , loss=0.142, lr=0.000883, step=1392\n",
      "118/118 00:34<00:00 \n",
      "EPOCH 4 | DICE 0.8885020930433993\n",
      "[0.92430088 0.93199942 0.87312743 0.81826624 0.80272497 0.8372059\n",
      " 0.89920958 0.91552123]\n",
      "SAVING BEST!\n",
      "348/348 01:04<00:00 , loss=0.13, lr=0.000821, step=1740 \n",
      "348/348 01:04<00:00 , loss=0.113, lr=0.00075, step=2088 \n",
      "118/118 00:34<00:00 \n",
      "EPOCH 6 | DICE 0.8972619359891266\n",
      "[0.92646354 0.93498629 0.87193465 0.83751304 0.83560505 0.86790338\n",
      " 0.91174297 0.91469942]\n",
      "SAVING BEST!\n",
      "348/348 01:04<00:00 , loss=0.0989, lr=0.000671, step=2436\n",
      "348/348 01:04<00:00 , loss=0.092, lr=0.000587, step=2784 \n",
      "118/118 00:34<00:00 \n",
      "EPOCH 8 | DICE 0.9058388434717641\n",
      "[0.92939989 0.93964455 0.88803069 0.84130826 0.84427602 0.87732545\n",
      " 0.91663582 0.92557903]\n",
      "SAVING BEST!\n",
      "348/348 01:04<00:00 , loss=0.0891, lr=0.0005, step=3132  \n",
      "348/348 01:04<00:00 , loss=0.0882, lr=0.000413, step=3480\n",
      "118/118 00:37<00:00 \n",
      "EPOCH 10 | DICE 0.9030068447013786\n",
      "[0.93282937 0.9409193  0.89849774 0.84586726 0.82134189 0.86828792\n",
      " 0.9185546  0.92011327]\n",
      "348/348 01:04<00:00 , loss=0.0842, lr=0.000329, step=3828\n",
      "348/348 01:04<00:00 , loss=0.0806, lr=0.00025, step=4176 \n",
      "118/118 00:35<00:00 \n",
      "EPOCH 12 | DICE 0.90508283005627\n",
      "[0.93283957 0.94112686 0.8995008  0.85094376 0.82877817 0.87095378\n",
      " 0.92012429 0.92190424]\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Adding this line solved my problem\n",
    "!kill $(ps aux | grep \"run.py\" | grep -v grep | awk '{print $2}')\n",
    "\n",
    "DIR = \"./data/segmentation_model/\"\n",
    "NAME = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
    "V = \"5\"\n",
    "\n",
    "os.makedirs(f\"{DIR}/{NAME}_v{V}/\", exist_ok=1)\n",
    "\n",
    "!jupyter nbconvert --to script train1.ipynb\n",
    "\n",
    "for F in range(1, 4):\n",
    "    \n",
    "    shutil.copy(\"train1.py\", f\"{DIR}/{NAME}_v{V}/run.py\")\n",
    "    \n",
    "    filedata = None\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'r') as file:\n",
    "        filedata = file.read()\n",
    "\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('FOLD = 0', f'FOLD = {F}')\n",
    "    filedata = filedata.replace('model_name = -1', f\"model_name = '{NAME}'\")\n",
    "    filedata = filedata.replace(f'V = -1', f\"V = '{V}'\")\n",
    "    \n",
    "    # Write the file out again\n",
    "    with open(f\"{DIR}/{NAME}_v{V}/run.py\", 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    #!python \"{DIR}/{NAME}_v{V}/run.py\"\n",
    "    \n",
    "    !CUDA_VISIBLE_DEVICES=1,2 python -m torch.distributed.launch --nproc_per_node=2 \"{DIR}/{NAME}_v{V}/run.py\" | tee \"{DIR}/{NAME}_v{V}/log_{F}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45102943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42ee61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b49fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'./data/segmentation_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c39a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8763f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29c20b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9177586798561688,\n",
       "  0.9250958151622709,\n",
       "  0.9221875105639453,\n",
       "  0.9058388434717641],\n",
       " 0.9177202122635373)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scs = [np.array([float(line.split('| DICE ')[1].split(' |')[0]) for line in open(f'./data/segmentation_model/tf_efficientnetv2_s.in21k_ft_in1k_v5/log_{F}.txt').readlines() if 'DICE' in line]).max() for F in range(4)]\n",
    "scs, np.mean(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29854ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcd8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74ee96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f63664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd289e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd0914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b459ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
